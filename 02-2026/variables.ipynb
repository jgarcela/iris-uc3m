{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook sirve para probar la clasificación de variables de manera automática en base al documento de **Protocolo de Variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0a. Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "def consultar_ollama(prompt: str, modelo: str = \"gemma3:4b\") -> str:\n",
    "    \"\"\"\n",
    "    Función genérica para enviar cualquier prompt a Ollama.\n",
    "    Devuelve la respuesta del modelo como texto limpio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(model=modelo, messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt,\n",
    "            },\n",
    "        ])\n",
    "        return response['message']['content'].strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error conectando con el modelo {modelo}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0b. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_N_noticia</th>\n",
       "      <th>IdNoticia</th>\n",
       "      <th>Medio_num</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>año</th>\n",
       "      <th>año_agrupado</th>\n",
       "      <th>Caracteres</th>\n",
       "      <th>Titular</th>\n",
       "      <th>nombre_propio_titular</th>\n",
       "      <th>cita_en_titulo</th>\n",
       "      <th>...</th>\n",
       "      <th>no_MES</th>\n",
       "      <th>no_Contenido</th>\n",
       "      <th>no_Pagina_url</th>\n",
       "      <th>no_verificacion</th>\n",
       "      <th>no_textonoticia</th>\n",
       "      <th>antiguo_genero_protagonistas</th>\n",
       "      <th>emocion_ia</th>\n",
       "      <th>IA_razonamiento_titulares</th>\n",
       "      <th>no_vacio_numero_caracteres</th>\n",
       "      <th>contenido_articulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>4515</td>\n",
       "      <td>el papa denuncia la violencia contra las mujer...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>“quien lastima a una mujer profana a dios”, ha...</td>\n",
       "      <td>https://elpais.com/sociedad/2024-01-01/el-papa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>el papa francisco ha denunciado la violencia c...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>El Papa (hombre)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El papa Francisco ha denunciado la violencia c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>4880</td>\n",
       "      <td>inteligencia artificial: agárrense, que vienen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>los despidos masivos de una industria tan rent...</td>\n",
       "      <td>https://elpais.com/babelia/2024-01-01/intelige...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>baldur’s gate 3, zelda: tears of the kingdom, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artículos estrictamente de opinión que respond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>9052</td>\n",
       "      <td>en 2024 votarán miles de millones de personas ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>la concentración de procesos electorales en un...</td>\n",
       "      <td>https://elpais.com/tecnologia/2024-01-01/en-20...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>durante el año 2024, el calendario electoral s...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Una persona antes de coger una papeleta para e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>2523</td>\n",
       "      <td>estupidez artificial</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lo tenebroso no son las nuevas formas de traba...</td>\n",
       "      <td>https://elpais.com/opinion/2024-01-02/estupide...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lo que da miedo de 2024 no es la inteligencia ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lo tenebroso no son las nuevas formas de traba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>3177</td>\n",
       "      <td>la última navidad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>los lectores escriben sobre la ilusión de los ...</td>\n",
       "      <td>https://elpais.com/opinion/2024-01-02/la-ultim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>estoy triste. sé positivamente que esta ha sid...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los lectores escriben sobre la ilusión de los ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>7111</td>\n",
       "      <td>j995</td>\n",
       "      <td>7</td>\n",
       "      <td>18/01/2017</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1631</td>\n",
       "      <td>Un ‘pezrobot’ tan realista que puede filmar pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.lavanguardia.com/natural/20180322/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No hay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La mayoría de los peces robot no se encuentran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>7112</td>\n",
       "      <td>j996</td>\n",
       "      <td>7</td>\n",
       "      <td>18/01/2017</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2553</td>\n",
       "      <td>YouTube prioriza contenido extremista</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.lavanguardia.com/tecnologia/201803...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YouTube (empresas).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>7113</td>\n",
       "      <td>j997</td>\n",
       "      <td>7</td>\n",
       "      <td>05/01/2017</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4599</td>\n",
       "      <td>Estos son los retos del futuro de la automoción</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.lavanguardia.com/motor/20180226/44...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No hay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El futuro del coche conectado en Volkswagen es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7114</td>\n",
       "      <td>j998</td>\n",
       "      <td>1</td>\n",
       "      <td>18/01/2017</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>6479</td>\n",
       "      <td>Lucía Velasco, tecnóloga: \"Hay 15s que recomie...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.elmundo.es/yodona/lifestyle/2021/1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucía Velasco (mujer).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tú crees que eso de los algoritmos no va conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>7115</td>\n",
       "      <td>j999</td>\n",
       "      <td>1</td>\n",
       "      <td>12/01/2017</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>6082</td>\n",
       "      <td>Valencia Digital Summit 2021:el referente tecn...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.elmundo.es/tecnologia/innovacion/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valencia Digital Summit 2021 (evento/entidad).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L'Oceanogràfic de Valencia acogió las ponencia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7115 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_N_noticia IdNoticia  Medio_num       Fecha   año  año_agrupado  \\\n",
       "0                1         1          2  01/01/2024  2024             2   \n",
       "1                2         2          2  01/01/2024  2024             2   \n",
       "2                3         3          2  01/01/2024  2024             2   \n",
       "3                4         4          2  02/01/2024  2024             2   \n",
       "4                5         5          2  02/01/2024  2024             2   \n",
       "...            ...       ...        ...         ...   ...           ...   \n",
       "7110          7111      j995          7  18/01/2017  2018             1   \n",
       "7111          7112      j996          7  18/01/2017  2018             1   \n",
       "7112          7113      j997          7  05/01/2017  2018             1   \n",
       "7113          7114      j998          1  18/01/2017  2021             1   \n",
       "7114          7115      j999          1  12/01/2017  2021             1   \n",
       "\n",
       "      Caracteres                                            Titular  \\\n",
       "0           4515  el papa denuncia la violencia contra las mujer...   \n",
       "1           4880  inteligencia artificial: agárrense, que vienen...   \n",
       "2           9052  en 2024 votarán miles de millones de personas ...   \n",
       "3           2523                               estupidez artificial   \n",
       "4           3177                                  la última navidad   \n",
       "...          ...                                                ...   \n",
       "7110        1631  Un ‘pezrobot’ tan realista que puede filmar pe...   \n",
       "7111        2553              YouTube prioriza contenido extremista   \n",
       "7112        4599    Estos son los retos del futuro de la automoción   \n",
       "7113        6479  Lucía Velasco, tecnóloga: \"Hay 15s que recomie...   \n",
       "7114        6082  Valencia Digital Summit 2021:el referente tecn...   \n",
       "\n",
       "      nombre_propio_titular  cita_en_titulo  ...  no_MES  \\\n",
       "0                         2               2  ...     1.0   \n",
       "1                         1               1  ...     1.0   \n",
       "2                         1               1  ...     1.0   \n",
       "3                         1               1  ...     1.0   \n",
       "4                         1               1  ...     1.0   \n",
       "...                     ...             ...  ...     ...   \n",
       "7110                      1               1  ...     NaN   \n",
       "7111                      5               1  ...     NaN   \n",
       "7112                      1               1  ...     NaN   \n",
       "7113                      3               2  ...     NaN   \n",
       "7114                      5               1  ...     NaN   \n",
       "\n",
       "                                           no_Contenido  \\\n",
       "0     “quien lastima a una mujer profana a dios”, ha...   \n",
       "1     los despidos masivos de una industria tan rent...   \n",
       "2     la concentración de procesos electorales en un...   \n",
       "3     lo tenebroso no son las nuevas formas de traba...   \n",
       "4     los lectores escriben sobre la ilusión de los ...   \n",
       "...                                                 ...   \n",
       "7110                                                  x   \n",
       "7111                                                  x   \n",
       "7112                                                  x   \n",
       "7113                                                  x   \n",
       "7114                                                  x   \n",
       "\n",
       "                                          no_Pagina_url  no_verificacion  \\\n",
       "0     https://elpais.com/sociedad/2024-01-01/el-papa...              1.0   \n",
       "1     https://elpais.com/babelia/2024-01-01/intelige...              1.0   \n",
       "2     https://elpais.com/tecnologia/2024-01-01/en-20...              1.0   \n",
       "3     https://elpais.com/opinion/2024-01-02/estupide...              1.0   \n",
       "4     https://elpais.com/opinion/2024-01-02/la-ultim...              1.0   \n",
       "...                                                 ...              ...   \n",
       "7110  https://www.lavanguardia.com/natural/20180322/...              NaN   \n",
       "7111  https://www.lavanguardia.com/tecnologia/201803...              NaN   \n",
       "7112  https://www.lavanguardia.com/motor/20180226/44...              NaN   \n",
       "7113  https://www.elmundo.es/yodona/lifestyle/2021/1...              NaN   \n",
       "7114  https://www.elmundo.es/tecnologia/innovacion/2...              NaN   \n",
       "\n",
       "                                        no_textonoticia  \\\n",
       "0     el papa francisco ha denunciado la violencia c...   \n",
       "1     baldur’s gate 3, zelda: tears of the kingdom, ...   \n",
       "2     durante el año 2024, el calendario electoral s...   \n",
       "3     lo que da miedo de 2024 no es la inteligencia ...   \n",
       "4     estoy triste. sé positivamente que esta ha sid...   \n",
       "...                                                 ...   \n",
       "7110                                                NaN   \n",
       "7111                                                NaN   \n",
       "7112                                                NaN   \n",
       "7113                                                NaN   \n",
       "7114                                                NaN   \n",
       "\n",
       "      antiguo_genero_protagonistas  emocion_ia  \\\n",
       "0                                3         5.0   \n",
       "1                                4         7.0   \n",
       "2                                1         7.0   \n",
       "3                                1         6.0   \n",
       "4                                1         3.0   \n",
       "...                            ...         ...   \n",
       "7110                             4         NaN   \n",
       "7111                             3         NaN   \n",
       "7112                             4         NaN   \n",
       "7113                             2         NaN   \n",
       "7114                             3         NaN   \n",
       "\n",
       "                           IA_razonamiento_titulares  \\\n",
       "0                                   El Papa (hombre)   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "7110                                         No hay.   \n",
       "7111                             YouTube (empresas).   \n",
       "7112                                         No hay.   \n",
       "7113                          Lucía Velasco (mujer).   \n",
       "7114  Valencia Digital Summit 2021 (evento/entidad).   \n",
       "\n",
       "      no_vacio_numero_caracteres  \\\n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "7110                         NaN   \n",
       "7111                         NaN   \n",
       "7112                         NaN   \n",
       "7113                         NaN   \n",
       "7114                         NaN   \n",
       "\n",
       "                                     contenido_articulo  \n",
       "0     El papa Francisco ha denunciado la violencia c...  \n",
       "1     Artículos estrictamente de opinión que respond...  \n",
       "2     Una persona antes de coger una papeleta para e...  \n",
       "3     Lo tenebroso no son las nuevas formas de traba...  \n",
       "4     Los lectores escriben sobre la ilusión de los ...  \n",
       "...                                                 ...  \n",
       "7110  La mayoría de los peces robot no se encuentran...  \n",
       "7111                                                NaN  \n",
       "7112  El futuro del coche conectado en Volkswagen es...  \n",
       "7113  Tú crees que eso de los algoritmos no va conti...  \n",
       "7114  L'Oceanogràfic de Valencia acogió las ponencia...  \n",
       "\n",
       "[7115 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import newspaper\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "\n",
    "SUFFIX = \"scrape\"\n",
    "data = pd.read_csv(f\"../data/2026_02_10_imio_def_todo_envio_heidy.xlsx - 2026_02_09_imio_def_todo_clara_{SUFFIX}.csv\")\n",
    "# data = pd.read_csv(\"../data/Base de datos Noticias 27102025.xlsx - Noticias_scrape.csv\")\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_N_noticia                                                                         1\n",
      "IdNoticia                                                                            1\n",
      "Medio_num                                                                            2\n",
      "Fecha                                                                       01/01/2024\n",
      "año                                                                               2024\n",
      "año_agrupado                                                                         2\n",
      "Caracteres                                                                        4515\n",
      "Titular                              el papa denuncia la violencia contra las mujer...\n",
      "nombre_propio_titular                                                                2\n",
      "cita_en_titulo                                                                       2\n",
      "cla_genero_prota                                                                     3\n",
      "nombre_periodista                                                         Lorena Pacho\n",
      "genero_periodista                                                                    2\n",
      "Tema_recodificado                                                                   12\n",
      "no_tema                                                                             12\n",
      "ia_tema_central                                                                    1.0\n",
      "significado_ia                                                                     1.0\n",
      "menciona_ia                                                                        2.0\n",
      "referencia_politicas_genero                                                        2.0\n",
      "denuncia_desigualdad_genero                                                          2\n",
      "mujeres_racializadas_noticias                                                      1.0\n",
      "mujeres_con_discapacidad_noticias                                                  1.0\n",
      "mujeres_generacionalidad_noticias                                                  1.0\n",
      "tiene_fotografias                                                                  2.0\n",
      "numero_fotografias                                                                 3.0\n",
      "utiliza_fuente                                                                     2.0\n",
      "numero_declaraciones                                                               1.0\n",
      "lenguaje_sexista                                                                   2.0\n",
      "masc_generico                                                                      1.0\n",
      "hombre_denominar_humanidad                                                         1.0\n",
      "uso_dual_zorr                                                                      1.0\n",
      "uso_cargo_mujer                                                                    1.0\n",
      "sexismo_discurso                                                                   2.0\n",
      "androcentrismo                                                                     1,0\n",
      "mencion_nombre_investigadora                                                       1.0\n",
      "asimetria_mujer_hombre                                                             1.0\n",
      "disminutivos_infantilizacion                                                       1.0\n",
      "denominacion_sexualizada                                                           1,0\n",
      "denominacion_redundante                                                            1.0\n",
      "denominacion_dependiente                                                           1.0\n",
      "criterios_excepcion                                                                1.0\n",
      "comparacion_mujer_hombre                                                           1.0\n",
      "no_NombreUsuario                                                                UCM3 6\n",
      "no_Autor                                                                  Lorena Pacho\n",
      "no_MES                                                                             1.0\n",
      "no_Contenido                         “quien lastima a una mujer profana a dios”, ha...\n",
      "no_Pagina_url                        https://elpais.com/sociedad/2024-01-01/el-papa...\n",
      "no_verificacion                                                                    1.0\n",
      "no_textonoticia                      el papa francisco ha denunciado la violencia c...\n",
      "antiguo_genero_protagonistas                                                         3\n",
      "emocion_ia                                                                         5.0\n",
      "IA_razonamiento_titulares                                             El Papa (hombre)\n",
      "no_vacio_numero_caracteres                                                         NaN\n",
      "contenido_articulo                   El papa Francisco ha denunciado la violencia c...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "articulo_raw = data[data['IdNoticia'] == \"1\"].iloc[0]\n",
    "print(articulo_raw)\n",
    "\n",
    "# articulo_raw = data[data['IdNoticia'] == 46].iloc[0]\n",
    "# print(articulo_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texto del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El papa Francisco ha denunciado la violencia contra las mujeres en la misa del día de Año Nuevo, y ha defendido que la Iglesia debe darle más espacio a ellas y “redescubrir su rostro femenino”. “Quien lastima a una mujer profana a Dios, nacido de mujer”, condenó Bergoglio. Y recordó: “Toda sociedad necesita acoger el don de la mujer, de cada mujer: respetarla, cuidarla, valorarla”.\\n\\nEl día 1 de enero el cristianismo dedica el día a la Virgen, por eso el Pontífice abrió el año con una misa en la basílica en la que ensalzó el papel de María y de la mujer en la Iglesia. Francisco hizo referencia en su discurso a textos papales, como la encíclica Lumen gentium (1964) que Pablo VI escribió en el revolucionario Concilio Vaticano II, y señaló que “la Iglesia necesita de María para redescubrir su propio rostro femenino, para asemejarse más a ella que, como mujer, Virgen y Madre, representa su modelo y su figura perfecta; para dar espacio a las mujeres y para ser generativa a través de una pastoral hecha de cuidado y solicitud, de paciencia y valentía materna”.\\n\\nEl Pontífice habló también del resto del mundo durante la misa solemne y ante la plana mayor de la curia romana, otras autoridades y los miles de fieles congregados en el templo: “También el mundo necesita mirar a las madres y a las mujeres para encontrar la paz, para escapar de las espirales de violencia y odio, y volver a tener miradas humanas y corazones que ven”.\\n\\n“Nuestro tiempo, vacío de paz, necesita de una Madre que vuelva a reunir a la familia humana. Miremos a María para ser constructores de unidad”, insistió Francisco.\\n\\nEl papa Francisco, durante el rezo del Ángelus desde el Palacio Apostólico Vaticano, este lunes. REMO CASILLI (REUTERS)\\n\\nDurante su pontificado, Francisco ha dado pasos para ampliar las responsabilidades de la mujer en la Iglesia y ha nombrado a varias mujeres en puestos de dirección en la curia. Por ejemplo, la religiosa italiana Alessandra Smerilli fue nombrada en 2021 subsecretaria del dicasterio para el Servicio del Desarrollo Humano Integral, el cargo más alto ocupado por una mujer en la Santa Sede.\\n\\nEste año además se ha celebrado la asamblea del primer sínodo de la Iglesia en el que las mujeres y los laicos tienen derecho a voto. El encuentro concluyó con un documento que reclama más puestos de poder para ellas y con el compromiso de presentar en un año conclusiones sobre el diaconado femenino.\\n\\nViolencia y feminicidios\\n\\nFrancisco ha denunciado la violencia contra las mujeres numerosas veces, pero en esta ocasión en Italia se ha acogido de una forma particular, ya que en este momento el país se encuentra en pleno examen de conciencia sobre cómo neutralizar una arraigada cultura machista que en ocasiones desemboca en feminicidios. El brutal asesinato de una universitaria de 22 años a manos de su expareja ha activado una insólita toma de conciencia en la sociedad. El crimen ha provocado protestas en todo el país y ha abierto el debate sobre la necesidad de legislar y poner en marcha iniciativas en las escuelas para atajar la violencia machista.\\n\\nSegún el Ministerio del Interior italiano, más de un centenar de mujeres fueron asesinadas en 2023, de ellas, 96 a manos de su pareja o expareja. El feminicidio se ha convertido en una palabra habitual en los titulares de los periódicos los últimos meses.\\n\\nAsistentes durante el rezo del Ángelus, este en la plaza de San Pedro en el Vaticano. VATICAN MEDIA (via REUTERS)\\n\\nEn Italia se vive un clima de concienciación también favorecido indirectamente por el estreno de la comedia dramática C’è ancora domani, sobre la emancipación de las mujeres y el sufragio femenino en el año 1946. La cinta va camino de convertirse en la película más vista de la historia del país y ya se utiliza como herramienta didáctica en las escuelas de todo el país.\\n\\nLa Iglesia celebra en Año Nuevo desde 1967 también la Jornada Mundial de la Paz. El Papa publica algunas semanas antes un mensaje especial para este día, que en esta ocasión abordaba los riesgos de la inteligencia artificial. “La inteligencia artificial debe ser entendida como una galaxia de realidades distintas y no podemos presumir a priori que su desarrollo aporte una contribución benéfica al futuro de la humanidad y a la paz entre los pueblos. Tal resultado positivo sólo será posible si somos capaces de actuar de forma responsable”, señaló el Pontífice. Según Francisco, los progresos tecnológicos y científicos están permitiendo “un control sobre la realidad nunca visto hasta ahora” y “poniendo en las manos del hombre una vasta gama de posibilidades, algunas de las cuales representan un riesgo para la supervivencia humana y un peligro para la casa común”.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articulo_text = articulo['no_Contenido']\n",
    "articulo_text = articulo_raw['contenido_articulo']\n",
    "\n",
    "articulo_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://elpais.com/sociedad/2024-01-01/el-papa-denuncia-la-violencia-contras-las-mujeres-y-reclama-mas-espacio-para-ellas-en-la-iglesia.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articulo_url = articulo_raw['no_Pagina_url']\n",
    "# articulo_url = articulo_raw['Pagina']\n",
    "\n",
    "articulo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objeto Article de newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "# Crear el objeto Article\n",
    "# Puedes añadir language='es' si ayuda al parser, aunque suele detectarlo solo.\n",
    "articulo = Article(articulo_url, language='es')\n",
    "\n",
    "try:\n",
    "    # 2. Descargar el HTML\n",
    "    articulo.download()\n",
    "    \n",
    "    # 3. Parsear (analizar) el contenido\n",
    "    articulo.parse()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al procesar la URL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02/2026 - Variables Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ID noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_id_noticia(articulo_raw):\n",
    "    \"\"\"\n",
    "    Extrae y devuelve el IdNoticia de un registro dado.\n",
    "    \"\"\"\n",
    "    articulo_id = articulo_raw['IdNoticia']\n",
    "    return articulo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articulo_id='1'\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "articulo_id = obtener_id_noticia(articulo_raw)\n",
    "print(f\"{articulo_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# Función para clasificar el medio según la URL\n",
    "def clasificar_var_medio(articulo):\n",
    "    # Extraer el dominio de la URL\n",
    "    url = articulo.url\n",
    "    domain = urlparse(url).netloc.lower()\n",
    "    \n",
    "    # Diccionario de dominios y categorías\n",
    "    media_map = {\n",
    "        \"elmundo.es\": 1,\n",
    "        \"elpais.com\": 2,\n",
    "        \"eldiario.es\": 3,\n",
    "        \"20minutos.es\": 4,\n",
    "        \"articulo14.com\": 5,\n",
    "        \"infolibre.es\": 6,\n",
    "        \"lavanguardia.com\": 7\n",
    "    }\n",
    "    \n",
    "    # Buscar el dominio en el mapa\n",
    "    for key, value in media_map.items():\n",
    "        if key in domain:\n",
    "            return key, value\n",
    "    \n",
    "    # Si no coincide con ninguno, retornar None o 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medio: elpais.com\n",
      "Categoría: 2\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Medio = clasificar_var_medio(articulo)[0]\n",
    "Medio_num = clasificar_var_medio(articulo)[1]\n",
    "\n",
    "print(f\"Medio: {Medio}\")\n",
    "print(f\"Categoría: {Medio_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from newspaper import Article\n",
    "\n",
    "def clasificar_var_fecha(articulo: Article) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article.\n",
    "    Devuelve la fecha como texto en formato 'dd/mm/aa' o None.\n",
    "    \"\"\"\n",
    "    # Verificamos si existe la fecha\n",
    "    if articulo.publish_date:\n",
    "        # %d = día (01-31)\n",
    "        # %m = mes (01-12)\n",
    "        # %y = año (dos últimos dígitos, ej: 26)\n",
    "        return articulo.publish_date.strftime(\"%d/%m/%y\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha: 01/01/24\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Fecha = clasificar_var_fecha(articulo)\n",
    "print(f\"Fecha: {Fecha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_mes(articulo: Article) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article procesado.\n",
    "    Devuelve el mes (MM) como entero o None si no tiene fecha.\n",
    "    \"\"\"\n",
    "    if articulo.publish_date:\n",
    "        return articulo.publish_date.month\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mes: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "mes = clasificar_var_mes(articulo)\n",
    "print(f\"mes: {mes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_año(articulo: Article) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article procesado.\n",
    "    Devuelve el año (YYYY) como entero o None si no tiene fecha.\n",
    "    \"\"\"\n",
    "    if articulo.publish_date:\n",
    "        return articulo.publish_date.year\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "año: 2024\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "año = clasificar_var_año(articulo)\n",
    "print(f\"año: {año}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Número de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_caracteres(articulo: Article) -> int:\n",
    "    \"\"\"\n",
    "    Devuelve la cantidad de caracteres del cuerpo del artículo.\n",
    "    Si no hay texto, devuelve 0.\n",
    "    \"\"\"\n",
    "    if articulo.text:\n",
    "        # Retorna la longitud del texto\n",
    "        return len(articulo.text)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres: 4697\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Caracteres = clasificar_var_caracteres(articulo)\n",
    "print(f\"Caracteres: {Caracteres}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Titular. Copia el titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_titular(articulo: Article) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article procesado.\n",
    "    Devuelve el titular en minúsculas o None si no existe.\n",
    "    \"\"\"\n",
    "    if articulo.title:\n",
    "        # .strip() quita espacios extra y .lower() pasa a minúsculas\n",
    "        return articulo.title.strip().lower()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titular: el papa denuncia la violencia contra las mujeres y reclama más “espacio” para ellas en la iglesia\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Titular = clasificar_var_titular(articulo)\n",
    "print(f\"Titular: {Titular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a. Nombre Propio Titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "\n",
    "class NombresDetectados(BaseModel):\n",
    "    # Lista de cadenas con los nombres extraídos\n",
    "    nombres: List[str] = Field(default_factory=list, description=\"Lista de nombres propios detectados\")\n",
    "    # Lista de enteros con los códigos correspondientes\n",
    "    valores: List[int] = Field(default_factory=list, description=\"Lista de valores clasificados según la tabla\")\n",
    "\n",
    "def clasificar_var_nombre_propio_titular_list(titulo: str) -> NombresDetectados:\n",
    "    \"\"\"\n",
    "    Extrae nombres propios del titular y los clasifica según su género o tipo.\n",
    "    Devuelve dos listas sincronizadas: nombres y valores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Si el título es muy corto, devolvemos listas vacías\n",
    "    if not titulo or len(titulo) < 3:\n",
    "        return NombresDetectados(nombres=[], valores=[])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente TITULAR y extrae los nombres propios, entidades, lugares o tecnologías.\n",
    "    Asigna a cada uno su código numérico correspondiente.\n",
    "\n",
    "    TITULAR: \"{titulo}\"\n",
    "\n",
    "    TABLA DE CÓDIGOS:\n",
    "    1  = Hombre (Nombre individual)\n",
    "    2  = Mujer (Nombre individual)\n",
    "    3  = Grupo Mixto (ej: \"Los Reyes\", \"La pareja\", \"Padres\")\n",
    "    32 = Grupo Mixto (Mayoría hombres)\n",
    "    33 = Grupo Mixto (Mayoría mujeres)\n",
    "    4  = Institución, Organización, Empresa, Partido Político (ej: \"Google\", \"PSOE\", \"La ONU\")\n",
    "    41 = Lugares: Países, Regiones, Ciudades (ej: \"España\", \"Madrid\", \"Europa\")\n",
    "    42 = Tecnología: Apps, Modelos de IA, Robots, Software (ej: \"ChatGPT\", \"Gemini\", \"Sora\", \"TikTok\")\n",
    "\n",
    "    INSTRUCCIONES:\n",
    "    - Ignora sustantivos comunes que no sean entidades (ej: no extraigas \"la policía\" si es genérico, pero sí \"Mossos d'Esquadra\").\n",
    "    - Distingue bien entre la EMPRESA (OpenAI -> 4) y el PRODUCTO (ChatGPT -> 42).\n",
    "    - Si no hay nombres propios, devuelve listas vacías.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON con esta estructura exacta:\n",
    "    {{\n",
    "        \"nombres\": [\"Nombre1\", \"Nombre2\"],\n",
    "        \"valores\": [Codigo1, Codigo2]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- PARSEO Y VALIDACIÓN ---\n",
    "    try:\n",
    "        # Limpieza básica para encontrar el JSON\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1:\n",
    "            return NombresDetectados(nombres=[], valores=[])\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        # Validamos con Pydantic\n",
    "        resultado = NombresDetectados(**data)\n",
    "        \n",
    "        # Validación de seguridad: Las listas deben tener el mismo tamaño\n",
    "        if len(resultado.nombres) != len(resultado.valores):\n",
    "            # Si hay desajuste, cortamos a la longitud del más corto\n",
    "            min_len = min(len(resultado.nombres), len(resultado.valores))\n",
    "            resultado.nombres = resultado.nombres[:min_len]\n",
    "            resultado.valores = resultado.valores[:min_len]\n",
    "            \n",
    "        return resultado\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError):\n",
    "        return NombresDetectados(nombres=[], valores=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre Propio Titular Lista Nombres: ['Papa']\n",
      "Nombre Propio Titular Lista Valores: [1]\n"
     ]
    }
   ],
   "source": [
    "nombre_propio_titular_list = clasificar_var_nombre_propio_titular_list(articulo.title)\n",
    "print(f\"Nombre Propio Titular Lista Nombres: {nombre_propio_titular_list.nombres}\")\n",
    "print(f\"Nombre Propio Titular Lista Valores: {nombre_propio_titular_list.valores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7b. Género Nombre Propio Titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_nombre_propio_titular(valores: list[int]) -> int:\n",
    "    \"\"\"\n",
    "    Calcula el valor único de protagonismo basado en la lista de entidades detectadas.\n",
    "    Prioridad absoluta a las personas sobre entidades/lugares.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not valores:\n",
    "        return 0\n",
    "\n",
    "    # 1. CONTADORES DE PERSONAS\n",
    "    cnt_hombres = valores.count(1)\n",
    "    cnt_mujeres = valores.count(2)\n",
    "    \n",
    "    # Contamos también si el LLM ya detectó grupos mixtos explícitos\n",
    "    cnt_mixtos_neutro = valores.count(3)\n",
    "    cnt_mixtos_hombres = valores.count(32)\n",
    "    cnt_mixtos_mujeres = valores.count(33)\n",
    "\n",
    "    # Suma total de indicadores humanos\n",
    "    total_humanos = cnt_hombres + cnt_mujeres + cnt_mixtos_neutro + cnt_mixtos_hombres + cnt_mixtos_mujeres\n",
    "\n",
    "    # --- FASE 1: FILTRO HUMANO (Prioridad Absoluta) ---\n",
    "    if total_humanos > 0:\n",
    "        \n",
    "        # CASO A: Solo Hombres (Sin mujeres ni grupos mixtos)\n",
    "        if cnt_hombres > 0 and cnt_mujeres == 0 and cnt_mixtos_neutro == 0 and cnt_mixtos_hombres == 0 and cnt_mixtos_mujeres == 0:\n",
    "            return 1\n",
    "            \n",
    "        # CASO B: Solo Mujeres (Sin hombres ni grupos mixtos)\n",
    "        if cnt_mujeres > 0 and cnt_hombres == 0 and cnt_mixtos_neutro == 0 and cnt_mixtos_hombres == 0 and cnt_mixtos_mujeres == 0:\n",
    "            return 2\n",
    "\n",
    "        # CASO C: Mixto (Hay presencia de ambos o indicadores de grupo)\n",
    "        # Aquí decidimos si es 3, 32 o 33 contando individuos\n",
    "        \n",
    "        if cnt_hombres > cnt_mujeres:\n",
    "            return 32  # Mixto mayoritariamente masculino\n",
    "        elif cnt_mujeres > cnt_hombres:\n",
    "            return 33  # Mixto mayoritariamente femenino\n",
    "        else:\n",
    "            # Empate técnico (ej: 1 hombre y 1 mujer) o solo había un [3] genérico\n",
    "            # Si el empate viene de counts explícitos (1 vs 1), es 3.\n",
    "            # Si viene de grupos (ej: un [32] detectado), respetamos ese matiz.\n",
    "            if cnt_mixtos_hombres > cnt_mixtos_mujeres:\n",
    "                return 32\n",
    "            elif cnt_mixtos_mujeres > cnt_mixtos_hombres:\n",
    "                return 33\n",
    "            else:\n",
    "                return 3 # Empate total o mixto neutro\n",
    "\n",
    "    # --- FASE 2: NO HUMANOS (Solo si total_humanos == 0) ---\n",
    "    # Establecemos jerarquía de interés: IA > Entidad > Lugar\n",
    "    \n",
    "    if 42 in valores:\n",
    "        return 42 # Prioridad a Tecnología/IA\n",
    "    \n",
    "    if 4 in valores:\n",
    "        return 4  # Empresas / Instituciones\n",
    "        \n",
    "    if 41 in valores:\n",
    "        return 41 # Lugares (es lo menos informativo)\n",
    "\n",
    "    # Si todo falla (ej: llegó un código desconocido)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_propio_titular 1\n"
     ]
    }
   ],
   "source": [
    "nombre_propio_titular = clasificar_var_nombre_propio_titular(nombre_propio_titular_list.valores)\n",
    "print(\"nombre_propio_titular\", nombre_propio_titular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jggomez/Desktop/IRIS/iris-uc3m/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-02-14 20:40:16.241372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771098016.257255 3425484 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771098016.262184 3425484 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-14 20:40:16.278434: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-14 20:40:30,215 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-LOC, S-ORG, B-PER, I-PER, E-PER, S-MISC, B-ORG, E-ORG, S-PER, I-ORG, B-LOC, E-LOC, B-MISC, E-MISC, I-MISC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "# 1. Cargar el modelo (se hace una sola vez)\n",
    "tagger = SequenceTagger.load(\"flair/ner-spanish-large\")\n",
    "\n",
    "# Caché para no repetir llamadas a la API y ahorrar créditos\n",
    "cache_generos = {}\n",
    "\n",
    "def get_gender_cached(name):\n",
    "    \"\"\"Consulta Genderize y guarda el resultado en memoria.\"\"\"\n",
    "    name = name.lower().capitalize()\n",
    "    if name in cache_generos:\n",
    "        return cache_generos[name]\n",
    "    try:\n",
    "        # Usamos timeout para que no se quede colgado si falla la red\n",
    "        response = requests.get(f\"https://api.genderize.io?name={name}\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            gen = response.json().get(\"gender\")\n",
    "            cache_generos[name] = gen\n",
    "            return gen\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def clasificar_var_nombre_propio_titular(titular: str):\n",
    "    \"\"\"\n",
    "    Detecta nombres y devuelve (categoría, lista_nombres).\n",
    "    Categorías: 1=No hay, 2=Hombre, 3=Mujer, 4=Ambos, 5=Neutro (entidades)\n",
    "    \"\"\"\n",
    "    if not titular:\n",
    "        return 1, []\n",
    "\n",
    "    sentence = Sentence(titular)\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    nombres_personas = []\n",
    "    otras_entidades = []\n",
    "\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        if entity.tag == \"PER\":\n",
    "            nombres_personas.append(entity.text)\n",
    "        else:\n",
    "            otras_entidades.append(entity.text)\n",
    "\n",
    "    # Lógica de categorías\n",
    "    if not nombres_personas and otras_entidades:\n",
    "        return 5, []\n",
    "    \n",
    "    if not nombres_personas:\n",
    "        return 1, []\n",
    "\n",
    "    # Determinamos género para la categoría\n",
    "    hombres, mujeres = 0, 0\n",
    "    for np in nombres_personas:\n",
    "        primer_nombre = np.split()[0]\n",
    "        gen = get_gender_cached(primer_nombre)\n",
    "        if gen == \"male\": hombres += 1\n",
    "        elif gen == \"female\": mujeres += 1\n",
    "\n",
    "    if hombres == 0 and mujeres == 0: cat = 1\n",
    "    elif hombres > mujeres: cat = 2\n",
    "    elif mujeres > hombres: cat = 3\n",
    "    else: cat = 4 # Empate o presencia de ambos\n",
    "\n",
    "    return cat, nombres_personas\n",
    "\n",
    "def clasificar_var_genero_nombre_propio_titular(lista_nombres):\n",
    "    \"\"\"\n",
    "    Recibe la lista de nombres y devuelve sus géneros.\n",
    "    Categorías: 1=No hay, 2=Hombre, 3=Mujer, 4=Ambos, 5=Neutro (entidades)\n",
    "    \"\"\"\n",
    "    generos = []\n",
    "    for nombre_completo in lista_nombres:\n",
    "        primer_nombre = nombre_completo.split()[0]\n",
    "        genero = get_gender_cached(primer_nombre)\n",
    "        # Traducimos a algo más legible\n",
    "        if genero == \"male\": generos.append(\"2\")\n",
    "        elif genero == \"female\": generos.append(\"3\")\n",
    "        else: generos.append(\"desconocido\")\n",
    "    return generos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_propio_titular: 1\n",
      "nombres_encontrados: []\n",
      "genero_nombre_propio_titular: []\n"
     ]
    }
   ],
   "source": [
    "# --- Ejemplo de uso ---\n",
    "# Titular = \"Isabel Díaz Ayuso se reúne con Pedro Sánchez en Madrid\"\n",
    "\n",
    "# # 1. Obtenemos categoría y nombres\n",
    "# nombre_propio_titular, nombre_propio_titular_lista = clasificar_var_nombre_propio_titular(Titular)\n",
    "\n",
    "# # 2. Obtenemos los géneros basándonos en esa lista\n",
    "# genero_nombre_propio_titular = clasificar_var_genero_nombre_propio_titular(nombre_propio_titular_lista)\n",
    "\n",
    "# print(f\"nombre_propio_titular: {nombre_propio_titular}\")\n",
    "# print(f\"nombres_encontrados: {nombre_propio_titular_lista}\")\n",
    "# print(f\"genero_nombre_propio_titular: {genero_nombre_propio_titular}\")\n",
    "\n",
    "\n",
    "# 1. Obtenemos categoría y nombres\n",
    "nombre_propio_titular, nombre_propio_titular_lista = clasificar_var_nombre_propio_titular(Titular)\n",
    "\n",
    "# 2. Obtenemos los géneros basándonos en esa lista\n",
    "genero_nombre_propio_titular = clasificar_var_genero_nombre_propio_titular(nombre_propio_titular_lista)\n",
    "\n",
    "print(f\"nombre_propio_titular: {nombre_propio_titular}\")\n",
    "print(f\"nombres_encontrados: {nombre_propio_titular_lista}\")\n",
    "print(f\"genero_nombre_propio_titular: {genero_nombre_propio_titular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cita en el titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-14 20:40:40,618 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-LOC, S-ORG, B-PER, I-PER, E-PER, S-MISC, B-ORG, E-ORG, S-PER, I-ORG, B-LOC, E-LOC, B-MISC, E-MISC, I-MISC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jggomez/Desktop/IRIS/iris-uc3m/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from transformers import pipeline\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Cargar modelo de NER en español (Flair)\n",
    "tagger = SequenceTagger.load(\"flair/ner-spanish-large\")\n",
    "\n",
    "# Modelo opcional Zero-Shot para clasificar citas\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Función para extraer fuentes con NER\n",
    "def extract_sources(text):\n",
    "    sentence = Sentence(text)\n",
    "    tagger.predict(sentence)\n",
    "   \n",
    "    sources = set()\n",
    "    for entity in sentence.get_spans(\"ner\"):\n",
    "        if entity.tag in [\"PER\", \"ORG\"]:  # Solo personas y organizaciones\n",
    "            sources.add(entity.text)\n",
    "   \n",
    "    return list(sources)\n",
    "\n",
    "# Función para extraer citas directas (entre comillas)\n",
    "def extract_explicit_quotes(text):\n",
    "    pattern = r'([\"“][^\"“”]+[\"”])'  # Busca texto entre comillas\n",
    "    quotes = re.findall(pattern, text)\n",
    "    return [{\"source\": \"Desconocido\", \"quote\": quote} for quote in quotes]\n",
    "\n",
    "# Función para extraer citas indirectas junto con su fuente\n",
    "def extract_indirect_quotes(text):\n",
    "    pattern = r'([A-ZÁÉÍÓÚ][a-záéíóú]+(?:\\s[A-ZÁÉÍÓÚ][a-záéíóú]+)?)?\\s*(dijo|afirmó|expresó|mencionó|declaró|aseguró|comentó|indicó)\\s*([^\\.\\n]+)'\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "   \n",
    "    extracted_quotes = []\n",
    "    for match in matches:\n",
    "        source = match[0].strip() if match[0] else \"Desconocido\"\n",
    "        verb = match[1]\n",
    "        quote = match[2].strip()\n",
    "       \n",
    "        extracted_quotes.append({\"source\": source, \"verb\": verb, \"quote\": quote})\n",
    "   \n",
    "    return extracted_quotes\n",
    "\n",
    "# Función para validar con zero-shot classification\n",
    "def validate_with_zero_shot(text):\n",
    "    candidate_labels = [\"cita\", \"sin cita\"]\n",
    "    result = zero_shot_classifier(text, candidate_labels)\n",
    "    return result[\"labels\"][0] == \"cita\"\n",
    "\n",
    "# Función combinada para detectar citas junto con la fuente\n",
    "def detect_and_extract_quotes(text, use_zero_shot=False):\n",
    "    explicit_quotes = extract_explicit_quotes(text)\n",
    "    indirect_quotes = extract_indirect_quotes(text)\n",
    "   \n",
    "    sources = extract_sources(text)\n",
    "\n",
    "    has_quote = bool(explicit_quotes or indirect_quotes)\n",
    "    if not has_quote and use_zero_shot:\n",
    "        has_quote = validate_with_zero_shot(text)\n",
    "   \n",
    "    return {\n",
    "        \"has_quote\": int(has_quote),\n",
    "        \"explicit_quotes\": explicit_quotes,\n",
    "        \"indirect_quotes\": indirect_quotes,\n",
    "        \"sources\": sources\n",
    "    }\n",
    "\n",
    "# Función para resaltar citas y fuentes en HTML\n",
    "def highlight_quotes_html(text):\n",
    "    text = re.sub(r'([\"“][^\"“”]+[\"”])', r'<span class=\"explicit-quote\">\\1</span>', text)\n",
    "    text = re.sub(r'([A-ZÁÉÍÓÚ][a-záéíóú]+(?:\\s[A-ZÁÉÍÓÚ][a-záéíóú]+)?)?\\s*(dijo|afirmó|expresó|mencionó|declaró|aseguró|comentó|indicó)\\s*([^\\.\\n]+)',\n",
    "                  r'<span class=\"source\">\\1</span> <span class=\"verb\">\\2</span> <span class=\"indirect-quote\">\\3</span>', text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pred) Cita en el titular: {'has_quote': 1, 'explicit_quotes': [{'source': 'Desconocido', 'quote': '“espacio”'}], 'indirect_quotes': [], 'sources': []}\n",
      "(Real) Cita en el titular: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .explicit-quote { color: red; font-weight: bold; }\n",
       "    .indirect-quote { color: blue; font-style: italic; }\n",
       "    .source { color: green; font-weight: bold; }\n",
       "    .verb { color: purple; }\n",
       "</style>\n",
       "<p>el papa denuncia la violencia contra las mujeres y reclama más <span class=\"explicit-quote\">“espacio”</span> para ellas en la iglesia</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Detectar y extraer citas\n",
    "quote_info = detect_and_extract_quotes(Titular)\n",
    "print(f\"(Pred) Cita en el titular: {quote_info}\")\n",
    "print(f\"(Real) Cita en el titular: {articulo_raw['cita_en_titulo']}\")\n",
    "\n",
    "# Generar HTML con citas y fuentes resaltadas\n",
    "html_content = f\"\"\"\n",
    "<style>\n",
    "    .explicit-quote {{ color: red; font-weight: bold; }}\n",
    "    .indirect-quote {{ color: blue; font-style: italic; }}\n",
    "    .source {{ color: green; font-weight: bold; }}\n",
    "    .verb {{ color: purple; }}\n",
    "</style>\n",
    "<p>{highlight_quotes_html(Titular)}</p>\n",
    "\"\"\"\n",
    "\n",
    "# Mostrar HTML en Jupyter Notebook\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sexo personas que aparecen en la información (y personas que aparecen en la información)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER (tag de persona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-14 20:40:52,183 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-LOC, S-ORG, B-PER, I-PER, E-PER, S-MISC, B-ORG, E-ORG, S-PER, I-ORG, B-LOC, E-LOC, B-MISC, E-MISC, I-MISC, I-LOC, <START>, <STOP>\n",
      "Nombres detectados: ['Francisco', 'Bergoglio', 'Pontífice', 'María', 'Francisco', 'Pablo VI', 'María', 'Pontífice', 'María', 'Francisco', 'papa', 'Francisco', 'REMO CASILLI', 'Francisco', 'Alessandra Smerilli', 'Francisco', 'Papa', 'Pontífice', 'Francisco']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_first_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Procesar los nombres detectados\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m full_name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[0;32m---> 21\u001b[0m     first_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_first_name\u001b[49m(full_name)  \u001b[38;5;66;03m# Extraer el primer nombre\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     gender \u001b[38;5;241m=\u001b[39m get_gender_with_genderize(first_name)  \u001b[38;5;66;03m# Determinar género\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNombre completo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Género: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgender\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_first_name' is not defined"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "import requests\n",
    "\n",
    "# Configurar el modelo de NER (Reconocimiento de Entidades Nombradas)\n",
    "tagger = SequenceTagger.load(\"flair/ner-spanish-large\")\n",
    "\n",
    "# Procesar el texto con Flair\n",
    "sentence = Sentence(articulo_text)\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# Extraer entidades PERSON\n",
    "names = [entity.text for entity in sentence.get_spans('ner') if entity.tag == \"PER\"]\n",
    "print(\"Nombres detectados:\", names)\n",
    "\n",
    "# Contar géneros\n",
    "genders = {\"male\": 0, \"female\": 0}\n",
    "\n",
    "# Procesar los nombres detectados\n",
    "for full_name in names:\n",
    "    first_name = get_first_name(full_name)  # Extraer el primer nombre\n",
    "    gender = get_gender_with_genderize(first_name)  # Determinar género\n",
    "    print(f\"Nombre completo: {full_name}, Género: {gender}\")\n",
    "    if gender == \"male\":\n",
    "        genders[\"male\"] += 1\n",
    "    elif gender == \"female\":\n",
    "        genders[\"female\"] += 1\n",
    "\n",
    "# Clasificar el género predominante\n",
    "if genders[\"male\"] > 0 and genders[\"female\"] == 0:\n",
    "    category = 0  # Masculino\n",
    "elif genders[\"female\"] > 0 and genders[\"male\"] == 0:\n",
    "    category = 1  # Femenino\n",
    "elif genders[\"male\"] > 0 and genders[\"female\"] > 0:\n",
    "    category = 2  # Mixto\n",
    "else:\n",
    "    category = 3  # Neutro (no se detectaron personas)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"(Pred) Género predominante en la información: {category}\")\n",
    "print(f\"(Real) Género predominante en la información: {articulo_raw['cla_genero_prota']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificación Zero-Shot: mixto\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Configurar modelo Zero-Shot\n",
    "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Etiquetas candidatas\n",
    "candidate_labels = [\"solo hombres\", \"solo mujeres\", \"mixto\", \"neutro\"]\n",
    "\n",
    "# Clasificación Zero-Shot\n",
    "result = zero_shot_classifier(articulo_text, candidate_labels)\n",
    "print(\"Clasificación Zero-Shot:\", result[\"labels\"][0])  # Categoría más probable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Nombre Periodista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_nombre_periodista(articulo: articulo) -> str:\n",
    "    \"\"\"\n",
    "    Extrae autores y limpia textos basura como 'Ver Biografía', 'Redacción', etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista de palabras/frases que NO queremos en el nombre\n",
    "    palabras_basura = [\n",
    "        \"ver biografía\", \"biografía\", \"ver perfil\", \"perfil\", \n",
    "        \"ver más\", \"see profile\", \"read more\", \"twitter\", \n",
    "        \"email\", \"follow\", \"redacción\", \"agencia\"\n",
    "    ]\n",
    "\n",
    "    autores_detectados = []\n",
    "\n",
    "    # 1. Intentar obtener autores desde el parser\n",
    "    if articulo.authors:\n",
    "        for autor in articulo.authors:\n",
    "            autor_limpio = autor.strip()\n",
    "            \n",
    "            # Verificamos si el texto (en minúsculas) contiene alguna palabra basura\n",
    "            if any(basura in autor_limpio.lower() for basura in palabras_basura):\n",
    "                # Si es basura pura (ej: \"Ver Biografía\"), lo ignoramos\n",
    "                # Pero si es \"Lorena Pacho, Ver Biografía\", intentamos limpiarlo\n",
    "                \n",
    "                # Caso específico que te pasó: eliminar \"Ver Biografía\" del string\n",
    "                for basura in palabras_basura:\n",
    "                    # Reemplazamos la basura por vacío, ignorando mayúsculas/minúsculas es complejo,\n",
    "                    # así que hacemos un replace simple de las variantes comunes:\n",
    "                    autor_limpio = autor_limpio.replace(\"Ver Biografía\", \"\")\n",
    "                    autor_limpio = autor_limpio.replace(\"Ver biografía\", \"\")\n",
    "                \n",
    "                autor_limpio = autor_limpio.strip(\" ,|\") # Limpiamos comas o barras sobrantes\n",
    "\n",
    "            # Si después de limpiar queda algo y no es demasiado corto, lo guardamos\n",
    "            if len(autor_limpio) > 2:\n",
    "                autores_detectados.append(autor_limpio)\n",
    "\n",
    "    # 2. Si encontramos autores limpios, los devolvemos\n",
    "    if autores_detectados:\n",
    "        # Eliminamos duplicados usando set() y mantenemos orden\n",
    "        return \", \".join(list(dict.fromkeys(autores_detectados)))\n",
    "\n",
    "    # 3. Fallback: Metadatos (si la lista authors falló o se limpió todo)\n",
    "    meta = articulo.meta_data\n",
    "    claves_meta = ['author', 'og:author', 'dc.creator', 'byl']\n",
    "    \n",
    "    for clave in claves_meta:\n",
    "        valor = meta.get(clave)\n",
    "        if valor:\n",
    "            # A veces los metadatos también traen basura, podrías aplicar limpieza aquí también\n",
    "            return str(valor).strip()\n",
    "\n",
    "    # 4. Defecto\n",
    "    return \"Redacción / Otros\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_periodista: Lorena Pacho\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "nombre_periodista = clasificar_var_nombre_periodista(articulo)\n",
    "print(f\"nombre_periodista: {nombre_periodista}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Género Periodista (Autoría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Optional\n",
    "import re\n",
    "\n",
    "# Modelo de validación estricta\n",
    "class GeneroPeriodistaValidado(BaseModel):\n",
    "    # Field(...) hace el campo obligatorio\n",
    "    # ge=0: Greater or equal to 0\n",
    "    # le=5: Less or equal to 5\n",
    "    codigo: int = Field(..., ge=0, le=7, description=\"Código de clasificación de autoría (0-7)\")\n",
    "\n",
    "\n",
    "def clasificar_var_genero_periodista(nombre_periodista: str, nombre_medio:str) -> int:\n",
    "    \"\"\"\n",
    "    Clasifica la autoría considerando el contexto del medio.\n",
    "    Recibe:\n",
    "      - nombre_periodista: El texto de la firma (ej: \"Redacción\", \"Juan Pérez\")\n",
    "      - nombre_medio: El nombre del periódico donde se publica (ej: \"El País\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validación inicial rápida\n",
    "    if not nombre_periodista or len(nombre_periodista) < 2:\n",
    "        return 0\n",
    "\n",
    "    # Prompt enriquecido con el contexto del medio y definiciones\n",
    "    prompt = f\"\"\"\n",
    "    Contexto:\n",
    "    Noticia publicada en el medio: \"{nombre_medio}\".\n",
    "    Autor/Firma a analizar: \"{nombre_periodista}\".\n",
    "    \n",
    "    Tu misión es clasificar la autoría (0-7) siguiendo estrictamente estas definiciones:\n",
    "\n",
    "    0 = Ns/Nc: Desconocido, ambiguo o iniciales.\n",
    "    1 = Hombre: Nombre de persona masculino.\n",
    "    2 = Mujer: Nombre de persona femenino.\n",
    "    3 = Mixto: Varios autores de distinto género.\n",
    "    4 = Otros medios: El autor es otro medio de comunicación (ej: \"The New York Times\", \"Revista Hola\").\n",
    "    5 = Agencia: Agencias de noticias puras (EFE, Europa Press, Reuters, AFP).\n",
    "    \n",
    "    6 = Redacción (Periodística): \n",
    "        - Firma genérica del propio medio \"{nombre_medio}\" (ej: \"Redacción\", \"El País\", \"Editorial\").\n",
    "        - IMPORTANTE: Si el autor es una empresa comercial que NO es un medio de noticias (como Ford, Apple), NO ES 6.\n",
    "    \n",
    "    7 = Corporativo (Comercial / Institucional): \n",
    "        - Firmado por una empresa comercial, marca de tecnología, coches, banco, etc. (ej: Ford, Meta, Google, BBVA, Zara).\n",
    "        - Firmado por instituciones gubernamentales o ONGs (ej: Gobierno de España, Greenpeace).\n",
    "        - Notas de prensa firmadas por la marca.\n",
    "\n",
    "    INSTRUCCIONES DE PRIORIDAD:\n",
    "    1. Si \"{nombre_periodista}\" es una marca conocida (coches, tech, ropa) -> ELIGE 7.\n",
    "    2. Si \"{nombre_periodista}\" es igual a \"{nombre_medio}\" -> ELIGE 6.\n",
    "    3. Si \"{nombre_periodista}\" es una Agencia conocida -> ELIGE 5.\n",
    "\n",
    "    Responde ÚNICAMENTE con el número dígito (0-7).\n",
    "    \"\"\"\n",
    "    # 1. Llamada al modelo (tu función externa)\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # 2. Extracción del número (Pre-procesamiento)\n",
    "    # Buscamos el primer dígito que aparezca en el texto\n",
    "    match = re.search(r'\\d+', respuesta_texto)\n",
    "    \n",
    "    numero_detectado = int(match.group()) if match else 0\n",
    "\n",
    "    # 3. Validación con Pydantic\n",
    "    try:\n",
    "        # Instanciamos el modelo con el dato detectado\n",
    "        # Si numero_detectado es 9 (alucinación), Pydantic dará error aquí\n",
    "        resultado = GeneroPeriodistaValidado(codigo=numero_detectado)\n",
    "        \n",
    "        # Si llegamos aquí, es un int válido entre 0 y 5\n",
    "        return resultado.codigo\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"Error de validación Pydantic (Dato inválido: {numero_detectado}): {e}\")\n",
    "        return 0 # Default seguro si la IA alucina un número fuera de rango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genero_periodista=2\n"
     ]
    }
   ],
   "source": [
    "# -- Uso -- \n",
    "genero_periodista = clasificar_var_genero_periodista(nombre_periodista=nombre_periodista, nombre_medio=Medio)\n",
    "print(f\"{genero_periodista=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class TemaConExplicacion(BaseModel):\n",
    "    # Validamos que sea un entero entre 0 y 17\n",
    "    codigo: int = Field(..., ge=0, le=17, description=\"Código numérico del tema\")\n",
    "    # Añadimos el campo de explicación\n",
    "    explicacion: str = Field(..., description=\"Breve justificación de por qué se eligió este tema\")\n",
    "\n",
    "def clasificar_var_tema(titulo: str, texto_cuerpo: str) -> TemaConExplicacion:\n",
    "    \"\"\"\n",
    "    Clasifica el tema y da una explicación.\n",
    "    Devuelve un objeto Pydantic con .codigo (int) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Validación rápida\n",
    "    full_text = f\"{titulo} {texto_cuerpo}\"\n",
    "    if not full_text or len(full_text) < 10:\n",
    "        # Devolvemos objeto vacío/error\n",
    "        return TemaConExplicacion(codigo=0, explicacion=\"Texto insuficiente para clasificar.\")\n",
    "\n",
    "    # Recorte para optimizar velocidad\n",
    "    texto_recortado = texto_cuerpo[:1500]\n",
    "    \n",
    "    # 2. Prompt diseñado para JSON\n",
    "    prompt = f\"\"\"\n",
    "    Analiza la noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea es clasificarla en UNA categoría (1-17) y explicar por qué.\n",
    "    \n",
    "    Categorías:\n",
    "    1 = Científica / Investigación\n",
    "    2 = Comunicación\n",
    "    3 = De farándula o espectáculo\n",
    "    4 = Deportiva\n",
    "    5 = Economía (Mercados, inflación, consumo)\n",
    "    6 = Educación/cultura\n",
    "    7 = Empleo/Trabajo\n",
    "    8 = Empresa (Corporativo, negocios)\n",
    "    9 = Judicial\n",
    "    10 = Medioambiente\n",
    "    11 = Policial\n",
    "    12 = Política\n",
    "    13 = Salud\n",
    "    14 = Social\n",
    "    15 = Tecnología\n",
    "    16 = Transporte\n",
    "    17 = Otros\n",
    "\n",
    "    FORMATO DE RESPUESTA OBLIGATORIO (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido con este formato:\n",
    "    {{\n",
    "        \"codigo\": (número entero del 1 al 17),\n",
    "        \"explicacion\": \"(frase breve justificando tu elección)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. Llamada al modelo\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # 4. Limpieza y Parsing de JSON\n",
    "    # A veces los modelos envuelven el JSON en markdown ```json ... ```\n",
    "    # Buscamos donde empieza '{' y termina '}'\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            raise ValueError(\"No se encontró JSON en la respuesta\")\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str) # Convertimos texto a diccionario Python\n",
    "\n",
    "        # 5. Validación Pydantic\n",
    "        resultado = TemaConExplicacion(**data)\n",
    "        return resultado\n",
    "\n",
    "    except (json.JSONDecodeError, ValueError, ValidationError) as e:\n",
    "        print(f\"Error parseando respuesta del modelo: {e}\")\n",
    "        # Retorno de seguridad en caso de fallo\n",
    "        return TemaConExplicacion(codigo=0, explicacion=f\"Error técnico: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Tema: 14\n",
      "Explicación: La noticia trata sobre la denuncia de violencias contra las mujeres, el papel de la mujer en la Iglesia, y la búsqueda de paz y humanidad, lo que lo clasifica claramente como un tema social.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "tema = clasificar_var_tema(articulo.title, articulo.text)\n",
    "print(f\"ID Tema: {tema.codigo}\")\n",
    "print(f\"Explicación: {tema.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12b. Sección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_seccion(articulo: Article) -> str:\n",
    "    \"\"\"\n",
    "    Extrae la sección del periódico basándose en metadatos y la URL.\n",
    "    No usa IA (es más rápido y exacto para este dato estructural).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. BUSCAR EN METADATOS (La fuente más fiable) ---\n",
    "    meta = articulo.meta_data\n",
    "    \n",
    "    # Lista de claves comunes donde los medios guardan la sección\n",
    "    claves_seccion = [\n",
    "        'section',           # Estándar simple\n",
    "        'article:section',   # Protocolo Open Graph (Facebook/LinkedIn)\n",
    "        'og:section',        # Variación Open Graph\n",
    "        'category',          # WordPress y CMS comunes\n",
    "        'dc.subject',        # Dublin Core standard\n",
    "        'ut.section'         # Algunos medios custom\n",
    "    ]\n",
    "\n",
    "    for clave in claves_seccion:\n",
    "        valor = meta.get(clave)\n",
    "        # A veces el valor es una lista, tomamos el primero\n",
    "        if isinstance(valor, list):\n",
    "            valor = valor[0]\n",
    "        \n",
    "        if valor and isinstance(valor, str) and len(valor) > 2:\n",
    "            return valor.strip().title() # Ej: \"DEPORTES \" -> \"Deportes\"\n",
    "\n",
    "    # --- 2. BUSCAR EN LA URL (Si no hay metadatos) ---\n",
    "    # Ejemplo: https://www.elmundo.es/economia/2024/02/10/noticia.html\n",
    "    # Queremos extraer \"economia\"\n",
    "    \n",
    "    path = urlparse(articulo.url).path\n",
    "    segmentos = path.split('/')\n",
    "    \n",
    "    # Filtramos segmentos vacíos\n",
    "    segmentos = [s for s in segmentos if s]\n",
    "\n",
    "    for segmento in segmentos:\n",
    "        # Ignoramos segmentos que son años (4 dígitos) o muy cortos (idiomas 'es', 'en')\n",
    "        if re.match(r'^\\d{4}$', segmento): # Es un año (2024)\n",
    "            continue\n",
    "        if re.match(r'^\\d{1,2}$', segmento): # Es un día o mes (10, 02)\n",
    "            continue\n",
    "        if len(segmento) <= 2: # Es un código de idioma (es, en, cat)\n",
    "            continue\n",
    "        if segmento in ['noticia', 'articulo', 'story', 'news']: # Palabras genéricas\n",
    "            continue\n",
    "            \n",
    "        # Si pasa los filtros, asumimos que es la sección\n",
    "        # Reemplazamos guiones por espacios (ej: \"ciencia-y-salud\" -> \"Ciencia Y Salud\")\n",
    "        return segmento.replace('-', ' ').title()\n",
    "\n",
    "    # --- 3. DEFECTO ---\n",
    "    return \"General\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección detectada: Sociedad\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "seccion = clasificar_var_seccion(articulo)\n",
    "print(f\"Sección detectada: {seccion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02/2026 - Variables específicas IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. IA tema central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IaTemaCentralConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No es tema central, 2=Sí es tema central\")\n",
    "    # Campo nuevo\n",
    "    explicacion: str = Field(..., description=\"Justificación de la jerarquía de la información\")\n",
    "\n",
    "def clasificar_var_ia_tema_central(titulo: str, texto_cuerpo: str) -> IaTemaCentralConExplicacion:\n",
    "    \"\"\"\n",
    "    Determina si la Inteligencia Artificial es el TEMA CENTRAL de la noticia.\n",
    "    Devuelve objeto con .codigo y .explicacion.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    palabras_clave_ia = [\n",
    "        \"inteligencia artificial\", \"artificial intelligence\", \"ia \", \"ai \", \n",
    "        \"chatgpt\", \"gpt\", \"llm\", \"machine learning\", \"aprendizaje automático\",\n",
    "        \"red neuronal\", \"deep learning\", \"midjourney\", \"dall-e\", \"bard\", \"gemini\",\n",
    "        \"copilot\", \"algoritmo generativo\", \"sam altman\", \"openai\", \"nvidia\"\n",
    "    ]\n",
    "    \n",
    "    # Si ninguna palabra clave está presente, asumimos directamente que NO (1)\n",
    "    if not any(palabra in texto_completo for palabra in palabras_clave_ia):\n",
    "        return IaTemaCentralConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos relacionados con la Inteligencia Artificial.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    # Recortamos texto para centrar la atención en el inicio (donde suele estar el tema central)\n",
    "    texto_recortado = texto_cuerpo[:2500]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la jerarquía de la información en esta noticia:\n",
    "    \n",
    "    TÍTULO: \"{titulo}\"\n",
    "    TEXTO: \"{texto_recortado}...\"\n",
    "\n",
    "    Objetivo: Determinar si la Inteligencia Artificial (IA) es el TEMA PRINCIPAL y PROTAGONISTA.\n",
    "    \n",
    "    Criterios de clasificación:\n",
    "\n",
    "    1 = No (Mención secundaria / Otro tema):\n",
    "        - La IA se menciona al final o de pasada.\n",
    "        - Es un discurso (Papa, Políticos) sobre varios temas y la IA es solo uno más.\n",
    "        - La IA es una herramienta secundaria (ej: \"Policía usa IA para un robo\", el tema es el robo).\n",
    "        - El Título NO menciona tecnología o IA.\n",
    "\n",
    "    2 = Sí (Tema Central):\n",
    "        - La noticia gira completamente en torno a la IA (avances, regulación, peligros, inversiones).\n",
    "        - La IA es el sujeto principal del Título.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Breve justificación analizando si la IA es protagonista o secundaria)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        # Buscamos el bloque JSON\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return IaTemaCentralConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación Pydantic\n",
    "        return IaTemaCentralConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        # Fallback seguro\n",
    "        return IaTemaCentralConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: La noticia se centra en el discurso del Papa Francisco sobre la violencia contra las mujeres, el papel de la mujer en la Iglesia y la necesidad de 'espacio' para ellas. La IA se menciona brevemente al final, en relación a la asamblea del sínodo, pero no es el tema principal ni el protagonista de la noticia.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "ia_tema_central = clasificar_var_ia_tema_central(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {ia_tema_central.codigo}\")\n",
    "print(f\"Razón: {ia_tema_central.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Explicación sobre el significado de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IaSignificadoConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No explica significado, 2=Sí explica significado\")\n",
    "    # Campo nuevo\n",
    "    explicacion: str = Field(..., description=\"Justificación: ¿Hay definiciones técnicas o es solo mención?\")\n",
    "\n",
    "def clasificar_var_significado_ia(titulo: str, texto_cuerpo: str) -> IaSignificadoConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si el artículo explica o define QUÉ ES la IA o CÓMO FUNCIONA.\n",
    "    Devuelve un objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Si no hay palabras \"inteligencia\" o \"algoritmo\", difícilmente explicará qué son.\n",
    "    keywords_tecnicas = [\"inteligencia\", \"ia \", \"ai \", \"algoritmo\", \"red neuronal\", \"modelo de lenguaje\"]\n",
    "    \n",
    "    if not any(k in texto_completo for k in keywords_tecnicas):\n",
    "        return IaSignificadoConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos técnicos básicos para ofrecer una definición de IA.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT EN FORMATO JSON ---\n",
    "    # Recortamos el texto (buscamos definiciones, suelen estar al principio)\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente texto periodístico con enfoque pedagógico:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si el artículo contiene una EXPLICACIÓN o DEFINICIÓN sobre qué es la Inteligencia Artificial (IA) o cómo funciona técnicamente.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No (Mera mención o uso):\n",
    "        - El artículo habla de herramientas (ChatGPT, Bard) o noticias de empresas sin explicar qué son.\n",
    "        - Habla de \"la IA\" como un sujeto abstracto (\"la IA cambiará el mundo\") sin definirla.\n",
    "        - Ej: \"Google lanzó su nueva IA ayer\". Aquí NO se aprende qué es la tecnología.\n",
    "\n",
    "    2 = Sí (Didáctico / Definitorio):\n",
    "        - El texto tiene intención educativa.\n",
    "        - Contiene frases tipo: \"La IA generativa funciona prediciendo el siguiente token...\", \"Los LLM son modelos entrenados con...\".\n",
    "        - Explica la diferencia técnica entre tipos de IA.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Breve frase justificando si hay definiciones técnicas o solo menciones)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        # Buscamos el bloque JSON por si el modelo añade texto extra\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return IaSignificadoConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación con Pydantic\n",
    "        return IaSignificadoConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return IaSignificadoConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: El artículo menciona el uso de la IA a través de referencias al Papa Francisco y sus discursos, pero no ofrece ninguna definición técnica o explicación de cómo funciona la IA.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "significado_ia = clasificar_var_significado_ia(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {significado_ia.codigo}\")\n",
    "print(f\"Razón: {significado_ia.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Se menciona la IA en algún momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MencionIaConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No menciona IA, 2=Sí menciona IA\")\n",
    "    # Explicación generada automáticamente por Python\n",
    "    explicacion: str = Field(..., description=\"Justificación exacta (qué palabra o sigla se encontró)\")\n",
    "\n",
    "\n",
    "def clasificar_var_menciona_ia(titulo: str, texto_cuerpo: str) -> MencionIaConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si se menciona la IA y lista TODAS las palabras clave encontradas.\n",
    "    Usa Regex y palabras clave (No requiere Ollama).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = f\"{titulo} \\n {texto_cuerpo}\"\n",
    "    texto_lower = texto_completo.lower()\n",
    "    \n",
    "    # Creamos un conjunto (set) para evitar palabras repetidas\n",
    "    palabras_encontradas = set()\n",
    "    \n",
    "    # --- 1. BÚSQUEDA DE CONCEPTOS CLAROS ---\n",
    "    palabras_clave = [\n",
    "        \"inteligencia artificial\", \"artificial intelligence\",\n",
    "        \"machine learning\", \"aprendizaje automático\", \"deep learning\",\n",
    "        \"redes neuronales\", \"chatgpt\", \"generative ai\", \"ia generativa\",\n",
    "        \"openai\", \"midjourney\", \"dall-e\", \"bard\", \"gemini\", \"copilot\",\n",
    "        \"large language model\", \" llm \", \"algoritmos generativos\",\n",
    "        \"sam altman\", \"sora\", \"claude 3\", \"llama 3\", \"mistral\",\n",
    "        \"vision pro\", \"neuralink\"\n",
    "    ]\n",
    "    \n",
    "    # Iteramos sobre todas las palabras y si están, las añadimos al set\n",
    "    for frase in palabras_clave:\n",
    "        if frase in texto_lower:\n",
    "            palabras_encontradas.add(frase.strip()) # strip para quitar espacios de \" llm \"\n",
    "\n",
    "    # --- 2. BÚSQUEDA DE SIGLAS \"IA\" o \"AI\" (Case Sensitive) ---\n",
    "    # Usamos re.findall para encontrar TODAS las ocurrencias, no solo la primera\n",
    "    patron_siglas = r'\\b(IA|AI|I\\.A\\.|A\\.I\\.)\\b'\n",
    "    coincidencias_siglas = re.findall(patron_siglas, texto_completo)\n",
    "    \n",
    "    # Añadimos las siglas encontradas al conjunto\n",
    "    for sigla in coincidencias_siglas:\n",
    "        palabras_encontradas.add(sigla)\n",
    "\n",
    "    # --- 3. CONSTRUCCIÓN DE RESPUESTA ---\n",
    "    \n",
    "    # Si el conjunto tiene elementos, es un SÍ (2)\n",
    "    if palabras_encontradas:\n",
    "        # Convertimos el set a una lista ordenada y la unimos con comas\n",
    "        lista_final = \", \".join(sorted(palabras_encontradas))\n",
    "        return MencionIaConExplicacion(\n",
    "            codigo=2,\n",
    "            explicacion=lista_final\n",
    "        )\n",
    "\n",
    "    # Si el conjunto está vacío, es un NO (1)\n",
    "    return MencionIaConExplicacion(\n",
    "        codigo=1,\n",
    "        explicacion=\"No se encontraron términos, siglas ni conceptos relacionados con la Inteligencia Artificial en el texto.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 2\n",
      "Razón: inteligencia artificial\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "menciona_ia = clasificar_var_menciona_ia(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {menciona_ia.codigo}\")\n",
    "print(f\"Razón: {menciona_ia.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Referencias en la noticia a políticas en materia de género e igualdad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenciaPoliticasGeneroConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No referencia políticas, 2=Sí referencia políticas de género\")\n",
    "    # Campo nuevo para el razonamiento\n",
    "    explicacion: str = Field(..., description=\"Justificación de la decisión\")\n",
    "\n",
    "\n",
    "def clasificar_var_referencia_politicas_genero(titulo: str, texto_cuerpo: str) -> ReferenciaPoliticasGeneroConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si la noticia hace referencia a POLÍTICAS, LEYES o DEBATES sobre \n",
    "    género, igualdad, feminismo o violencia machista.\n",
    "    Devuelve objeto con .codigo y .explicacion.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos y limpiamos texto para el filtro\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "    \n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    raices_clave = [\n",
    "        \"igualdad\", \"género\", \"genero\", \"femin\", \"mujer\", \"machis\", \n",
    "        \"brecha\", \"paridad\", \"sexis\", \"patriarca\", \"trans \", \"lgtbi\",\n",
    "        \"conciliación\", \"techo de cristal\", \"violencia vicaria\", \"víctima\",\n",
    "        \"ley\", \"ministerio\", \"protesta\", \"derechos\" # Añadido contexto político/legal\n",
    "    ]\n",
    "    \n",
    "    # Verificamos si hay al menos una palabra de género Y contexto político/social\n",
    "    # (Simplificado: si no hay ninguna raíz clave, descartamos).\n",
    "    if not any(raiz in texto_completo for raiz in raices_clave):\n",
    "        return ReferenciaPoliticasGeneroConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos clave relacionados con género, igualdad o políticas sociales.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT ESPECÍFICO (Modo JSON) ---\n",
    "    # Recortamos el texto para no saturar el contexto\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la siguiente noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si el texto hace referencia a POLÍTICAS DE GÉNERO, LEYES DE IGUALDAD o DEBATES SOBRE DERECHOS DE LA MUJER.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    1 = No:\n",
    "        - La mujer es mencionada solo como protagonista de un hecho (ej: \"La alcaldesa inauguró la feria\").\n",
    "        - Sucesos o crímenes sin contexto social/legal.\n",
    "    \n",
    "    2 = Sí:\n",
    "        - Menciona leyes, cuotas, paridad o medidas gubernamentales sobre igualdad.\n",
    "        - Habla de violencia machista/género como problema estructural o legal.\n",
    "        - Trata sobre feminismo, 8M, brecha salarial o discriminación laboral.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Frase breve justificando si se trata de política/derechos o es solo una mención circunstancial)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. Llamada al modelo ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. Procesamiento JSON ---\n",
    "    try:\n",
    "        # Buscamos el JSON dentro de la respuesta (por si el modelo añade texto extra)\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            # Fallback si no hay JSON\n",
    "            return ReferenciaPoliticasGeneroConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación final con Pydantic\n",
    "        return ReferenciaPoliticasGeneroConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return ReferenciaPoliticasGeneroConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 2\n",
      "Razón: El texto aborda la violencia contra las mujeres como un problema estructural, refiriéndose a la necesidad de 'espacio' para las mujeres en la Iglesia y a la importancia de 'cuidarlas, valorarlas' y 'ser generativa a través de una pastoral hecha de cuidado y solicitud'. Además, menciona la influencia de documentos como la encíclica Lumen Gentium, vinculada al Concilio Vaticano II, y el papel de María como modelo, directamente relacionado con la defensa de los derechos de la mujer.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "referencia_politicas_genero = clasificar_var_referencia_politicas_genero(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {referencia_politicas_genero.codigo}\")\n",
    "print(f\"Razón: {referencia_politicas_genero.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Denuncia a la desigualdad de género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenunciaDesigualdadConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No denuncia, 2=Sí denuncia desigualdad\")\n",
    "    # Nueva explicación\n",
    "    explicacion: str = Field(..., description=\"Justificación de por qué se considera denuncia o no\")\n",
    "\n",
    "\n",
    "def clasificar_var_denuncia_desigualdad_genero(titulo: str, texto_cuerpo: str) -> DenunciaDesigualdadConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si la noticia DENUNCIA desigualdad y explica por qué.\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "    \n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    palabras_activadoras = [\n",
    "        \"desigualdad\", \"discriminaci\", \"brecha\", \"violencia\", \"machis\", \n",
    "        \"patriarca\", \"acos\", \"abus\", \"víctima\", \"feminici\", \"sexismo\",\n",
    "        \"techo de cristal\", \"precariedad\", \"injusticia\", \"derechos de las mujeres\",\n",
    "        \"igualdad real\", \"conciliación\", \"paridad\"\n",
    "    ]\n",
    "    \n",
    "    # Si NO hay palabras clave, retornamos 1 directamente con explicación automática\n",
    "    if not any(p in texto_completo for p in palabras_activadoras):\n",
    "        return DenunciaDesigualdadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=\"El texto no contiene términos relacionados con género, desigualdad o violencia machista.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT PARA JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza el enfoque de esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea es determinar si el texto DENUNCIA o VISIBILIZA un problema de desigualdad de género.\n",
    "\n",
    "    Criterios:\n",
    "    1 = No (Neutro/Sucesos): Solo narra hechos sin crítica social, o habla de mujeres exitosas sin mencionar dificultades de género.\n",
    "    2 = Sí (Denuncia/Crítica): Critica el machismo, aporta datos de brechas, denuncia violencia sistémica o cubre protestas feministas.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Frase breve justificando si hay denuncia social o es meramente informativo)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA A OLLAMA ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. PROCESAMIENTO DE RESPUESTA ---\n",
    "    try:\n",
    "        # Limpieza de bloques de código markdown si los hay\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            # Fallback si el modelo no devuelve JSON\n",
    "            return DenunciaDesigualdadConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación Pydantic\n",
    "        return DenunciaDesigualdadConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        # Si algo falla en el parseo, devolvemos un objeto seguro\n",
    "        return DenunciaDesigualdadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 2\n",
      "Razón: El texto denuncia la violencia contra las mujeres y, específicamente, la necesidad de que la Iglesia dé más 'espacio' a las mujeres, invocando la figura de María como modelo.  Se refiere a la 'violación de Dios' causada por la violencia contra mujeres y al imperativo de que la Iglesia se 'redescubra su rostro femenino', indicando una crítica a las estructuras y prácticas que perpetúan la desigualdad de género.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "denuncia_desigualdad_genero = clasificar_var_denuncia_desigualdad_genero(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {denuncia_desigualdad_genero.codigo}\")\n",
    "print(f\"Razón: {denuncia_desigualdad_genero.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Presencia de mujeres racializadas en la noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujeresRacializadasConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No aparecen, 2=Sí aparecen mujeres racializadas\")\n",
    "    # Justificación\n",
    "    explicacion: str = Field(..., description=\"Detalle sobre quiénes son las mujeres detectadas y su contexto étnico\")\n",
    "\n",
    "def clasificar_var_mujeres_racializadas_noticias(titulo: str, texto_cuerpo: str) -> MujeresRacializadasConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta la presencia o mención de mujeres racializadas (no blancas/caucásicas) en la noticia.\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Buscamos términos que sugieran diversidad étnica, racial o contextos migratorios.\n",
    "    # Si no aparece NADA de esto, asumimos que se habla de mujeres blancas o el tema no es racial.\n",
    "    \n",
    "    terminos_clave = [\n",
    "        \"racializada\", \"negra\", \"afro\", \"etnia\", \"raza\", \"indígena\", \n",
    "        \"gitana\", \"romaní\", \"latina\", \"hispana\", \"asiática\", \"árabe\", \n",
    "        \"musulmana\", \"morocc\", \"marroquí\", \"subsahariana\", \"migrante\", \n",
    "        \"refugiada\", \"islam\", \"velo\", \"hijab\", \"mestiza\", \"mulata\",\n",
    "        \"origen\", \"nacionalidad\", \"extranjera\", \"diversidad\"\n",
    "    ]\n",
    "    \n",
    "    # Nota: Este filtro es laxo para no descartar falsos negativos, \n",
    "    # pero ayuda a limpiar noticias de política nacional estándar (ej: Ayuso, Montero).\n",
    "    if not any(t in texto_completo for t in terminos_clave):\n",
    "        return MujeresRacializadasConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene marcadores explícitos de diversidad étnica o racial.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la representación de las personas en esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si en la noticia aparecen, se mencionan o protagonizan **MUJERES RACIALIZADAS**.\n",
    "    \n",
    "    Definición de \"Mujer Racializada\" para este análisis:\n",
    "    Mujeres que son percibidas socialmente como no blancas en un contexto occidental. Incluye:\n",
    "    - Mujeres negras / afrodescendientes.\n",
    "    - Mujeres latinas / sudamericanas.\n",
    "    - Mujeres asiáticas.\n",
    "    - Mujeres árabes / magrebíes / musulmanas (contexto cultural-étnico).\n",
    "    - Mujeres indígenas.\n",
    "    - Mujeres gitanas / romaníes.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No:\n",
    "        - Solo aparecen mujeres blancas / caucásicas (ej: políticas europeas, actrices de Hollywood blancas).\n",
    "        - No se menciona el origen étnico y por el contexto se asume hegemonía blanca.\n",
    "        - Se habla de \"inmigrantes\" en general sin especificar mujeres.\n",
    "\n",
    "    2 = Sí:\n",
    "        - Aparece explícitamente una mujer descrita por su etnia u origen (ej: \"la activista afroamericana\", \"la cantante colombiana\").\n",
    "        - Se menciona a una figura pública conocida por ser racializada (ej: Kamala Harris, Rihanna, Salma Hayek, Zendaya) aunque no se diga su raza explícitamente en el texto.\n",
    "        - Noticias sobre colectivos específicos (ej: \"Las mujeres afganas\", \"Las temporeras marroquíes\").\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Indica qué mujer o colectivo racializado se ha detectado y por qué)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt, modelo=\"gemma:4b\")\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return MujeresRacializadasConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        return MujeresRacializadasConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return MujeresRacializadasConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: El texto no contiene marcadores explícitos de diversidad étnica o racial.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "mujeres_racializadas_noticias = clasificar_var_mujeres_racializadas_noticias(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {mujeres_racializadas_noticias.codigo}\")\n",
    "print(f\"Razón: {mujeres_racializadas_noticias.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Presencia de mujeres con discapacidad en la noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujeresConDiscapacidadConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No aparecen, 2=Sí aparecen mujeres con discapacidad\")\n",
    "    # Justificación\n",
    "    explicacion: str = Field(..., description=\"Detalle sobre quiénes son las mujeres detectadas y su contexto de discapacidad\")\n",
    "\n",
    "def clasificar_var_mujeres_con_discapacidad_noticias(titulo: str, texto_cuerpo: str) -> MujeresConDiscapacidadConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta la presencia o mención explícita de mujeres con discapacidad o diversidad funcional.\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Palabras clave que sugieren discapacidad, diversidad funcional o condiciones específicas.\n",
    "    # Si no aparece ninguna, descartamos la noticia.\n",
    "    \n",
    "    terminos_clave = [\n",
    "        \"discapacidad\", \"diversidad funcional\", \"silla de ruedas\", \"movilidad reducida\",\n",
    "        \"ciega\", \"sorda\", \"sordomuda\", \"invidente\", \"autis\", \" tea \", \"asperger\",\n",
    "        \"síndrome de down\", \"parálisis\", \"cerebral\", \"amputada\", \"prótesis\",\n",
    "        \"salud mental\", \"trastorno\", \"bipolar\", \"esquizofren\", \"depresio\", # En contextos de discapacidad psicosocial\n",
    "        \"dependencia\", \"capacitism\", \"paralímpic\", \"once\", \"cermi\"\n",
    "    ]\n",
    "    \n",
    "    if not any(t in texto_completo for t in terminos_clave):\n",
    "        return MujeresConDiscapacidadConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos relacionados con la discapacidad o diversidad funcional.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la representación de las personas en esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si en la noticia aparecen, se mencionan o protagonizan **MUJERES CON DISCAPACIDAD**.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No:\n",
    "        - Se menciona discapacidad, pero en HOMBRES (ej: \"El atleta paralímpico ganó el oro\").\n",
    "        - Se usan términos metafóricos (ej: \"La justicia es ciega\", \"parálisis política\").\n",
    "        - Son lesiones temporales (ej: \"La jugadora se rompió la pierna y estará baja un mes\").\n",
    "        - Se habla de discapacidad en general (leyes, barreras) sin mencionar a ninguna mujer o colectivo femenino específico.\n",
    "\n",
    "    2 = Sí:\n",
    "        - Aparece una mujer (o niña) con discapacidad física, sensorial, intelectual o psicosocial.\n",
    "        - Se habla de colectivos específicos (ej: \"Las mujeres con discapacidad sufren más violencia\").\n",
    "        - Se menciona a deportistas paralímpicas, activistas con diversidad funcional, etc.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Indica quién es la mujer y cuál es su discapacidad o contexto)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    # Gemma 4b suele ser bueno distinguiendo género en estos contextos\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return MujeresConDiscapacidadConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        return MujeresConDiscapacidadConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return MujeresConDiscapacidadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: El texto no contiene términos relacionados con la discapacidad o diversidad funcional.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "mujeres_con_discapacidad_noticias = clasificar_var_mujeres_con_discapacidad_noticias(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {mujeres_con_discapacidad_noticias.codigo}\")\n",
    "print(f\"Razón: {mujeres_con_discapacidad_noticias.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Presencia de diversidad generacional en las mujeres que aparecen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujeresGeneracionalidadConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No hay diversidad generacional, 2=Sí hay diversidad (niñas, ancianas o mezcla)\")\n",
    "    # Justificación\n",
    "    explicacion: str = Field(..., description=\"Detalle de las edades o generaciones identificadas en la noticia\")\n",
    "\n",
    "def clasificar_var_mujeres_generacionalidad_noticias(titulo: str, texto_cuerpo: str) -> MujeresGeneracionalidadConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si en la noticia aparecen mujeres de **distintas generaciones** o de \n",
    "    **edades no hegemónicas** (niñas, adolescentes o ancianas).\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Buscamos marcadores de edad extremos o relaciones intergeneracionales.\n",
    "    # Si no aparecen, asumimos que son adultos estándar (lo más común en noticias).\n",
    "    \n",
    "    terminos_edad = [\n",
    "        # Infancia / Juventud\n",
    "        \"niña\", \"adolescente\", \"joven\", \"menor\", \"escolar\", \"alumna\", \"estudiante\", \n",
    "        \"chica\", \"hija\", \"infantil\", \"bebé\", \"generación z\",\n",
    "        # Vejez / Tercera Edad\n",
    "        \"anciana\", \"abuela\", \"jubilada\", \"mayor\", \"tercera edad\", \"senior\", \n",
    "        \"vejez\", \"pensionista\", \"octogenaria\", \"nonagenaria\", \"vieja\", \"residencia\",\n",
    "        # Relacional\n",
    "        \"madre\", \"nieta\", \"familia\", \"generaciones\", \"intergeneracional\"\n",
    "    ]\n",
    "    \n",
    "    if not any(t in texto_completo for t in terminos_edad):\n",
    "        return MujeresGeneracionalidadConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos que sugieran diversidad de edades (niñas, ancianas) o relaciones intergeneracionales.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la edad y las generaciones de las mujeres en esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si hay **DIVERSIDAD GENERACIONAL** en la representación femenina.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No (Representación Estándar):\n",
    "        - Solo aparecen mujeres adultas en edad laboral típica (aprox 25-60 años). Ej: Políticas, profesionales, empresarias.\n",
    "        - Se menciona \"madre\" solo como dato biográfico sin relevancia en la historia (ej: \"es madre de dos hijos\").\n",
    "        - No se especifica la edad y se asume adultez.\n",
    "\n",
    "    2 = Sí (Diversidad / Edades no hegemónicas):\n",
    "        - Aparecen **Niñas o Adolescentes** con voz propia o como protagonistas.\n",
    "        - Aparecen **Mujeres Mayores / Ancianas / Jubiladas** (Visibilidad de la tercera edad).\n",
    "        - Hay un enfoque **Intergeneracional**: Se habla de madres e hijas, abuelas y nietas, o el impacto de un tema en distintas generaciones de mujeres.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Indica qué edades o relación generacional se ha detectado)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    # Usamos Gemma 4b (o tu modelo preferido)\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return MujeresGeneracionalidadConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        return MujeresGeneracionalidadConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return MujeresGeneracionalidadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: La noticia se centra en el Papa Francisco y en su visión sobre el papel de la mujer en la Iglesia. Si bien se menciona el papel de María y de las madres, no hay ninguna mención explícita a niñas, adolescentes o mujeres mayores. La representación femenina se limita a la figura de la Virgen y a la referencia general a las madres sin detalles sobre sus edades o generaciones.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "mujeres_generacionalidad_noticias = clasificar_var_mujeres_generacionalidad_noticias(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {mujeres_generacionalidad_noticias.codigo}\")\n",
    "print(f\"Razón: {mujeres_generacionalidad_noticias.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Tiene fotografías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FotografiasValidadas(BaseModel):\n",
    "    # Variable 1: ¿Tiene fotos? (1=No, 2=Sí)\n",
    "    tiene_fotos_codigo: int = Field(..., ge=1, le=2, description=\"1=No, 2=Sí\")\n",
    "    \n",
    "    # Variable 2: Número exacto de fotos\n",
    "    cantidad: int = Field(..., ge=0, description=\"Número total de fotografías detectadas\")\n",
    "\n",
    "def clasificar_var_fotografias(articulo: Article) -> FotografiasValidadas:\n",
    "    \"\"\"\n",
    "    Analiza las imágenes REALES (editoriales) de la noticia.\n",
    "    Combina la imagen principal (top_image) + imágenes insertadas en el texto,\n",
    "    filtrando iconos, logotipos y publicidad.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Usamos un set para evitar duplicados de URL\n",
    "    imagenes_reales = set()\n",
    "    \n",
    "    # 1. IMAGEN DE PORTADA (TOP IMAGE)\n",
    "    # Es la más importante. Si existe, la añadimos.\n",
    "    if articulo.top_image:\n",
    "        imagenes_reales.add(articulo.top_image)\n",
    "\n",
    "    # 2. IMÁGENES DEL CUERPO (CLEAN_TOP_NODE)\n",
    "    # En lugar de buscar en todo el HTML, buscamos solo en el nodo que \n",
    "    # newspaper ha detectado como \"cuerpo de la noticia\".\n",
    "    nodo_texto = articulo.clean_top_node \n",
    "    \n",
    "    if nodo_texto is not None:\n",
    "        # Buscamos todas las etiquetas <img> dentro del texto limpio\n",
    "        imgs_en_texto = nodo_texto.xpath('.//img')\n",
    "        \n",
    "        for img in imgs_en_texto:\n",
    "            src = img.get('src')\n",
    "            if not src:\n",
    "                continue\n",
    "                \n",
    "            src_lower = src.lower()\n",
    "            \n",
    "            # --- FILTROS ANTI-BASURA ---\n",
    "            \n",
    "            # A. Descartar formatos que suelen ser elementos de interfaz\n",
    "            if src_lower.endswith('.svg') or src_lower.endswith('.gif') or src_lower.endswith('.ico'):\n",
    "                continue\n",
    "                \n",
    "            # B. Descartar palabras clave de elementos web (no noticias)\n",
    "            palabras_prohibidas = [\n",
    "                'logo', 'icon', 'avatar', 'profile', 'pixel', 'spacer', \n",
    "                'doubleclick', 'adserver', 'banner', 'button', 'social',\n",
    "                'facebook', 'twitter', 'whatsapp', 'share'\n",
    "            ]\n",
    "            \n",
    "            if any(palabra in src_lower for palabra in palabras_prohibidas):\n",
    "                continue\n",
    "\n",
    "            # C. Descartar por tamaño (si el atributo existe en el HTML)\n",
    "            # Muchos iconos son 1x1, 16x16, etc.\n",
    "            width = img.get('width')\n",
    "            height = img.get('height')\n",
    "            if width and width.isdigit() and int(width) < 50:\n",
    "                continue\n",
    "            if height and height.isdigit() and int(height) < 50:\n",
    "                continue\n",
    "\n",
    "            # Si pasa los filtros, es una foto editorial válida\n",
    "            imagenes_reales.add(src)\n",
    "\n",
    "    # 3. CONTEO Y CÓDIGO\n",
    "    cantidad_final = len(imagenes_reales)\n",
    "    \n",
    "    # Si hay al menos 1 foto, el código es 2 (Sí). Si es 0, es 1 (No).\n",
    "    codigo_final = 2 if cantidad_final > 0 else 1\n",
    "\n",
    "    # 4. RETORNO SEGURO\n",
    "    try:\n",
    "        return FotografiasValidadas(\n",
    "            tiene_fotos_codigo=codigo_final,\n",
    "            cantidad=cantidad_final\n",
    "        )\n",
    "    except ValidationError:\n",
    "        # Fallback por seguridad\n",
    "        return FotografiasValidadas(tiene_fotos_codigo=1, cantidad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiene_fotografías: 2\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "tiene_fotografías = clasificar_var_fotografias(articulo).tiene_fotos_codigo\n",
    "print(f\"tiene_fotografías: {tiene_fotografías}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Número de fotografías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero_fotografias: 3\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "numero_fotografias = clasificar_var_fotografias(articulo).cantidad\n",
    "print(f\"numero_fotografias: {numero_fotografias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Tiene Fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Número de Fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Utiliza Fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pred) Cita en el titular: {'has_quote': 1, 'explicit_quotes': [{'source': 'Desconocido', 'quote': '\"La felicidad, de la que se habla mucho, es una actitud\"'}], 'indirect_quotes': [], 'sources': ['Agatha', 'Naoko Takeuchi', 'Moria Casán', 'Nerea', 'Carlos Latre', 'Protección Civil', 'Nerea Luis', 'Nacho', 'Fangoria', 'Fundación Inspiring Girls', 'Agatha Ruiz de la Prada', 'Sole Giménez', 'Alaska']}\n",
      "(Real) Cita en el titular: 1\n",
      "Citas directas: [{'source': 'Desconocido', 'quote': '\"La felicidad, de la que se habla mucho, es una actitud\"'}]\n",
      "Citas indirectas: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .explicit-quote { color: red; font-weight: bold; }\n",
       "    .indirect-quote { color: blue; font-style: italic; }\n",
       "    .source { color: green; font-weight: bold; }\n",
       "    .verb { color: purple; }\n",
       "</style>\n",
       "<p>La mayoría de foros femeninos ponen de manifiesto la falta de mujeres referentes para las generaciones más jóvenes. Acciones como las que lleva a cabo la Fundación Inspiring Girls, que ha galardonado a Alaska con el premio Mujer Inspiración Pionera, intentan paliar esta situación. Hablamos con ella.\n",
       "\n",
       "Sole Giménez: <span class=\"explicit-quote\">\"La felicidad, de la que se habla mucho, es una actitud\"</span>\n",
       "\n",
       "Hace unos días se presentaba en el Jardín Botánico de Madrid la nueva edición del proyecto Inspiring Stories by Evax, un libro ilustrado que recoge historias de mujeres increíbles para inspirar a las jóvenes y que hagan realidad sus sueños, sin ningún tipo de límites. El libro se presentó en el marco de la gala de los premios Inspiring Girls en los que Alaska recibió el premio Mujer Inspiración Pionera. Además de ella, fueron galardonados Carlos Latre, premio Hombre Inspirador, y la diseñadora Agatha Ruiz de la Prada, premio Inspiración Artística.\n",
       "\n",
       "Acabas de cumplir 58 años. ¿Estás en el mejor momento de tu vida?\n",
       "\n",
       "No lo sé, porque habrá que ver lo que viene después. Estaba mejor a los 50, eso lo tengo clarísimo, física y mentalmente. Aunque eso no quiere decir que no pueda estar mejor a los 68...\n",
       "\n",
       "¿Cambiarías algo de tu trayectoria profesional?\n",
       "\n",
       "No, es la que yo he elegido con mis aciertos y mis errores. Y son MIS aciertos y MIS errores.\n",
       "\n",
       "Acabas de publicar con Fangoria 'Existencialismo pop'. ¿Qué vamos a encontrar de nuevo en esta propuesta musical?\n",
       "\n",
       "Como su título indica es pop, pero con algo más, en las letras y en la producción. Es un álbum que ha surgido fruto del momento que vivimos.\n",
       "\n",
       "En la canción 'Momentismo absoluto', apostáis por el 'carpe diem'. ¿No nos queda otra?\n",
       "\n",
       "No es que no nos quede otra, es que es la vida. Al escuchar esta canción, todo el mundo la ha asociado a la pandemia, pero Nacho y yo pensamos en la vida. Nosotros somos un ejemplo de personas que en su carrera y en su vida han vivido así, al día, a lo que hay en cada momento.\n",
       "\n",
       "¿Cómo surgió la historia de este tema?\n",
       "\n",
       "Surgió por una frase de la genial vedette, cantante, actriz y presentadora argentina Moria Casán. Le hicieron una entrevista en la que ella estaba hablando de su vida sentimental y contestó que estaba en el ''momentismo absoluto'\". Nos pareció que reflejaba muy bien lo que queríamos contar.\n",
       "\n",
       "En el libro 'Inspiring Stories by Evax', ¿cuál de las siete historias te ha llegado más o te ha resultado más sorprendente?\n",
       "\n",
       "La que más me llama la atención, por envidia insana, es la historia de la programadora de inteligencia artificial (IA) Nerea Luis. Lo más alucinante es que decide hacerse ingeniera gracias a Sailor Moon [personaje de la serie manga escrita e ilustrada por Naoko Takeuchi]. ¡Me parece maravilloso! Nos dicen que el manga, el cómic o lo pop no son inspiradores, que hay otras disciplinas más profundas, pero la inspiración está en cualquier sitio. Nerea, con 13 años, siendo fan de Sailor, se mete en internet a buscar información sobre ella, se da cuenta de que casi no hay y de que la que hay no está bien organizada. Entonces se pone a hacerlo ella. ¡Le tengo mucha envidia!\n",
       "\n",
       "¿Qué les dirías a las niñas que tienen una clara vocación profesional, sea la que sea, bombero o policía, para que no abandonen su sueño?\n",
       "\n",
       "Que piensen en esa vocación como una afición, que a lo mejor no se van a dedicar profesionalmente a ello, que quizás no van a vivir de eso... pero no tienen que abandonar su sueño. Yo sigo considerando que tengo una afición por la que a veces me pagan y otras me cuesta mucho dinero. No creo que puedas ser bombero como hobby, o quizás sí, trabajando como voluntario de Protección Civil en tus horas libres. Las vocaciones se pueden materializar siempre, no hay que frustrarse si no se convierten en una profesión. Si eso sucede, es un regalo. Así que, ¡adelante!\n",
       "\n",
       "También eres una de las galardonadas de los premios de la Fundación Inspiring Girls, ¿cuál crees que ha sido tu mensaje para recibir esta distinción?\n",
       "\n",
       "Con mi edad es muy fácil decirlo porque hay una trayectoria y podemos pararnos en muchos momentos de la historia de este país a través de la televisión y la música. Creo que se lo dan a mi yo de 14 años, que decide crear un grupo de música por las tardes, después del colegio, e iniciar lo que ella considera que es la vida real para así crear su mundo paralelo.\n",
       "\n",
       "Estás junto a grandes amigas, como Agatha Ruiz de la Prada. ¿Qué destacarías de esta artista multidisciplinar?\n",
       "\n",
       "Tiene una trayectoria impresionante, pero yo me voy a la Agatha que conocí en los 80: esa chica que estaba esperando poder hacer sus diseños poniendo un hula-hoop a una falda y desfilando. Es una persona que ha sido dueña de su carrera y, quizás, las prendas que diseñaba no eran lo que su familia y la sociedad esperaban de ella. Yo recuerdo sus principios y lo que ella hace es un reflejo de lo que ella es.\n",
       "\n",
       "¿Qué mensaje le darías a las jóvenes que no saben qué hacer con su vida o que dudan sobre los estudios a elegir?\n",
       "\n",
       "Es algo en lo que es muy difícil aconsejar. Es muy fácil decirle a alguien que se dedique a lo que le gusta. Lo que me pasa últimamente es que te encuentras con mucha gente que no sabe ni lo que le gusta y ahí... ¡me desarman! Mi problema es poder elegir, hay muchas cosas que quiero hacer. Quizás ellas no han encontrado al profesor o a la persona adecuada que les descubra un nuevo mundo. Yo les diría que presten atención y que tengan los oídos y los ojos muy abiertos.\n",
       "\n",
       "Por último... ¿Un mensaje o consejo para que ellas sean dueñas de su vida?\n",
       "\n",
       "Primero, no pidas consejos. Te tiene que importar cero lo que opinen los demás, ya sea con la mejor o la peor intención. No escuches consejos que no has pedido y lo que tengas en mente, hazlo. ¡Y punto!\n",
       "\n",
       ".\n",
       "\n",
       "Conforme a los criterios de\n",
       "\n",
       "The Trust Project\n",
       "\n",
       "Saber más</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Detectar y extraer citas\n",
    "quote_info = detect_and_extract_quotes(articulo_text)\n",
    "print(f\"(Pred) Cita en el titular: {quote_info}\")\n",
    "print(f\"(Real) Cita en el titular: {articulo['Cita_en_titular']}\")\n",
    "\n",
    "print(\"Citas directas:\", quote_info['explicit_quotes'])\n",
    "print(\"Citas indirectas:\", quote_info['indirect_quotes'])\n",
    "\n",
    "# Generar HTML con citas y fuentes resaltadas\n",
    "html_content = f\"\"\"\n",
    "<style>\n",
    "    .explicit-quote {{ color: red; font-weight: bold; }}\n",
    "    .indirect-quote {{ color: blue; font-style: italic; }}\n",
    "    .source {{ color: green; font-weight: bold; }}\n",
    "    .verb {{ color: purple; }}\n",
    "</style>\n",
    "<p>{highlight_quotes_html(articulo_text)}</p>\n",
    "\"\"\"\n",
    "\n",
    "# Mostrar HTML en Jupyter Notebook\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Escribe el número de declaraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pred) Total declaraciones: 1\n",
      "(Real) Total declaraciones: 11\n"
     ]
    }
   ],
   "source": [
    "# Contar declaraciones\n",
    "num_explicit_quotes = len(quote_info['explicit_quotes'])\n",
    "num_implicit_quotes = len(quote_info['indirect_quotes'])\n",
    "total_quotes = num_explicit_quotes + num_implicit_quotes\n",
    "print(\"(Pred) Total declaraciones:\", total_quotes)\n",
    "print(\"(Real) Total declaraciones:\", articulo['ndeclaracion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Género persona declara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Tipo de fuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. Biografía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
