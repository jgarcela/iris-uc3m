{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258b7daf",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ollama serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a33d46",
   "metadata": {},
   "source": [
    "## Test simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "047879e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm DeepSeek-R1-Lite-Preview, an AI assistant created by DeepSeek. I provide helpful, honest answers across various domains while maintaining a formal tone.\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "\n",
    "response = completion(\n",
    "    model=\"ollama/deepseek-r1:32b\", \n",
    "    messages=[{ \"content\": \"respond in 20 words. who are you?\",\"role\": \"user\"}], \n",
    "    api_base=\"http://localhost:11434\"\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6a172",
   "metadata": {},
   "source": [
    "## Test agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5d03dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El análisis del sesgo de género en el texto \"Las mujeres son malas conductoras\" se puede realizar de la siguiente manera:\n",
      "\n",
      "1. **Uso de términos generalizadores**: La frase utiliza \"las mujeres\", que refiere a todas las mujeres sin considerar individualidades, lo que puede contribuir a una percepción estereotipada.\n",
      "\n",
      "2. **Judicialidad negativa**: El término \"malas\" se emplea para calificar las habilidades de conducción, lo que puede reforzar la idea de que las mujeres son incompetentes en este ámbito.\n",
      "\n",
      "3. **Especificación del género en el rol**: La palabra \"conductoras\" relaciona directamente el género femenino con una supuesta incapacidad, refiriendo a mujeres como si fueran inherentemente peores conductoras que los hombres.\n",
      "\n",
      "Este tipo de lenguaje puede perpetuar estereotipos y sesgos de género al vincular negativamente la condición femenina con una actividad considerada tradicionalmente masculina.\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Inicializamos el modelo local\n",
    "ollama_model = Ollama(model=\"ollama/deepseek-r1:32b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "# Creamos un agente con CrewAI\n",
    "agent = Agent(\n",
    "    role='Analyst',\n",
    "    goal='Analizar el texto y detectar sesgos de género',\n",
    "    backstory=\"Eres un experto en igualdad y lenguaje inclusivo.\",\n",
    "    llm=ollama_model\n",
    ")\n",
    "\n",
    "# Creamos una tarea\n",
    "task = Task(\n",
    "    description=\"Analiza el siguiente texto: 'Las mujeres son malas conductoras.'\",\n",
    "    expected_output=\"Un análisis del sesgo de género en el texto.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "# Ejecutamos el crew (puede ser un solo agente o varios)\n",
    "crew = Crew(agents=[agent], tasks=[task])\n",
    "result = crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0702b04",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m _input \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat_prompt(texto\u001b[38;5;241m=\u001b[39mtext)\n\u001b[1;32m     72\u001b[0m output \u001b[38;5;241m=\u001b[39m ollama_model\u001b[38;5;241m.\u001b[39minvoke(_input\u001b[38;5;241m.\u001b[39mto_string())\n\u001b[0;32m---> 73\u001b[0m structured \u001b[38;5;241m=\u001b[39m output_parser\u001b[38;5;241m.\u001b[39mparse(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(structured)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# === 1. Modelo local ===\n",
    "ollama_model = Ollama(model=\"deepseek-r1:32b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "# === 2. Variables ===\n",
    "VARIABLES = [\n",
    "    'cita_textual_titular', 'genero_nombre_propio_titular', 'genero_periodista',\n",
    "    'genero_personas_mencionadas', 'nombre_propio_titular', 'personas_mencionadas', 'tema'\n",
    "]\n",
    "\n",
    "CITA_TITULAR = {'0': 'No', '1': 'Sí'}\n",
    "GENERO_NOMBRE_PROPIO_TITULAR = {'1': 'No hay', '2': 'Sí, hombre', '3': 'Sí, mujer', '4': 'Sí, mujer y hombre'}\n",
    "GENERO_PERIODISTA = {'1': 'Masculino', '2': 'Femenino', '3': 'Mixto', '4': 'Ns/Nc', '5': 'Agencia/otros medios', '6': 'Redacción', '7': 'Corporativo'}\n",
    "GENERO_PERSONAS_MENCIONADAS = {'1': 'No hay', '2': 'Sí, hombre', '3': 'Sí, mujer', '4': 'Sí, mujer y hombre'}\n",
    "TEMA = {'1': 'Científica/Investigación', '2': 'Comunicación', '3': 'De farándula o espectáculo', '4': 'Deportiva', '5': 'Economía', '6': 'Educación/cultura', '7': 'Empleo/Trabajo', '8': 'Empresa', '9': 'Judicial', '10': 'Medioambiente', '11': 'Policial', '12': 'Política', '13': 'Salud', '14': 'Social', '15': 'Tecnología', '16': 'Transporte', '17': 'Otros'}\n",
    "\n",
    "# === 3. Esquema ===\n",
    "schemas = [\n",
    "    ResponseSchema(\n",
    "        name=var,\n",
    "        description=\"Objeto con 'codigo' (string) y 'evidencia' (lista de fragmentos textuales que justifican el valor).\"\n",
    "    )\n",
    "    for var in VARIABLES\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# === 4. Prompt ===\n",
    "template_parts = [\n",
    "    \"Analiza el siguiente texto periodístico y clasifícalo según las variables de CONTENIDO_GENERAL.\",\n",
    "    \"\",\n",
    "    \"Texto:\",\n",
    "    \"{texto}\",\n",
    "    \"\",\n",
    "    \"Para cada variable, devuelve un objeto con:\",\n",
    "    '- \"codigo\": el número correspondiente según las tablas (no inventes etiquetas ni palabras).',\n",
    "    '- \"evidencia\": lista de fragmentos textuales del texto que justifican el valor.',\n",
    "    \"\",\n",
    "    \"Usa *exclusivamente* los siguientes valores numéricos:\",\n",
    "    f\"CITA_TITULAR = {list(CITA_TITULAR.keys())}\",\n",
    "    f\"GENERO_NOMBRE_PROPIO_TITULAR = {list(GENERO_NOMBRE_PROPIO_TITULAR.keys())}\",\n",
    "    f\"GENERO_PERIODISTA = {list(GENERO_PERIODISTA.keys())}\",\n",
    "    f\"GENERO_PERSONAS_MENCIONADAS = {list(GENERO_PERSONAS_MENCIONADAS.keys())}\",\n",
    "    f\"TEMA = {list(TEMA.keys())}\",\n",
    "    \"\",\n",
    "    \"Ejemplo de formato esperado:\",\n",
    "    \"{{\",\n",
    "    '  \"cita_textual_titular\": {{\"codigo\": \"1\", \"evidencia\": [\"\\'María López presentó un estudio\\'\"]}},',\n",
    "    '  \"genero_personas_mencionadas\": {{\"codigo\": \"4\", \"evidencia\": [\"María López\", \"Juan Pérez\"]}}',\n",
    "    \"}}\",\n",
    "    \"\",\n",
    "    \"{format_instructions}\"\n",
    "]\n",
    "\n",
    "template = \"\\n\".join(template_parts)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"texto\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "# === 5. Texto de prueba ===\n",
    "text = \"\"\"La científica María López presentó un nuevo estudio sobre inteligencia artificial,\n",
    "pero el titular mencionó solo a su colega Juan Pérez.\"\"\"\n",
    "\n",
    "_input = prompt.format_prompt(texto=text)\n",
    "output = ollama_model.invoke(_input.to_string())\n",
    "structured = output_parser.parse(output.content)\n",
    "print(structured)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0047a6",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc395cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_822382/3128448210.py:25: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  react_agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the `genderize_name` tool to determine the probable gender for each name.\n",
      "Action: genderize_name\n",
      "Action Input: María\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'name': 'María', 'gender': 'female', 'probability': 0.99, 'count': 97652}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I know the gender of María.\n",
      "Action: genderize_name\n",
      "Action Input: Juan\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'name': 'Juan', 'gender': 'male', 'probability': 0.99, 'count': 2143485}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I know the gender of Juan.\n",
      "Final Answer: María es femenino y Juan es masculino.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "María es femenino y Juan es masculino.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import requests\n",
    "\n",
    "# === Tool: genderize.io ===\n",
    "@tool(\"genderize_name\")\n",
    "def genderize_name(name: str) -> str:\n",
    "    \"\"\"Dado un nombre de pila, devuelve el género probable usando genderize.io.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(\"https://api.genderize.io\", params={\"name\": name}, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        # Resumimos para mostrar información útil\n",
    "        return str({\n",
    "            \"name\": data.get(\"name\"),\n",
    "            \"gender\": data.get(\"gender\"),\n",
    "            \"probability\": data.get(\"probability\"),\n",
    "            \"count\": data.get(\"count\"),\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return f\"Error consultando genderize: {e}\"\n",
    "\n",
    "# === Agente con herramientas (ReAct) ===\n",
    "tools = [genderize_name]\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=ollama_model,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Ejemplo de uso\n",
    "query = \"Usa la herramienta para predecir el género de 'María' y 'Juan'.\"\n",
    "react_result = react_agent.invoke({\"input\": query})\n",
    "print(react_result[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d34182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out who Marie Curie is and summarize her information in two sentences. I should use the `wikipedia_search` tool for this.\n",
      "Action: wikipedia_search\n",
      "Action Input: \"Marie Curie\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Marie Curie\n",
      "Summary: Maria Salomea Skłodowska-Curie,​​ más conocida como Marie Curie​​ o Madame Curie (Varsovia, 7 de noviembre de 1867-Passy, 4 de julio de 1934), fue una física y química de origen polaco. Pionera en el campo de la radiactividad, es la primera y única persona en recibir dos premios Nobel en distintas especialidades científicas: Física y Química.​ También fue la primera mujer en ocupar el puesto de profesora en la Universidad de París y la primera en recibir sepultura con honores en el Panteón de París por méritos propios en 1995.​\n",
      "Nació en Varsovia, en lo que entonces era el Zarato de Polonia (territorio administrado por el Imperio ruso). Estudió clandestinamente en la «universidad flotante» de Varsovia y comenzó su formación científica en dicha ciudad. En 1891, a los 24 años, siguió a su hermana mayor Bronisława Dłuska a París, donde culminó sus estudios y llevó a cabo sus trabajos científicos más sobresalientes. Compartió el premio Nobel de Física de 1903 con su marido Pierre Curie y el físico Henri Becquerel. Años después, ganó en solitario el premio Nobel de Química de 1911. Aunque recibió la ciudadanía francesa y apoyó a su nueva patria, nunca perdió su identidad polaca: enseñó a sus hijas su lengua materna y las llevaba a sus visitas a Polonia.​ Nombró el primer elemento químico que descubrió, el polonio, como su país de origen.​\n",
      "Sus logros incluyen los primeros estudios sobre el fenómeno de la radiactividad (término que ella misma acuñó),​​​ técnicas para el aislamiento de isótopos radiactivos y el descubrimiento de dos elementos —el polonio y el radio—. Bajo su dirección, se llevaron a cabo los primeros estudios en el tratamiento de neoplasias con isótopos radiactivos. Fundó el Instituto Curie en París y en Varsovia, que se mantienen entre los principales centros de investigación médica en la actualidad. Durante la Primera Guerra Mundial creó los primeros centros radiológicos para uso militar. Murió en 1934 a los 66 años, en el sanato\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Marie Curie fue una física y química de origen polaco que fue pionera en el campo de la radiactividad y recibió dos premios Nobel en distintas especialidades científicas: Física y Química. También fundó el Instituto Curie.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Marie Curie fue una física y química de origen polaco que fue pionera en el campo de la radiactividad y recibió dos premios Nobel en distintas especialidades científicas: Física y Química. También fundó el Instituto Curie.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# === Tool: Wikipedia (ES) ===\n",
    "wiki = WikipediaAPIWrapper(lang=\"es\", top_k_results=3, doc_content_chars_max=2000)\n",
    "\n",
    "@tool(\"wikipedia_search\")\n",
    "def wikipedia_search(query: str) -> str:\n",
    "    \"\"\"Busca en Wikipedia (es) y devuelve un resumen de los mejores resultados.\"\"\"\n",
    "    try:\n",
    "        result = wiki.run(query)\n",
    "        return result if isinstance(result, str) else str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error en Wikipedia: {e}\"\n",
    "\n",
    "# === Agente con herramientas (incluye Wikipedia) ===\n",
    "tools = [genderize_name, wikipedia_search]\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=ollama_model,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Ejemplo de uso\n",
    "query = \"Busca en Wikipedia quién es 'Marie Curie' y resume en 2 frases.\"\n",
    "react_result = react_agent.invoke({\"input\": query})\n",
    "print(react_result[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f9e44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5f5f7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5842f15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b70afded",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
