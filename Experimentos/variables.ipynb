{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook sirve para probar la clasificación de variables de manera automática en base al documento de **Protocolo de Variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0a. Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import re\n",
    "from typing import Optional, List, Any, Dict\n",
    "import json\n",
    "\n",
    "def consultar_ollama(\n",
    "    prompt: str, \n",
    "    modelo: str = \"gemma3:4b\", \n",
    "    formato: str = \"json\",  # Forzamos JSON por defecto\n",
    "    temperature: float = 0.1 # Bajo para ser preciso/determinista\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Envía un prompt a Ollama con soporte para formato JSON y temperatura.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configuramos las opciones avanzadas\n",
    "        opciones = {\n",
    "            'temperature': temperature,\n",
    "            'num_ctx': 8192,       # <--- ESTO ES LO IMPORTANTE. Ampliamos la memoria a ~32k caracteres.\n",
    "            'num_predict': 1024,   # Reservamos espacio suficiente para la respuesta JSON\n",
    "        }\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=modelo,\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            format=formato,  # Esto es CLAVE: fuerza al modelo a devolver JSON estructura\n",
    "            options=opciones\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error conectando con el modelo {modelo}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0b. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_N_noticia</th>\n",
       "      <th>IdNoticia</th>\n",
       "      <th>Medio_num</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>año</th>\n",
       "      <th>año_agrupado</th>\n",
       "      <th>Caracteres</th>\n",
       "      <th>Titular</th>\n",
       "      <th>nombre_propio_titular</th>\n",
       "      <th>cita_en_titulo</th>\n",
       "      <th>...</th>\n",
       "      <th>no_MES</th>\n",
       "      <th>no_Contenido</th>\n",
       "      <th>no_Pagina_url</th>\n",
       "      <th>no_verificacion</th>\n",
       "      <th>no_textonoticia</th>\n",
       "      <th>antiguo_genero_protagonistas</th>\n",
       "      <th>emocion_ia</th>\n",
       "      <th>IA_razonamiento_titulares</th>\n",
       "      <th>no_vacio_numero_caracteres</th>\n",
       "      <th>contenido_articulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>4515</td>\n",
       "      <td>el papa denuncia la violencia contra las mujer...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>“quien lastima a una mujer profana a dios”, ha...</td>\n",
       "      <td>https://elpais.com/sociedad/2024-01-01/el-papa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>el papa francisco ha denunciado la violencia c...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>El Papa (hombre)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El papa Francisco ha denunciado la violencia c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>4880</td>\n",
       "      <td>inteligencia artificial: agárrense, que vienen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>los despidos masivos de una industria tan rent...</td>\n",
       "      <td>https://elpais.com/babelia/2024-01-01/intelige...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>baldur’s gate 3, zelda: tears of the kingdom, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artículos estrictamente de opinión que respond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>9052</td>\n",
       "      <td>en 2024 votarán miles de millones de personas ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>la concentración de procesos electorales en un...</td>\n",
       "      <td>https://elpais.com/tecnologia/2024-01-01/en-20...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>durante el año 2024, el calendario electoral s...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Una persona antes de coger una papeleta para e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>2523</td>\n",
       "      <td>estupidez artificial</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lo tenebroso no son las nuevas formas de traba...</td>\n",
       "      <td>https://elpais.com/opinion/2024-01-02/estupide...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lo que da miedo de 2024 no es la inteligencia ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lo tenebroso no son las nuevas formas de traba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>3177</td>\n",
       "      <td>la última navidad</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>los lectores escriben sobre la ilusión de los ...</td>\n",
       "      <td>https://elpais.com/opinion/2024-01-02/la-ultim...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>estoy triste. sé positivamente que esta ha sid...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los lectores escriben sobre la ilusión de los ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>7111</td>\n",
       "      <td>j995</td>\n",
       "      <td>7</td>\n",
       "      <td>18/01/2017</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1631</td>\n",
       "      <td>Un ‘pezrobot’ tan realista que puede filmar pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.lavanguardia.com/natural/20180322/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No hay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La mayoría de los peces robot no se encuentran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>7112</td>\n",
       "      <td>j996</td>\n",
       "      <td>7</td>\n",
       "      <td>18/01/2017</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2553</td>\n",
       "      <td>YouTube prioriza contenido extremista</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.lavanguardia.com/tecnologia/201803...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YouTube (empresas).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>7113</td>\n",
       "      <td>j997</td>\n",
       "      <td>7</td>\n",
       "      <td>05/01/2017</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4599</td>\n",
       "      <td>Estos son los retos del futuro de la automoción</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.lavanguardia.com/motor/20180226/44...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No hay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El futuro del coche conectado en Volkswagen es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>7114</td>\n",
       "      <td>j998</td>\n",
       "      <td>1</td>\n",
       "      <td>18/01/2017</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>6479</td>\n",
       "      <td>Lucía Velasco, tecnóloga: \"Hay 15s que recomie...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.elmundo.es/yodona/lifestyle/2021/1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucía Velasco (mujer).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tú crees que eso de los algoritmos no va conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>7115</td>\n",
       "      <td>j999</td>\n",
       "      <td>1</td>\n",
       "      <td>12/01/2017</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>6082</td>\n",
       "      <td>Valencia Digital Summit 2021:el referente tecn...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>https://www.elmundo.es/tecnologia/innovacion/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valencia Digital Summit 2021 (evento/entidad).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L'Oceanogràfic de Valencia acogió las ponencia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7115 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_N_noticia IdNoticia  Medio_num       Fecha   año  año_agrupado  \\\n",
       "0                1         1          2  01/01/2024  2024             2   \n",
       "1                2         2          2  01/01/2024  2024             2   \n",
       "2                3         3          2  01/01/2024  2024             2   \n",
       "3                4         4          2  02/01/2024  2024             2   \n",
       "4                5         5          2  02/01/2024  2024             2   \n",
       "...            ...       ...        ...         ...   ...           ...   \n",
       "7110          7111      j995          7  18/01/2017  2018             1   \n",
       "7111          7112      j996          7  18/01/2017  2018             1   \n",
       "7112          7113      j997          7  05/01/2017  2018             1   \n",
       "7113          7114      j998          1  18/01/2017  2021             1   \n",
       "7114          7115      j999          1  12/01/2017  2021             1   \n",
       "\n",
       "      Caracteres                                            Titular  \\\n",
       "0           4515  el papa denuncia la violencia contra las mujer...   \n",
       "1           4880  inteligencia artificial: agárrense, que vienen...   \n",
       "2           9052  en 2024 votarán miles de millones de personas ...   \n",
       "3           2523                               estupidez artificial   \n",
       "4           3177                                  la última navidad   \n",
       "...          ...                                                ...   \n",
       "7110        1631  Un ‘pezrobot’ tan realista que puede filmar pe...   \n",
       "7111        2553              YouTube prioriza contenido extremista   \n",
       "7112        4599    Estos son los retos del futuro de la automoción   \n",
       "7113        6479  Lucía Velasco, tecnóloga: \"Hay 15s que recomie...   \n",
       "7114        6082  Valencia Digital Summit 2021:el referente tecn...   \n",
       "\n",
       "      nombre_propio_titular  cita_en_titulo  ...  no_MES  \\\n",
       "0                         2               2  ...     1.0   \n",
       "1                         1               1  ...     1.0   \n",
       "2                         1               1  ...     1.0   \n",
       "3                         1               1  ...     1.0   \n",
       "4                         1               1  ...     1.0   \n",
       "...                     ...             ...  ...     ...   \n",
       "7110                      1               1  ...     NaN   \n",
       "7111                      5               1  ...     NaN   \n",
       "7112                      1               1  ...     NaN   \n",
       "7113                      3               2  ...     NaN   \n",
       "7114                      5               1  ...     NaN   \n",
       "\n",
       "                                           no_Contenido  \\\n",
       "0     “quien lastima a una mujer profana a dios”, ha...   \n",
       "1     los despidos masivos de una industria tan rent...   \n",
       "2     la concentración de procesos electorales en un...   \n",
       "3     lo tenebroso no son las nuevas formas de traba...   \n",
       "4     los lectores escriben sobre la ilusión de los ...   \n",
       "...                                                 ...   \n",
       "7110                                                  x   \n",
       "7111                                                  x   \n",
       "7112                                                  x   \n",
       "7113                                                  x   \n",
       "7114                                                  x   \n",
       "\n",
       "                                          no_Pagina_url  no_verificacion  \\\n",
       "0     https://elpais.com/sociedad/2024-01-01/el-papa...              1.0   \n",
       "1     https://elpais.com/babelia/2024-01-01/intelige...              1.0   \n",
       "2     https://elpais.com/tecnologia/2024-01-01/en-20...              1.0   \n",
       "3     https://elpais.com/opinion/2024-01-02/estupide...              1.0   \n",
       "4     https://elpais.com/opinion/2024-01-02/la-ultim...              1.0   \n",
       "...                                                 ...              ...   \n",
       "7110  https://www.lavanguardia.com/natural/20180322/...              NaN   \n",
       "7111  https://www.lavanguardia.com/tecnologia/201803...              NaN   \n",
       "7112  https://www.lavanguardia.com/motor/20180226/44...              NaN   \n",
       "7113  https://www.elmundo.es/yodona/lifestyle/2021/1...              NaN   \n",
       "7114  https://www.elmundo.es/tecnologia/innovacion/2...              NaN   \n",
       "\n",
       "                                        no_textonoticia  \\\n",
       "0     el papa francisco ha denunciado la violencia c...   \n",
       "1     baldur’s gate 3, zelda: tears of the kingdom, ...   \n",
       "2     durante el año 2024, el calendario electoral s...   \n",
       "3     lo que da miedo de 2024 no es la inteligencia ...   \n",
       "4     estoy triste. sé positivamente que esta ha sid...   \n",
       "...                                                 ...   \n",
       "7110                                                NaN   \n",
       "7111                                                NaN   \n",
       "7112                                                NaN   \n",
       "7113                                                NaN   \n",
       "7114                                                NaN   \n",
       "\n",
       "      antiguo_genero_protagonistas  emocion_ia  \\\n",
       "0                                3         5.0   \n",
       "1                                4         7.0   \n",
       "2                                1         7.0   \n",
       "3                                1         6.0   \n",
       "4                                1         3.0   \n",
       "...                            ...         ...   \n",
       "7110                             4         NaN   \n",
       "7111                             3         NaN   \n",
       "7112                             4         NaN   \n",
       "7113                             2         NaN   \n",
       "7114                             3         NaN   \n",
       "\n",
       "                           IA_razonamiento_titulares  \\\n",
       "0                                   El Papa (hombre)   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "7110                                         No hay.   \n",
       "7111                             YouTube (empresas).   \n",
       "7112                                         No hay.   \n",
       "7113                          Lucía Velasco (mujer).   \n",
       "7114  Valencia Digital Summit 2021 (evento/entidad).   \n",
       "\n",
       "      no_vacio_numero_caracteres  \\\n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "7110                         NaN   \n",
       "7111                         NaN   \n",
       "7112                         NaN   \n",
       "7113                         NaN   \n",
       "7114                         NaN   \n",
       "\n",
       "                                     contenido_articulo  \n",
       "0     El papa Francisco ha denunciado la violencia c...  \n",
       "1     Artículos estrictamente de opinión que respond...  \n",
       "2     Una persona antes de coger una papeleta para e...  \n",
       "3     Lo tenebroso no son las nuevas formas de traba...  \n",
       "4     Los lectores escriben sobre la ilusión de los ...  \n",
       "...                                                 ...  \n",
       "7110  La mayoría de los peces robot no se encuentran...  \n",
       "7111                                                NaN  \n",
       "7112  El futuro del coche conectado en Volkswagen es...  \n",
       "7113  Tú crees que eso de los algoritmos no va conti...  \n",
       "7114  L'Oceanogràfic de Valencia acogió las ponencia...  \n",
       "\n",
       "[7115 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import newspaper\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "\n",
    "SUFFIX = \"scrape\"\n",
    "data = pd.read_csv(f\"../data/2026_02_10_imio_def_todo_envio_heidy.xlsx - 2026_02_09_imio_def_todo_clara_{SUFFIX}.csv\")\n",
    "# data = pd.read_csv(\"../data/Base de datos Noticias 27102025.xlsx - Noticias_scrape.csv\")\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_N_noticia                                                                         1\n",
      "IdNoticia                                                                            1\n",
      "Medio_num                                                                            2\n",
      "Fecha                                                                       01/01/2024\n",
      "año                                                                               2024\n",
      "año_agrupado                                                                         2\n",
      "Caracteres                                                                        4515\n",
      "Titular                              el papa denuncia la violencia contra las mujer...\n",
      "nombre_propio_titular                                                                2\n",
      "cita_en_titulo                                                                       2\n",
      "cla_genero_prota                                                                     3\n",
      "nombre_periodista                                                         Lorena Pacho\n",
      "genero_periodista                                                                    2\n",
      "Tema_recodificado                                                                   12\n",
      "no_tema                                                                             12\n",
      "ia_tema_central                                                                    1.0\n",
      "significado_ia                                                                     1.0\n",
      "menciona_ia                                                                        2.0\n",
      "referencia_politicas_genero                                                        2.0\n",
      "denuncia_desigualdad_genero                                                          2\n",
      "mujeres_racializadas_noticias                                                      1.0\n",
      "mujeres_con_discapacidad_noticias                                                  1.0\n",
      "mujeres_generacionalidad_noticias                                                  1.0\n",
      "tiene_fotografias                                                                  2.0\n",
      "numero_fotografias                                                                 3.0\n",
      "utiliza_fuente                                                                     2.0\n",
      "numero_declaraciones                                                               1.0\n",
      "lenguaje_sexista                                                                   2.0\n",
      "masc_generico                                                                      1.0\n",
      "hombre_denominar_humanidad                                                         1.0\n",
      "uso_dual_zorr                                                                      1.0\n",
      "uso_cargo_mujer                                                                    1.0\n",
      "sexismo_discurso                                                                   2.0\n",
      "androcentrismo                                                                     1,0\n",
      "mencion_nombre_investigadora                                                       1.0\n",
      "asimetria_mujer_hombre                                                             1.0\n",
      "disminutivos_infantilizacion                                                       1.0\n",
      "denominacion_sexualizada                                                           1,0\n",
      "denominacion_redundante                                                            1.0\n",
      "denominacion_dependiente                                                           1.0\n",
      "criterios_excepcion                                                                1.0\n",
      "comparacion_mujer_hombre                                                           1.0\n",
      "no_NombreUsuario                                                                UCM3 6\n",
      "no_Autor                                                                  Lorena Pacho\n",
      "no_MES                                                                             1.0\n",
      "no_Contenido                         “quien lastima a una mujer profana a dios”, ha...\n",
      "no_Pagina_url                        https://elpais.com/sociedad/2024-01-01/el-papa...\n",
      "no_verificacion                                                                    1.0\n",
      "no_textonoticia                      el papa francisco ha denunciado la violencia c...\n",
      "antiguo_genero_protagonistas                                                         3\n",
      "emocion_ia                                                                         5.0\n",
      "IA_razonamiento_titulares                                             El Papa (hombre)\n",
      "no_vacio_numero_caracteres                                                         NaN\n",
      "contenido_articulo                   El papa Francisco ha denunciado la violencia c...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "articulo_raw = data[data['IdNoticia'] == \"1\"].iloc[0]\n",
    "print(articulo_raw)\n",
    "\n",
    "# articulo_raw = data[data['IdNoticia'] == 46].iloc[0]\n",
    "# print(articulo_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texto del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El papa Francisco ha denunciado la violencia contra las mujeres en la misa del día de Año Nuevo, y ha defendido que la Iglesia debe darle más espacio a ellas y “redescubrir su rostro femenino”. “Quien lastima a una mujer profana a Dios, nacido de mujer”, condenó Bergoglio. Y recordó: “Toda sociedad necesita acoger el don de la mujer, de cada mujer: respetarla, cuidarla, valorarla”.\\n\\nEl día 1 de enero el cristianismo dedica el día a la Virgen, por eso el Pontífice abrió el año con una misa en la basílica en la que ensalzó el papel de María y de la mujer en la Iglesia. Francisco hizo referencia en su discurso a textos papales, como la encíclica Lumen gentium (1964) que Pablo VI escribió en el revolucionario Concilio Vaticano II, y señaló que “la Iglesia necesita de María para redescubrir su propio rostro femenino, para asemejarse más a ella que, como mujer, Virgen y Madre, representa su modelo y su figura perfecta; para dar espacio a las mujeres y para ser generativa a través de una pastoral hecha de cuidado y solicitud, de paciencia y valentía materna”.\\n\\nEl Pontífice habló también del resto del mundo durante la misa solemne y ante la plana mayor de la curia romana, otras autoridades y los miles de fieles congregados en el templo: “También el mundo necesita mirar a las madres y a las mujeres para encontrar la paz, para escapar de las espirales de violencia y odio, y volver a tener miradas humanas y corazones que ven”.\\n\\n“Nuestro tiempo, vacío de paz, necesita de una Madre que vuelva a reunir a la familia humana. Miremos a María para ser constructores de unidad”, insistió Francisco.\\n\\nEl papa Francisco, durante el rezo del Ángelus desde el Palacio Apostólico Vaticano, este lunes. REMO CASILLI (REUTERS)\\n\\nDurante su pontificado, Francisco ha dado pasos para ampliar las responsabilidades de la mujer en la Iglesia y ha nombrado a varias mujeres en puestos de dirección en la curia. Por ejemplo, la religiosa italiana Alessandra Smerilli fue nombrada en 2021 subsecretaria del dicasterio para el Servicio del Desarrollo Humano Integral, el cargo más alto ocupado por una mujer en la Santa Sede.\\n\\nEste año además se ha celebrado la asamblea del primer sínodo de la Iglesia en el que las mujeres y los laicos tienen derecho a voto. El encuentro concluyó con un documento que reclama más puestos de poder para ellas y con el compromiso de presentar en un año conclusiones sobre el diaconado femenino.\\n\\nViolencia y feminicidios\\n\\nFrancisco ha denunciado la violencia contra las mujeres numerosas veces, pero en esta ocasión en Italia se ha acogido de una forma particular, ya que en este momento el país se encuentra en pleno examen de conciencia sobre cómo neutralizar una arraigada cultura machista que en ocasiones desemboca en feminicidios. El brutal asesinato de una universitaria de 22 años a manos de su expareja ha activado una insólita toma de conciencia en la sociedad. El crimen ha provocado protestas en todo el país y ha abierto el debate sobre la necesidad de legislar y poner en marcha iniciativas en las escuelas para atajar la violencia machista.\\n\\nSegún el Ministerio del Interior italiano, más de un centenar de mujeres fueron asesinadas en 2023, de ellas, 96 a manos de su pareja o expareja. El feminicidio se ha convertido en una palabra habitual en los titulares de los periódicos los últimos meses.\\n\\nAsistentes durante el rezo del Ángelus, este en la plaza de San Pedro en el Vaticano. VATICAN MEDIA (via REUTERS)\\n\\nEn Italia se vive un clima de concienciación también favorecido indirectamente por el estreno de la comedia dramática C’è ancora domani, sobre la emancipación de las mujeres y el sufragio femenino en el año 1946. La cinta va camino de convertirse en la película más vista de la historia del país y ya se utiliza como herramienta didáctica en las escuelas de todo el país.\\n\\nLa Iglesia celebra en Año Nuevo desde 1967 también la Jornada Mundial de la Paz. El Papa publica algunas semanas antes un mensaje especial para este día, que en esta ocasión abordaba los riesgos de la inteligencia artificial. “La inteligencia artificial debe ser entendida como una galaxia de realidades distintas y no podemos presumir a priori que su desarrollo aporte una contribución benéfica al futuro de la humanidad y a la paz entre los pueblos. Tal resultado positivo sólo será posible si somos capaces de actuar de forma responsable”, señaló el Pontífice. Según Francisco, los progresos tecnológicos y científicos están permitiendo “un control sobre la realidad nunca visto hasta ahora” y “poniendo en las manos del hombre una vasta gama de posibilidades, algunas de las cuales representan un riesgo para la supervivencia humana y un peligro para la casa común”.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# articulo_text = articulo['no_Contenido']\n",
    "articulo_text = articulo_raw['contenido_articulo']\n",
    "\n",
    "articulo_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL del artículo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://elpais.com/sociedad/2024-01-01/el-papa-denuncia-la-violencia-contras-las-mujeres-y-reclama-mas-espacio-para-ellas-en-la-iglesia.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articulo_url = articulo_raw['no_Pagina_url']\n",
    "# articulo_url = articulo_raw['Pagina']\n",
    "\n",
    "articulo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objeto Article de newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "# Crear el objeto Article\n",
    "# Puedes añadir language='es' si ayuda al parser, aunque suele detectarlo solo.\n",
    "articulo = Article(articulo_url, language='es')\n",
    "\n",
    "try:\n",
    "    # 2. Descargar el HTML\n",
    "    articulo.download()\n",
    "    \n",
    "    # 3. Parsear (analizar) el contenido\n",
    "    articulo.parse()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al procesar la URL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 02/2026 - Variables Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ID noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_id_noticia(articulo_raw):\n",
    "    \"\"\"\n",
    "    Extrae y devuelve el IdNoticia de un registro dado.\n",
    "    \"\"\"\n",
    "    articulo_id = articulo_raw['IdNoticia']\n",
    "    return articulo_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articulo_id='1'\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "articulo_id = obtener_id_noticia(articulo_raw)\n",
    "print(f\"{articulo_id=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# Función para clasificar el medio según la URL\n",
    "def clasificar_var_medio(articulo):\n",
    "    # Extraer el dominio de la URL\n",
    "    url = articulo.url\n",
    "    domain = urlparse(url).netloc.lower()\n",
    "    \n",
    "    # Diccionario de dominios y categorías\n",
    "    media_map = {\n",
    "        \"elmundo.es\": 1,\n",
    "        \"elpais.com\": 2,\n",
    "        \"eldiario.es\": 3,\n",
    "        \"20minutos.es\": 4,\n",
    "        \"articulo14.com\": 5,\n",
    "        \"infolibre.es\": 6,\n",
    "        \"lavanguardia.com\": 7\n",
    "    }\n",
    "    \n",
    "    # Buscar el dominio en el mapa\n",
    "    for key, value in media_map.items():\n",
    "        if key in domain:\n",
    "            return key, value\n",
    "    \n",
    "    # Si no coincide con ninguno, retornar None o 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medio: elpais.com\n",
      "Categoría: 2\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Medio = clasificar_var_medio(articulo)[0]\n",
    "Medio_num = clasificar_var_medio(articulo)[1]\n",
    "\n",
    "print(f\"Medio: {Medio}\")\n",
    "print(f\"Categoría: {Medio_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from newspaper import Article\n",
    "\n",
    "def clasificar_var_fecha(articulo: Article) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article.\n",
    "    Devuelve la fecha como texto en formato 'dd/mm/aaaa' o None.\n",
    "    \"\"\"\n",
    "    # Verificamos si existe la fecha\n",
    "    if articulo.publish_date:\n",
    "        # %d = día (01-31)\n",
    "        # %m = mes (01-12)\n",
    "        # %Y = año (cuatro dígitos, ej: 2026)\n",
    "        return articulo.publish_date.strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha: 01/01/24\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Fecha = clasificar_var_fecha(articulo)\n",
    "print(f\"Fecha: {Fecha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_mes(articulo: Article) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article procesado.\n",
    "    Devuelve el mes (MM) como entero o None si no tiene fecha.\n",
    "    \"\"\"\n",
    "    if articulo.publish_date:\n",
    "        return articulo.publish_date.month\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mes: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "mes = clasificar_var_mes(articulo)\n",
    "print(f\"mes: {mes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_año(articulo: Article) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article procesado.\n",
    "    Devuelve el año (YYYY) como entero o None si no tiene fecha.\n",
    "    \"\"\"\n",
    "    if articulo.publish_date:\n",
    "        return articulo.publish_date.year\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "año: 2024\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "año = clasificar_var_año(articulo)\n",
    "print(f\"año: {año}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Número de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_caracteres(articulo: Article) -> int:\n",
    "    \"\"\"\n",
    "    Devuelve la cantidad de caracteres del cuerpo del artículo.\n",
    "    Si no hay texto, devuelve 0.\n",
    "    \"\"\"\n",
    "    if articulo.text:\n",
    "        # Retorna la longitud del texto\n",
    "        return len(articulo.text)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres: 4697\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Caracteres = clasificar_var_caracteres(articulo)\n",
    "print(f\"Caracteres: {Caracteres}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Titular. Copia el titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_titular(articulo: Article) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Recibe un objeto Article procesado.\n",
    "    Devuelve el titular en minúsculas o None si no existe.\n",
    "    \"\"\"\n",
    "    if articulo.title:\n",
    "        # .strip() quita espacios extra y .lower() pasa a minúsculas\n",
    "        return articulo.title.strip().lower()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titular: el papa denuncia la violencia contra las mujeres y reclama más “espacio” para ellas en la iglesia\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "Titular = clasificar_var_titular(articulo)\n",
    "print(f\"Titular: {Titular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a. Nombre Propio Titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "\n",
    "class NombresDetectados(BaseModel):\n",
    "    # Lista de cadenas con los nombres extraídos\n",
    "    nombres: List[str] = Field(default_factory=list, description=\"Lista de nombres propios detectados\")\n",
    "    # Lista de enteros con los códigos correspondientes\n",
    "    valores: List[int] = Field(default_factory=list, description=\"Lista de valores clasificados según la tabla\")\n",
    "\n",
    "def clasificar_var_nombre_propio_titular_list(titulo: str) -> NombresDetectados:\n",
    "    \"\"\"\n",
    "    Extrae nombres propios del titular y los clasifica según su género o tipo.\n",
    "    Devuelve dos listas sincronizadas: nombres y valores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Si el título es muy corto, devolvemos listas vacías\n",
    "    if not titulo or len(titulo) < 3:\n",
    "        return NombresDetectados(nombres=[], valores=[])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente TITULAR y extrae los nombres propios, entidades, lugares o tecnologías.\n",
    "    Asigna a cada uno su código numérico correspondiente.\n",
    "\n",
    "    TITULAR: \"{titulo}\"\n",
    "\n",
    "    TABLA DE CÓDIGOS:\n",
    "    1  = Hombre (Ej: \"Pedro Sánchez\", \"El Papa\", \"Carlos\")\n",
    "    2  = Mujer (Ej: \"María\", \"Isabel Díaz Ayuso\", \"Alessandra\")\n",
    "    3  = Grupo Mixto (Ej: \"La pareja\", \"Los vecinos\", \"Padres\")\n",
    "    4  = Institución, Organización, Empresa, Partido Político (ej: \"Google\", \"PSOE\", \"La ONU\")\n",
    "    41 = Lugares: Países, Regiones, Ciudades (ej: \"España\", \"Madrid\", \"Europa\")\n",
    "    42 = Tecnología: Apps, Modelos de IA, Robots, Software (ej: \"ChatGPT\", \"Gemini\", \"Sora\", \"TikTok\")\n",
    "\n",
    "    INSTRUCCIONES:\n",
    "    - Ignora sustantivos comunes que no sean entidades (ej: no extraigas \"la policía\" si es genérico, pero sí \"Mossos d'Esquadra\").\n",
    "    - Distingue bien entre la EMPRESA (OpenAI -> 4) y el PRODUCTO (ChatGPT -> 42).\n",
    "    - Si no hay nombres propios, devuelve listas vacías.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON con esta estructura exacta:\n",
    "    {{\n",
    "        \"nombres\": [\"Nombre1\", \"Nombre2\"],\n",
    "        \"valores\": [Codigo1, Codigo2]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- PARSEO Y VALIDACIÓN ---\n",
    "    try:\n",
    "        # Limpieza básica para encontrar el JSON\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1:\n",
    "            return NombresDetectados(nombres=[], valores=[])\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        # Validamos con Pydantic\n",
    "        resultado = NombresDetectados(**data)\n",
    "        \n",
    "        # Validación de seguridad: Las listas deben tener el mismo tamaño\n",
    "        if len(resultado.nombres) != len(resultado.valores):\n",
    "            # Si hay desajuste, cortamos a la longitud del más corto\n",
    "            min_len = min(len(resultado.nombres), len(resultado.valores))\n",
    "            resultado.nombres = resultado.nombres[:min_len]\n",
    "            resultado.valores = resultado.valores[:min_len]\n",
    "            \n",
    "        return resultado\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError):\n",
    "        return NombresDetectados(nombres=[], valores=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre Propio Titular Lista Nombres: ['Papa']\n",
      "Nombre Propio Titular Lista Valores: [1]\n"
     ]
    }
   ],
   "source": [
    "nombre_propio_titular_list = clasificar_var_nombre_propio_titular_list(articulo.title)\n",
    "print(f\"Nombre Propio Titular Lista Nombres: {nombre_propio_titular_list.nombres}\")\n",
    "print(f\"Nombre Propio Titular Lista Valores: {nombre_propio_titular_list.valores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7b. Género Nombre Propio Titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_nombre_propio_titular(valores: list[int]) -> int:\n",
    "    \"\"\"\n",
    "    Calcula el valor único de protagonismo basado en la lista de entidades detectadas.\n",
    "    Prioridad absoluta a las personas sobre entidades/lugares.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not valores:\n",
    "        return 0\n",
    "\n",
    "    # 1. CONTADORES DE PERSONAS\n",
    "    cnt_hombres = valores.count(1)\n",
    "    cnt_mujeres = valores.count(2)\n",
    "    \n",
    "    # Contamos también si el LLM ya detectó grupos mixtos explícitos\n",
    "    cnt_mixtos_neutro = valores.count(3)\n",
    "    cnt_mixtos_hombres = valores.count(32)\n",
    "    cnt_mixtos_mujeres = valores.count(33)\n",
    "\n",
    "    # Suma total de indicadores humanos\n",
    "    total_humanos = cnt_hombres + cnt_mujeres + cnt_mixtos_neutro + cnt_mixtos_hombres + cnt_mixtos_mujeres\n",
    "\n",
    "    # --- FASE 1: FILTRO HUMANO (Prioridad Absoluta) ---\n",
    "    if total_humanos > 0:\n",
    "        \n",
    "        # CASO A: Solo Hombres (Sin mujeres ni grupos mixtos)\n",
    "        if cnt_hombres > 0 and cnt_mujeres == 0 and cnt_mixtos_neutro == 0 and cnt_mixtos_hombres == 0 and cnt_mixtos_mujeres == 0:\n",
    "            return 1\n",
    "            \n",
    "        # CASO B: Solo Mujeres (Sin hombres ni grupos mixtos)\n",
    "        if cnt_mujeres > 0 and cnt_hombres == 0 and cnt_mixtos_neutro == 0 and cnt_mixtos_hombres == 0 and cnt_mixtos_mujeres == 0:\n",
    "            return 2\n",
    "\n",
    "        # CASO C: Mixto (Hay presencia de ambos o indicadores de grupo)\n",
    "        # Aquí decidimos si es 3, 32 o 33 contando individuos\n",
    "        \n",
    "        if cnt_hombres > cnt_mujeres:\n",
    "            return 32  # Mixto mayoritariamente masculino\n",
    "        elif cnt_mujeres > cnt_hombres:\n",
    "            return 33  # Mixto mayoritariamente femenino\n",
    "        else:\n",
    "            # Empate técnico (ej: 1 hombre y 1 mujer) o solo había un [3] genérico\n",
    "            # Si el empate viene de counts explícitos (1 vs 1), es 3.\n",
    "            # Si viene de grupos (ej: un [32] detectado), respetamos ese matiz.\n",
    "            if cnt_mixtos_hombres > cnt_mixtos_mujeres:\n",
    "                return 32\n",
    "            elif cnt_mixtos_mujeres > cnt_mixtos_hombres:\n",
    "                return 33\n",
    "            else:\n",
    "                return 3 # Empate total o mixto neutro\n",
    "\n",
    "    # --- FASE 2: NO HUMANOS (Solo si total_humanos == 0) ---\n",
    "    # Establecemos jerarquía de interés: IA > Entidad > Lugar\n",
    "    \n",
    "    if 42 in valores:\n",
    "        return 42 # Prioridad a Tecnología/IA\n",
    "    \n",
    "    if 4 in valores:\n",
    "        return 4  # Empresas / Instituciones\n",
    "        \n",
    "    if 41 in valores:\n",
    "        return 41 # Lugares (es lo menos informativo)\n",
    "\n",
    "    # Si todo falla (ej: llegó un código desconocido)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_propio_titular 1\n"
     ]
    }
   ],
   "source": [
    "nombre_propio_titular = clasificar_var_nombre_propio_titular(nombre_propio_titular_list.valores)\n",
    "print(\"nombre_propio_titular\", nombre_propio_titular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jggomez/Desktop/IRIS/iris-uc3m/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-02-14 20:40:16.241372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1771098016.257255 3425484 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1771098016.262184 3425484 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-14 20:40:16.278434: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-14 20:40:30,215 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-LOC, S-ORG, B-PER, I-PER, E-PER, S-MISC, B-ORG, E-ORG, S-PER, I-ORG, B-LOC, E-LOC, B-MISC, E-MISC, I-MISC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "\n",
    "# 1. Cargar el modelo (se hace una sola vez)\n",
    "tagger = SequenceTagger.load(\"flair/ner-spanish-large\")\n",
    "\n",
    "# Caché para no repetir llamadas a la API y ahorrar créditos\n",
    "cache_generos = {}\n",
    "\n",
    "def get_gender_cached(name):\n",
    "    \"\"\"Consulta Genderize y guarda el resultado en memoria.\"\"\"\n",
    "    name = name.lower().capitalize()\n",
    "    if name in cache_generos:\n",
    "        return cache_generos[name]\n",
    "    try:\n",
    "        # Usamos timeout para que no se quede colgado si falla la red\n",
    "        response = requests.get(f\"https://api.genderize.io?name={name}\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            gen = response.json().get(\"gender\")\n",
    "            cache_generos[name] = gen\n",
    "            return gen\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def clasificar_var_nombre_propio_titular(titular: str):\n",
    "    \"\"\"\n",
    "    Detecta nombres y devuelve (categoría, lista_nombres).\n",
    "    Categorías: 1=No hay, 2=Hombre, 3=Mujer, 4=Ambos, 5=Neutro (entidades)\n",
    "    \"\"\"\n",
    "    if not titular:\n",
    "        return 1, []\n",
    "\n",
    "    sentence = Sentence(titular)\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    nombres_personas = []\n",
    "    otras_entidades = []\n",
    "\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        if entity.tag == \"PER\":\n",
    "            nombres_personas.append(entity.text)\n",
    "        else:\n",
    "            otras_entidades.append(entity.text)\n",
    "\n",
    "    # Lógica de categorías\n",
    "    if not nombres_personas and otras_entidades:\n",
    "        return 5, []\n",
    "    \n",
    "    if not nombres_personas:\n",
    "        return 1, []\n",
    "\n",
    "    # Determinamos género para la categoría\n",
    "    hombres, mujeres = 0, 0\n",
    "    for np in nombres_personas:\n",
    "        primer_nombre = np.split()[0]\n",
    "        gen = get_gender_cached(primer_nombre)\n",
    "        if gen == \"male\": hombres += 1\n",
    "        elif gen == \"female\": mujeres += 1\n",
    "\n",
    "    if hombres == 0 and mujeres == 0: cat = 1\n",
    "    elif hombres > mujeres: cat = 2\n",
    "    elif mujeres > hombres: cat = 3\n",
    "    else: cat = 4 # Empate o presencia de ambos\n",
    "\n",
    "    return cat, nombres_personas\n",
    "\n",
    "def clasificar_var_genero_nombre_propio_titular(lista_nombres):\n",
    "    \"\"\"\n",
    "    Recibe la lista de nombres y devuelve sus géneros.\n",
    "    Categorías: 1=No hay, 2=Hombre, 3=Mujer, 4=Ambos, 5=Neutro (entidades)\n",
    "    \"\"\"\n",
    "    generos = []\n",
    "    for nombre_completo in lista_nombres:\n",
    "        primer_nombre = nombre_completo.split()[0]\n",
    "        genero = get_gender_cached(primer_nombre)\n",
    "        # Traducimos a algo más legible\n",
    "        if genero == \"male\": generos.append(\"2\")\n",
    "        elif genero == \"female\": generos.append(\"3\")\n",
    "        else: generos.append(\"desconocido\")\n",
    "    return generos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_propio_titular: 1\n",
      "nombres_encontrados: []\n",
      "genero_nombre_propio_titular: []\n"
     ]
    }
   ],
   "source": [
    "# --- Ejemplo de uso ---\n",
    "# Titular = \"Isabel Díaz Ayuso se reúne con Pedro Sánchez en Madrid\"\n",
    "\n",
    "# # 1. Obtenemos categoría y nombres\n",
    "# nombre_propio_titular, nombre_propio_titular_lista = clasificar_var_nombre_propio_titular(Titular)\n",
    "\n",
    "# # 2. Obtenemos los géneros basándonos en esa lista\n",
    "# genero_nombre_propio_titular = clasificar_var_genero_nombre_propio_titular(nombre_propio_titular_lista)\n",
    "\n",
    "# print(f\"nombre_propio_titular: {nombre_propio_titular}\")\n",
    "# print(f\"nombres_encontrados: {nombre_propio_titular_lista}\")\n",
    "# print(f\"genero_nombre_propio_titular: {genero_nombre_propio_titular}\")\n",
    "\n",
    "\n",
    "# 1. Obtenemos categoría y nombres\n",
    "nombre_propio_titular, nombre_propio_titular_lista = clasificar_var_nombre_propio_titular(Titular)\n",
    "\n",
    "# 2. Obtenemos los géneros basándonos en esa lista\n",
    "genero_nombre_propio_titular = clasificar_var_genero_nombre_propio_titular(nombre_propio_titular_lista)\n",
    "\n",
    "print(f\"nombre_propio_titular: {nombre_propio_titular}\")\n",
    "print(f\"nombres_encontrados: {nombre_propio_titular_lista}\")\n",
    "print(f\"genero_nombre_propio_titular: {genero_nombre_propio_titular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cita en el titular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitaTitularValidada(BaseModel):\n",
    "    # La parte del texto que corresponde a la cita\n",
    "    cita: str = Field(..., description=\"El fragmento exacto de la declaración. Si es 1 (No), dejar vacío o poner 'N/A'.\")\n",
    "    \n",
    "    # El código de clasificación\n",
    "    tipo: int = Field(..., description=\"1=No, 2=Directa, 3=Indirecta\")\n",
    "\n",
    "def clasificar_var_cita_titular(titulo: str) -> CitaTitularValidada:\n",
    "    \"\"\"\n",
    "    Analiza si el titular contiene una cita o declaración de alguien.\n",
    "    Distingue entre directa (textual) e indirecta (parafraseada).\n",
    "    \"\"\"\n",
    "    \n",
    "    if not titulo:\n",
    "        return CitaTitularValidada(cita=\"N/A\", tipo=1)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente TITULAR de noticia y detecta si contiene una CITA o DECLARACIÓN de una persona o entidad.\n",
    "\n",
    "    TITULAR: \"{titulo}\"\n",
    "\n",
    "    CLASIFICACIÓN:\n",
    "    1 = No hay cita. Es un hecho, una descripción del periodista o usa comillas solo para resaltar una palabra (ej: El \"caso Koldo\").\n",
    "    2 = Cita Directa. Reproduce palabras textuales. \n",
    "        - Pistas: Usa comillas para una frase completa (\"Me voy\", dijo X) o dos puntos (Sánchez: No dimitiré).\n",
    "    3 = Cita Indirecta. Parafrasea lo que alguien dijo sin usar comillas para la frase entera.\n",
    "        - Pistas: Usa verbos de habla (asegura que, dice que, pide, advierte, niega) seguidos de la idea.\n",
    "\n",
    "    INSTRUCCIONES:\n",
    "    - En el campo \"cita\", extrae SOLO el contenido de lo que se ha dicho. Si es tipo 1, pon \"N/A\".\n",
    "    - Sé estricto: \"Madrid aprueba la ley\" es 1 (hecho). \"Ayuso dice que Madrid aprobará la ley\" es 3 (indirecta).\n",
    "\n",
    "    Responde SOLO con este JSON:\n",
    "    {{\n",
    "        \"cita\": \"texto de la declaración\",\n",
    "        \"tipo\": numero\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Llamada al LLM (asumiendo que tienes tu función consultar_ollama)\n",
    "    respuesta = consultar_ollama(prompt)\n",
    "    \n",
    "    try:\n",
    "        # Limpieza básica para extraer JSON\n",
    "        json_str = respuesta[respuesta.find('{'):respuesta.rfind('}')+1]\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        return CitaTitularValidada(**data)\n",
    "        \n",
    "    except Exception:\n",
    "        # Fallback en caso de error\n",
    "        return CitaTitularValidada(cita=\"Error al procesar\", tipo=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cita Titular Cita:  El Papa denuncia la violencia contra las mujeres y reclama más \"espacio\" para ellas en la Iglesia\n",
      "Cita Titular Tipo:  2\n"
     ]
    }
   ],
   "source": [
    "cita_titular = clasificar_var_cita_titular(articulo.title)\n",
    "print(\"Cita Titular Cita: \", cita_titular.cita)\n",
    "print(\"Cita Titular Tipo: \", cita_titular.tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9a. Protagonistas que aparecen en la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtagonistasDetectados(BaseModel):\n",
    "    # Lista de cadenas con los nombres extraídos\n",
    "    nombres: List[str] = Field(default_factory=list, description=\"Lista de nombres únicos detectados en la noticia\")\n",
    "    # Lista de enteros con los códigos correspondientes\n",
    "    valores: List[int] = Field(default_factory=list, description=\"Lista de valores clasificados según la tabla\")\n",
    "\n",
    "def clasificar_var_cla_genero_prota_list(texto_noticia: str) -> ProtagonistasDetectados:\n",
    "    \"\"\"\n",
    "    Analiza el cuerpo de la noticia para extraer los protagonistas principales.\n",
    "    Devuelve listas sincronizadas de nombres únicos y sus códigos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validación básica\n",
    "    if not texto_noticia or len(texto_noticia) < 10:\n",
    "        return ProtagonistasDetectados(nombres=[], valores=[])\n",
    "\n",
    "    # --- PROMPT ---\n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente TEXTO DE NOTICIA y extrae los protagonistas (personas, entidades, lugares clave).\n",
    "    \n",
    "    TEXTO (Fragmento):\n",
    "    \"{texto_noticia}...\"\n",
    "\n",
    "    TABLA DE CÓDIGOS ESTRICTA:\n",
    "    1  = Hombre (Ej: \"Pedro Sánchez\", \"El Papa\", \"Carlos\")\n",
    "    2  = Mujer (Ej: \"María\", \"Isabel Díaz Ayuso\", \"Alessandra\")\n",
    "    3  = Grupo Mixto (Ej: \"La pareja\", \"Los vecinos\", \"Padres\")\n",
    "    4  = Institución/Empresa (Ej: \"Gobierno\", \"Reuters\", \"Vatican Media\", \"PSOE\")\n",
    "    41 = Lugares: Países, Regiones, Ciudades (ej: \"España\", \"Madrid\", \"Europa\")\n",
    "    42 = Tecnología: Apps, Modelos de IA, Robots, Software (ej: \"ChatGPT\", \"Gemini\", \"Sora\", \"TikTok\")\n",
    "\n",
    "    REGLAS OBLIGATORIAS:\n",
    "    1. Si el nombre es de una sola persona, JAMÁS uses códigos 3, 32 o 33.\n",
    "    2. Agencias de noticias (Reuters, EFE, Europa Press) son SIEMPRE código 4.\n",
    "    3. Nombres femeninos (María, Alessandra) son código 2.\n",
    "    4. Nombres masculinos (Pedro, Francisco) son código 1.\n",
    "    \n",
    "    FORMATO JSON EXACTO:\n",
    "    {{\n",
    "        \"nombres\": [\"Nombre1\", \"Nombre2\"],\n",
    "        \"valores\": [Codigo1, Codigo2]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- LLAMADA AL MODELO ---\n",
    "    # Asumiendo que usas tu función 'consultar_ollama'\n",
    "    # Se recomienda un modelo con buena capacidad de contexto (ej: llama3, mistral, gemma:7b)\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- PARSEO Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1:\n",
    "            return ProtagonistasDetectados(nombres=[], valores=[])\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        resultado = ProtagonistasDetectados(**data)\n",
    "        \n",
    "        # Sincronización de seguridad\n",
    "        min_len = min(len(resultado.nombres), len(resultado.valores))\n",
    "        resultado.nombres = resultado.nombres[:min_len]\n",
    "        resultado.valores = resultado.valores[:min_len]\n",
    "            \n",
    "        return resultado\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError):\n",
    "        return ProtagonistasDetectados(nombres=[], valores=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre Propio Titular Lista Nombres: ['Papa Francisco', 'Alessandra Smerilli', 'María', 'Francesco Cassilli', 'Reuters', 'Vatican Media', 'Italia', 'Francesco Cassilli']\n",
      "Nombre Propio Titular Lista Valores: [1, 2, 2, 1, 4, 4, 41, 1]\n"
     ]
    }
   ],
   "source": [
    "cla_genero_prota_list = clasificar_var_cla_genero_prota_list(articulo.text)\n",
    "print(f\"Nombre Propio Titular Lista Nombres: {cla_genero_prota_list.nombres}\")\n",
    "print(f\"Nombre Propio Titular Lista Valores: {cla_genero_prota_list.valores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9b. Género Protagonistas que aparecen en la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_cla_genero_prota(valores: list[int]) -> int:\n",
    "    \"\"\"\n",
    "    Calcula el valor único de los protagonistas en el CUERPO de la noticia.\n",
    "    Toma la lista de códigos detectados y decide el código dominante.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not valores:\n",
    "        return 0\n",
    "\n",
    "    # 1. CONTEO DE CÓDIGOS HUMANOS\n",
    "    cnt_hombres = valores.count(1)\n",
    "    cnt_mujeres = valores.count(2)\n",
    "    \n",
    "    # Contamos grupos mixtos detectados por el LLM\n",
    "    cnt_mixtos_neutro = valores.count(3)\n",
    "    cnt_mixtos_hombres = valores.count(32)\n",
    "    cnt_mixtos_mujeres = valores.count(33)\n",
    "\n",
    "    # Suma total de indicadores humanos (Individuales + Grupos)\n",
    "    total_humanos = cnt_hombres + cnt_mujeres + cnt_mixtos_neutro + cnt_mixtos_hombres + cnt_mixtos_mujeres\n",
    "\n",
    "    # --- FASE 1: FILTRO HUMANO (Prioridad Absoluta) ---\n",
    "    if total_humanos > 0:\n",
    "        \n",
    "        # CASO A: Solo Hombres (Sin mujeres individuales NI grupos mixtos)\n",
    "        # Es estricto: si aparece un grupo \"33\" o \"3\", ya no es solo hombres.\n",
    "        if (cnt_hombres > 0 and cnt_mujeres == 0 and \n",
    "            cnt_mixtos_neutro == 0 and cnt_mixtos_hombres == 0 and cnt_mixtos_mujeres == 0):\n",
    "            return 1\n",
    "            \n",
    "        # CASO B: Solo Mujeres (Sin hombres individuales NI grupos mixtos)\n",
    "        if (cnt_mujeres > 0 and cnt_hombres == 0 and \n",
    "            cnt_mixtos_neutro == 0 and cnt_mixtos_hombres == 0 and cnt_mixtos_mujeres == 0):\n",
    "            return 2\n",
    "\n",
    "        # CASO C: Mixto (Hay presencia de ambos o hay grupos mixtos)\n",
    "        # Comparamos cantidades para determinar la mayoría\n",
    "        \n",
    "        # C1. Comparación directa de individuos\n",
    "        if cnt_hombres > cnt_mujeres:\n",
    "            return 32  # Mixto más hombres\n",
    "        elif cnt_mujeres > cnt_hombres:\n",
    "            return 33  # Mixto más mujeres\n",
    "        \n",
    "        # C2. Empate de individuos (ej: 0 vs 0, o 2 vs 2). Desempate por grupos.\n",
    "        else:\n",
    "            if cnt_mixtos_hombres > cnt_mixtos_mujeres:\n",
    "                return 32\n",
    "            elif cnt_mixtos_mujeres > cnt_mixtos_hombres:\n",
    "                return 33\n",
    "            else:\n",
    "                # Empate total (ej: 1 hombre, 1 mujer) o solo grupos neutros (3)\n",
    "                return 3\n",
    "\n",
    "    # --- FASE 2: NO HUMANOS (Solo si no hay NINGÚN humano) ---\n",
    "    \n",
    "    # Prioridad: Tecnología (42) > Institución (4) > Lugar (41)\n",
    "    \n",
    "    if 42 in valores:\n",
    "        return 42 # IA, Robots, Apps\n",
    "    \n",
    "    if 4 in valores:\n",
    "        return 4  # Empresas, Partidos, Organismos\n",
    "        \n",
    "    if 41 in valores:\n",
    "        return 41 # Países, Ciudades (Fondo)\n",
    "\n",
    "    # Si llega aquí, es un código desconocido o lista vacía\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Género Protagonistas: 32\n"
     ]
    }
   ],
   "source": [
    "cla_genero_prota = clasificar_var_cla_genero_prota(cla_genero_prota_list.valores)\n",
    "print(f\"Género Protagonistas: {cla_genero_prota}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER (tag de persona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Nombre Periodista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_nombre_periodista(articulo: articulo) -> str:\n",
    "    \"\"\"\n",
    "    Extrae autores y limpia textos basura como 'Ver Biografía', 'Redacción', etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista de palabras/frases que NO queremos en el nombre\n",
    "    palabras_basura = [\n",
    "        \"ver biografía\", \"biografía\", \"ver perfil\", \"perfil\", \n",
    "        \"ver más\", \"see profile\", \"read more\", \"twitter\", \n",
    "        \"email\", \"follow\", \"redacción\", \"agencia\"\n",
    "    ]\n",
    "\n",
    "    autores_detectados = []\n",
    "\n",
    "    # 1. Intentar obtener autores desde el parser\n",
    "    if articulo.authors:\n",
    "        for autor in articulo.authors:\n",
    "            autor_limpio = autor.strip()\n",
    "            \n",
    "            # Verificamos si el texto (en minúsculas) contiene alguna palabra basura\n",
    "            if any(basura in autor_limpio.lower() for basura in palabras_basura):\n",
    "                # Si es basura pura (ej: \"Ver Biografía\"), lo ignoramos\n",
    "                # Pero si es \"Lorena Pacho, Ver Biografía\", intentamos limpiarlo\n",
    "                \n",
    "                # Caso específico que te pasó: eliminar \"Ver Biografía\" del string\n",
    "                for basura in palabras_basura:\n",
    "                    # Reemplazamos la basura por vacío, ignorando mayúsculas/minúsculas es complejo,\n",
    "                    # así que hacemos un replace simple de las variantes comunes:\n",
    "                    autor_limpio = autor_limpio.replace(\"Ver Biografía\", \"\")\n",
    "                    autor_limpio = autor_limpio.replace(\"Ver biografía\", \"\")\n",
    "                \n",
    "                autor_limpio = autor_limpio.strip(\" ,|\") # Limpiamos comas o barras sobrantes\n",
    "\n",
    "            # Si después de limpiar queda algo y no es demasiado corto, lo guardamos\n",
    "            if len(autor_limpio) > 2:\n",
    "                autores_detectados.append(autor_limpio)\n",
    "\n",
    "    # 2. Si encontramos autores limpios, los devolvemos\n",
    "    if autores_detectados:\n",
    "        # Eliminamos duplicados usando set() y mantenemos orden\n",
    "        return \", \".join(list(dict.fromkeys(autores_detectados)))\n",
    "\n",
    "    # 3. Fallback: Metadatos (si la lista authors falló o se limpió todo)\n",
    "    meta = articulo.meta_data\n",
    "    claves_meta = ['author', 'og:author', 'dc.creator', 'byl']\n",
    "    \n",
    "    for clave in claves_meta:\n",
    "        valor = meta.get(clave)\n",
    "        if valor:\n",
    "            # A veces los metadatos también traen basura, podrías aplicar limpieza aquí también\n",
    "            return str(valor).strip()\n",
    "\n",
    "    # 4. Defecto\n",
    "    return \"Redacción / Otros\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre_periodista: Lorena Pacho\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "nombre_periodista = clasificar_var_nombre_periodista(articulo)\n",
    "print(f\"nombre_periodista: {nombre_periodista}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Género Periodista (Autoría)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Optional\n",
    "import re\n",
    "\n",
    "# Modelo de validación estricta\n",
    "class GeneroPeriodistaValidado(BaseModel):\n",
    "    # Field(...) hace el campo obligatorio\n",
    "    # ge=0: Greater or equal to 0\n",
    "    # le=5: Less or equal to 5\n",
    "    codigo: int = Field(..., ge=0, le=7, description=\"Código de clasificación de autoría (0-7)\")\n",
    "\n",
    "\n",
    "def clasificar_var_genero_periodista(nombre_periodista: str, nombre_medio:str) -> int:\n",
    "    \"\"\"\n",
    "    Clasifica la autoría considerando el contexto del medio.\n",
    "    Recibe:\n",
    "      - nombre_periodista: El texto de la firma (ej: \"Redacción\", \"Juan Pérez\")\n",
    "      - nombre_medio: El nombre del periódico donde se publica (ej: \"El País\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validación inicial rápida\n",
    "    if not nombre_periodista or len(nombre_periodista) < 2:\n",
    "        return 0\n",
    "\n",
    "    # Prompt enriquecido con el contexto del medio y definiciones\n",
    "    prompt = f\"\"\"\n",
    "    Contexto:\n",
    "    Noticia publicada en el medio: \"{nombre_medio}\".\n",
    "    Autor/Firma a analizar: \"{nombre_periodista}\".\n",
    "    \n",
    "    Tu misión es clasificar la autoría (0-7) siguiendo estrictamente estas definiciones:\n",
    "\n",
    "    0 = Ns/Nc: Desconocido, ambiguo o iniciales.\n",
    "    1 = Hombre: Nombre de persona masculino.\n",
    "    2 = Mujer: Nombre de persona femenino.\n",
    "    3 = Mixto: Varios autores de distinto género.\n",
    "    4 = Otros medios: El autor es otro medio de comunicación (ej: \"The New York Times\", \"Revista Hola\").\n",
    "    5 = Agencia: Agencias de noticias puras (EFE, Europa Press, Reuters, AFP).\n",
    "    \n",
    "    6 = Redacción (Periodística): \n",
    "        - Firma genérica del propio medio \"{nombre_medio}\" (ej: \"Redacción\", \"El País\", \"Editorial\").\n",
    "        - IMPORTANTE: Si el autor es una empresa comercial que NO es un medio de noticias (como Ford, Apple), NO ES 6.\n",
    "    \n",
    "    7 = Corporativo (Comercial / Institucional): \n",
    "        - Firmado por una empresa comercial, marca de tecnología, coches, banco, etc. (ej: Ford, Meta, Google, BBVA, Zara).\n",
    "        - Firmado por instituciones gubernamentales o ONGs (ej: Gobierno de España, Greenpeace).\n",
    "        - Notas de prensa firmadas por la marca.\n",
    "\n",
    "    INSTRUCCIONES DE PRIORIDAD:\n",
    "    1. Si \"{nombre_periodista}\" es una marca conocida (coches, tech, ropa) -> ELIGE 7.\n",
    "    2. Si \"{nombre_periodista}\" es igual a \"{nombre_medio}\" -> ELIGE 6.\n",
    "    3. Si \"{nombre_periodista}\" es una Agencia conocida -> ELIGE 5.\n",
    "\n",
    "    Responde ÚNICAMENTE con el número dígito (0-7).\n",
    "    \"\"\"\n",
    "    # 1. Llamada al modelo (tu función externa)\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # 2. Extracción del número (Pre-procesamiento)\n",
    "    # Buscamos el primer dígito que aparezca en el texto\n",
    "    match = re.search(r'\\d+', respuesta_texto)\n",
    "    \n",
    "    numero_detectado = int(match.group()) if match else 0\n",
    "\n",
    "    # 3. Validación con Pydantic\n",
    "    try:\n",
    "        # Instanciamos el modelo con el dato detectado\n",
    "        # Si numero_detectado es 9 (alucinación), Pydantic dará error aquí\n",
    "        resultado = GeneroPeriodistaValidado(codigo=numero_detectado)\n",
    "        \n",
    "        # Si llegamos aquí, es un int válido entre 0 y 5\n",
    "        return resultado.codigo\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"Error de validación Pydantic (Dato inválido: {numero_detectado}): {e}\")\n",
    "        return 0 # Default seguro si la IA alucina un número fuera de rango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genero_periodista=2\n"
     ]
    }
   ],
   "source": [
    "# -- Uso -- \n",
    "genero_periodista = clasificar_var_genero_periodista(nombre_periodista=nombre_periodista, nombre_medio=Medio)\n",
    "print(f\"{genero_periodista=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class TemaConExplicacion(BaseModel):\n",
    "    # Validamos que sea un entero entre 0 y 17\n",
    "    codigo: int = Field(..., ge=0, le=17, description=\"Código numérico del tema\")\n",
    "    # Añadimos el campo de explicación\n",
    "    explicacion: str = Field(..., description=\"Breve justificación de por qué se eligió este tema\")\n",
    "\n",
    "def clasificar_var_tema(titulo: str, texto_cuerpo: str) -> TemaConExplicacion:\n",
    "    \"\"\"\n",
    "    Clasifica el tema y da una explicación.\n",
    "    Devuelve un objeto Pydantic con .codigo (int) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Validación rápida\n",
    "    full_text = f\"{titulo} {texto_cuerpo}\"\n",
    "    if not full_text or len(full_text) < 10:\n",
    "        # Devolvemos objeto vacío/error\n",
    "        return TemaConExplicacion(codigo=0, explicacion=\"Texto insuficiente para clasificar.\")\n",
    "\n",
    "    # Recorte para optimizar velocidad\n",
    "    texto_recortado = texto_cuerpo[:1500]\n",
    "    \n",
    "    # 2. Prompt diseñado para JSON\n",
    "    prompt = f\"\"\"\n",
    "    Analiza la noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea es clasificarla en UNA categoría (1-17) y explicar por qué.\n",
    "    \n",
    "    Categorías:\n",
    "    1 = Científica / Investigación\n",
    "    2 = Comunicación\n",
    "    3 = De farándula o espectáculo\n",
    "    4 = Deportiva\n",
    "    5 = Economía (Mercados, inflación, consumo)\n",
    "    6 = Educación/cultura\n",
    "    7 = Empleo/Trabajo\n",
    "    8 = Empresa (Corporativo, negocios)\n",
    "    9 = Judicial\n",
    "    10 = Medioambiente\n",
    "    11 = Policial\n",
    "    12 = Política\n",
    "    13 = Salud\n",
    "    14 = Social\n",
    "    15 = Tecnología\n",
    "    16 = Transporte\n",
    "    17 = Otros\n",
    "\n",
    "    FORMATO DE RESPUESTA OBLIGATORIO (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido con este formato:\n",
    "    {{\n",
    "        \"codigo\": (número entero del 1 al 17),\n",
    "        \"explicacion\": \"(frase breve justificando tu elección)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. Llamada al modelo\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # 4. Limpieza y Parsing de JSON\n",
    "    # A veces los modelos envuelven el JSON en markdown ```json ... ```\n",
    "    # Buscamos donde empieza '{' y termina '}'\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            raise ValueError(\"No se encontró JSON en la respuesta\")\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str) # Convertimos texto a diccionario Python\n",
    "\n",
    "        # 5. Validación Pydantic\n",
    "        resultado = TemaConExplicacion(**data)\n",
    "        return resultado\n",
    "\n",
    "    except (json.JSONDecodeError, ValueError, ValidationError) as e:\n",
    "        print(f\"Error parseando respuesta del modelo: {e}\")\n",
    "        # Retorno de seguridad en caso de fallo\n",
    "        return TemaConExplicacion(codigo=0, explicacion=f\"Error técnico: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Tema: 14\n",
      "Explicación: La noticia trata sobre la denuncia de violencias contra las mujeres, el papel de la mujer en la Iglesia, y la búsqueda de paz y humanidad, lo que lo clasifica claramente como un tema social.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "tema = clasificar_var_tema(articulo.title, articulo.text)\n",
    "print(f\"ID Tema: {tema.codigo}\")\n",
    "print(f\"Explicación: {tema.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12b. Sección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_seccion(articulo: Article) -> str:\n",
    "    \"\"\"\n",
    "    Extrae la sección del periódico basándose en metadatos y la URL.\n",
    "    No usa IA (es más rápido y exacto para este dato estructural).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. BUSCAR EN METADATOS (La fuente más fiable) ---\n",
    "    meta = articulo.meta_data\n",
    "    \n",
    "    # Lista de claves comunes donde los medios guardan la sección\n",
    "    claves_seccion = [\n",
    "        'section',           # Estándar simple\n",
    "        'article:section',   # Protocolo Open Graph (Facebook/LinkedIn)\n",
    "        'og:section',        # Variación Open Graph\n",
    "        'category',          # WordPress y CMS comunes\n",
    "        'dc.subject',        # Dublin Core standard\n",
    "        'ut.section'         # Algunos medios custom\n",
    "    ]\n",
    "\n",
    "    for clave in claves_seccion:\n",
    "        valor = meta.get(clave)\n",
    "        # A veces el valor es una lista, tomamos el primero\n",
    "        if isinstance(valor, list):\n",
    "            valor = valor[0]\n",
    "        \n",
    "        if valor and isinstance(valor, str) and len(valor) > 2:\n",
    "            return valor.strip().title() # Ej: \"DEPORTES \" -> \"Deportes\"\n",
    "\n",
    "    # --- 2. BUSCAR EN LA URL (Si no hay metadatos) ---\n",
    "    # Ejemplo: https://www.elmundo.es/economia/2024/02/10/noticia.html\n",
    "    # Queremos extraer \"economia\"\n",
    "    \n",
    "    path = urlparse(articulo.url).path\n",
    "    segmentos = path.split('/')\n",
    "    \n",
    "    # Filtramos segmentos vacíos\n",
    "    segmentos = [s for s in segmentos if s]\n",
    "\n",
    "    for segmento in segmentos:\n",
    "        # Ignoramos segmentos que son años (4 dígitos) o muy cortos (idiomas 'es', 'en')\n",
    "        if re.match(r'^\\d{4}$', segmento): # Es un año (2024)\n",
    "            continue\n",
    "        if re.match(r'^\\d{1,2}$', segmento): # Es un día o mes (10, 02)\n",
    "            continue\n",
    "        if len(segmento) <= 2: # Es un código de idioma (es, en, cat)\n",
    "            continue\n",
    "        if segmento in ['noticia', 'articulo', 'story', 'news']: # Palabras genéricas\n",
    "            continue\n",
    "            \n",
    "        # Si pasa los filtros, asumimos que es la sección\n",
    "        # Reemplazamos guiones por espacios (ej: \"ciencia-y-salud\" -> \"Ciencia Y Salud\")\n",
    "        return segmento.replace('-', ' ').title()\n",
    "\n",
    "    # --- 3. DEFECTO ---\n",
    "    return \"General\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sección detectada: Sociedad\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "seccion = clasificar_var_seccion(articulo)\n",
    "print(f\"Sección detectada: {seccion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 02/2026 - Variables específicas IRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. IA tema central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IaTemaCentralConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No es tema central, 2=Sí es tema central\")\n",
    "    # Campo nuevo\n",
    "    explicacion: str = Field(..., description=\"Justificación de la jerarquía de la información\")\n",
    "\n",
    "def clasificar_var_ia_tema_central(titulo: str, texto_cuerpo: str) -> IaTemaCentralConExplicacion:\n",
    "    \"\"\"\n",
    "    Determina si la Inteligencia Artificial es el TEMA CENTRAL de la noticia.\n",
    "    Devuelve objeto con .codigo y .explicacion.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    palabras_clave_ia = [\n",
    "        \"inteligencia artificial\", \"artificial intelligence\", \"ia \", \"ai \", \n",
    "        \"chatgpt\", \"gpt\", \"llm\", \"machine learning\", \"aprendizaje automático\",\n",
    "        \"red neuronal\", \"deep learning\", \"midjourney\", \"dall-e\", \"bard\", \"gemini\",\n",
    "        \"copilot\", \"algoritmo generativo\", \"sam altman\", \"openai\", \"nvidia\"\n",
    "    ]\n",
    "    \n",
    "    # Si ninguna palabra clave está presente, asumimos directamente que NO (1)\n",
    "    if not any(palabra in texto_completo for palabra in palabras_clave_ia):\n",
    "        return IaTemaCentralConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos relacionados con la Inteligencia Artificial.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    # Recortamos texto para centrar la atención en el inicio (donde suele estar el tema central)\n",
    "    texto_recortado = texto_cuerpo[:2500]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la jerarquía de la información en esta noticia:\n",
    "    \n",
    "    TÍTULO: \"{titulo}\"\n",
    "    TEXTO: \"{texto_recortado}...\"\n",
    "\n",
    "    Objetivo: Determinar si la Inteligencia Artificial (IA) es el TEMA PRINCIPAL y PROTAGONISTA.\n",
    "    \n",
    "    Criterios de clasificación:\n",
    "\n",
    "    1 = No (Mención secundaria / Otro tema):\n",
    "        - La IA se menciona al final o de pasada.\n",
    "        - Es un discurso (Papa, Políticos) sobre varios temas y la IA es solo uno más.\n",
    "        - La IA es una herramienta secundaria (ej: \"Policía usa IA para un robo\", el tema es el robo).\n",
    "        - El Título NO menciona tecnología o IA.\n",
    "\n",
    "    2 = Sí (Tema Central):\n",
    "        - La noticia gira completamente en torno a la IA (avances, regulación, peligros, inversiones).\n",
    "        - La IA es el sujeto principal del Título.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Breve justificación analizando si la IA es protagonista o secundaria)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        # Buscamos el bloque JSON\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return IaTemaCentralConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación Pydantic\n",
    "        return IaTemaCentralConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        # Fallback seguro\n",
    "        return IaTemaCentralConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: La noticia se centra en el discurso del Papa Francisco sobre la violencia contra las mujeres, el papel de la mujer en la Iglesia y la necesidad de 'espacio' para ellas. La IA se menciona brevemente al final, en relación a la asamblea del sínodo, pero no es el tema principal ni el protagonista de la noticia.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "ia_tema_central = clasificar_var_ia_tema_central(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {ia_tema_central.codigo}\")\n",
    "print(f\"Razón: {ia_tema_central.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Explicación sobre el significado de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IaSignificadoConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No explica significado, 2=Sí explica significado\")\n",
    "    # Campo nuevo\n",
    "    explicacion: str = Field(..., description=\"Justificación: ¿Hay definiciones técnicas o es solo mención?\")\n",
    "\n",
    "def clasificar_var_significado_ia(titulo: str, texto_cuerpo: str) -> IaSignificadoConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si el artículo explica o define QUÉ ES la IA o CÓMO FUNCIONA.\n",
    "    Devuelve un objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Si no hay palabras \"inteligencia\" o \"algoritmo\", difícilmente explicará qué son.\n",
    "    keywords_tecnicas = [\"inteligencia\", \"ia \", \"ai \", \"algoritmo\", \"red neuronal\", \"modelo de lenguaje\"]\n",
    "    \n",
    "    if not any(k in texto_completo for k in keywords_tecnicas):\n",
    "        return IaSignificadoConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos técnicos básicos para ofrecer una definición de IA.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT EN FORMATO JSON ---\n",
    "    # Recortamos el texto (buscamos definiciones, suelen estar al principio)\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza el siguiente texto periodístico con enfoque pedagógico:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si el artículo contiene una EXPLICACIÓN o DEFINICIÓN sobre qué es la Inteligencia Artificial (IA) o cómo funciona técnicamente.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No (Mera mención o uso):\n",
    "        - El artículo habla de herramientas (ChatGPT, Bard) o noticias de empresas sin explicar qué son.\n",
    "        - Habla de \"la IA\" como un sujeto abstracto (\"la IA cambiará el mundo\") sin definirla.\n",
    "        - Ej: \"Google lanzó su nueva IA ayer\". Aquí NO se aprende qué es la tecnología.\n",
    "\n",
    "    2 = Sí (Didáctico / Definitorio):\n",
    "        - El texto tiene intención educativa.\n",
    "        - Contiene frases tipo: \"La IA generativa funciona prediciendo el siguiente token...\", \"Los LLM son modelos entrenados con...\".\n",
    "        - Explica la diferencia técnica entre tipos de IA.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Breve frase justificando si hay definiciones técnicas o solo menciones)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        # Buscamos el bloque JSON por si el modelo añade texto extra\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return IaSignificadoConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación con Pydantic\n",
    "        return IaSignificadoConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return IaSignificadoConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: El artículo menciona el uso de la IA a través de referencias al Papa Francisco y sus discursos, pero no ofrece ninguna definición técnica o explicación de cómo funciona la IA.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "significado_ia = clasificar_var_significado_ia(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {significado_ia.codigo}\")\n",
    "print(f\"Razón: {significado_ia.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Se menciona la IA en algún momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MencionIaConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No menciona IA, 2=Sí menciona IA\")\n",
    "    # Explicación generada automáticamente por Python\n",
    "    explicacion: str = Field(..., description=\"Justificación exacta (qué palabra o sigla se encontró)\")\n",
    "\n",
    "\n",
    "def clasificar_var_menciona_ia(titulo: str, texto_cuerpo: str) -> MencionIaConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si se menciona la IA y lista TODAS las palabras clave encontradas.\n",
    "    Usa Regex y palabras clave (No requiere Ollama).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = f\"{titulo} \\n {texto_cuerpo}\"\n",
    "    texto_lower = texto_completo.lower()\n",
    "    \n",
    "    # Creamos un conjunto (set) para evitar palabras repetidas\n",
    "    palabras_encontradas = set()\n",
    "    \n",
    "    # --- 1. BÚSQUEDA DE CONCEPTOS CLAROS ---\n",
    "    palabras_clave = [\n",
    "        \"inteligencia artificial\", \"artificial intelligence\",\n",
    "        \"machine learning\", \"aprendizaje automático\", \"deep learning\",\n",
    "        \"redes neuronales\", \"chatgpt\", \"generative ai\", \"ia generativa\",\n",
    "        \"openai\", \"midjourney\", \"dall-e\", \"bard\", \"gemini\", \"copilot\",\n",
    "        \"large language model\", \" llm \", \"algoritmos generativos\",\n",
    "        \"sam altman\", \"sora\", \"claude 3\", \"llama 3\", \"mistral\",\n",
    "        \"vision pro\", \"neuralink\"\n",
    "    ]\n",
    "    \n",
    "    # Iteramos sobre todas las palabras y si están, las añadimos al set\n",
    "    for frase in palabras_clave:\n",
    "        if frase in texto_lower:\n",
    "            palabras_encontradas.add(frase.strip()) # strip para quitar espacios de \" llm \"\n",
    "\n",
    "    # --- 2. BÚSQUEDA DE SIGLAS \"IA\" o \"AI\" (Case Sensitive) ---\n",
    "    # Usamos re.findall para encontrar TODAS las ocurrencias, no solo la primera\n",
    "    patron_siglas = r'\\b(IA|AI|I\\.A\\.|A\\.I\\.)\\b'\n",
    "    coincidencias_siglas = re.findall(patron_siglas, texto_completo)\n",
    "    \n",
    "    # Añadimos las siglas encontradas al conjunto\n",
    "    for sigla in coincidencias_siglas:\n",
    "        palabras_encontradas.add(sigla)\n",
    "\n",
    "    # --- 3. CONSTRUCCIÓN DE RESPUESTA ---\n",
    "    \n",
    "    # Si el conjunto tiene elementos, es un SÍ (2)\n",
    "    if palabras_encontradas:\n",
    "        # Convertimos el set a una lista ordenada y la unimos con comas\n",
    "        lista_final = \", \".join(sorted(palabras_encontradas))\n",
    "        return MencionIaConExplicacion(\n",
    "            codigo=2,\n",
    "            explicacion=lista_final\n",
    "        )\n",
    "\n",
    "    # Si el conjunto está vacío, es un NO (1)\n",
    "    return MencionIaConExplicacion(\n",
    "        codigo=1,\n",
    "        explicacion=\"No se encontraron términos, siglas ni conceptos relacionados con la Inteligencia Artificial en el texto.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 2\n",
      "Razón: inteligencia artificial\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "menciona_ia = clasificar_var_menciona_ia(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {menciona_ia.codigo}\")\n",
    "print(f\"Razón: {menciona_ia.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Referencias en la noticia a políticas en materia de género e igualdad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenciaPoliticasGeneroConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No referencia políticas, 2=Sí referencia políticas de género\")\n",
    "    # Campo nuevo para el razonamiento\n",
    "    explicacion: str = Field(..., description=\"Justificación de la decisión\")\n",
    "\n",
    "\n",
    "def clasificar_var_referencia_politicas_genero(titulo: str, texto_cuerpo: str) -> ReferenciaPoliticasGeneroConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si la noticia hace referencia a POLÍTICAS, LEYES o DEBATES sobre \n",
    "    género, igualdad, feminismo o violencia machista.\n",
    "    Devuelve objeto con .codigo y .explicacion.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos y limpiamos texto para el filtro\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "    \n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    raices_clave = [\n",
    "        \"igualdad\", \"género\", \"genero\", \"femin\", \"mujer\", \"machis\", \n",
    "        \"brecha\", \"paridad\", \"sexis\", \"patriarca\", \"trans \", \"lgtbi\",\n",
    "        \"conciliación\", \"techo de cristal\", \"violencia vicaria\", \"víctima\",\n",
    "        \"ley\", \"ministerio\", \"protesta\", \"derechos\" # Añadido contexto político/legal\n",
    "    ]\n",
    "    \n",
    "    # Verificamos si hay al menos una palabra de género Y contexto político/social\n",
    "    # (Simplificado: si no hay ninguna raíz clave, descartamos).\n",
    "    if not any(raiz in texto_completo for raiz in raices_clave):\n",
    "        return ReferenciaPoliticasGeneroConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos clave relacionados con género, igualdad o políticas sociales.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT ESPECÍFICO (Modo JSON) ---\n",
    "    # Recortamos el texto para no saturar el contexto\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la siguiente noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si el texto hace referencia a POLÍTICAS DE GÉNERO, LEYES DE IGUALDAD o DEBATES SOBRE DERECHOS DE LA MUJER.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    1 = No:\n",
    "        - La mujer es mencionada solo como protagonista de un hecho (ej: \"La alcaldesa inauguró la feria\").\n",
    "        - Sucesos o crímenes sin contexto social/legal.\n",
    "    \n",
    "    2 = Sí:\n",
    "        - Menciona leyes, cuotas, paridad o medidas gubernamentales sobre igualdad.\n",
    "        - Habla de violencia machista/género como problema estructural o legal.\n",
    "        - Trata sobre feminismo, 8M, brecha salarial o discriminación laboral.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Frase breve justificando si se trata de política/derechos o es solo una mención circunstancial)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. Llamada al modelo ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. Procesamiento JSON ---\n",
    "    try:\n",
    "        # Buscamos el JSON dentro de la respuesta (por si el modelo añade texto extra)\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            # Fallback si no hay JSON\n",
    "            return ReferenciaPoliticasGeneroConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación final con Pydantic\n",
    "        return ReferenciaPoliticasGeneroConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return ReferenciaPoliticasGeneroConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 2\n",
      "Razón: El texto aborda la violencia contra las mujeres como un problema estructural, refiriéndose a la necesidad de 'espacio' para las mujeres en la Iglesia y a la importancia de 'cuidarlas, valorarlas' y 'ser generativa a través de una pastoral hecha de cuidado y solicitud'. Además, menciona la influencia de documentos como la encíclica Lumen Gentium, vinculada al Concilio Vaticano II, y el papel de María como modelo, directamente relacionado con la defensa de los derechos de la mujer.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "referencia_politicas_genero = clasificar_var_referencia_politicas_genero(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {referencia_politicas_genero.codigo}\")\n",
    "print(f\"Razón: {referencia_politicas_genero.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Denuncia a la desigualdad de género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenunciaDesigualdadConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No denuncia, 2=Sí denuncia desigualdad\")\n",
    "    # Nueva explicación\n",
    "    explicacion: str = Field(..., description=\"Justificación de por qué se considera denuncia o no\")\n",
    "\n",
    "\n",
    "def clasificar_var_denuncia_desigualdad_genero(titulo: str, texto_cuerpo: str) -> DenunciaDesigualdadConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si la noticia DENUNCIA desigualdad y explica por qué.\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "    \n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    palabras_activadoras = [\n",
    "        \"desigualdad\", \"discriminaci\", \"brecha\", \"violencia\", \"machis\", \n",
    "        \"patriarca\", \"acos\", \"abus\", \"víctima\", \"feminici\", \"sexismo\",\n",
    "        \"techo de cristal\", \"precariedad\", \"injusticia\", \"derechos de las mujeres\",\n",
    "        \"igualdad real\", \"conciliación\", \"paridad\"\n",
    "    ]\n",
    "    \n",
    "    # Si NO hay palabras clave, retornamos 1 directamente con explicación automática\n",
    "    if not any(p in texto_completo for p in palabras_activadoras):\n",
    "        return DenunciaDesigualdadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=\"El texto no contiene términos relacionados con género, desigualdad o violencia machista.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT PARA JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza el enfoque de esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea es determinar si el texto DENUNCIA o VISIBILIZA un problema de desigualdad de género.\n",
    "\n",
    "    Criterios:\n",
    "    1 = No (Neutro/Sucesos): Solo narra hechos sin crítica social, o habla de mujeres exitosas sin mencionar dificultades de género.\n",
    "    2 = Sí (Denuncia/Crítica): Critica el machismo, aporta datos de brechas, denuncia violencia sistémica o cubre protestas feministas.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Frase breve justificando si hay denuncia social o es meramente informativo)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA A OLLAMA ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. PROCESAMIENTO DE RESPUESTA ---\n",
    "    try:\n",
    "        # Limpieza de bloques de código markdown si los hay\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            # Fallback si el modelo no devuelve JSON\n",
    "            return DenunciaDesigualdadConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        # Validación Pydantic\n",
    "        return DenunciaDesigualdadConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        # Si algo falla en el parseo, devolvemos un objeto seguro\n",
    "        return DenunciaDesigualdadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 2\n",
      "Razón: El texto denuncia la violencia contra las mujeres y, específicamente, la necesidad de que la Iglesia dé más 'espacio' a las mujeres, invocando la figura de María como modelo.  Se refiere a la 'violación de Dios' causada por la violencia contra mujeres y al imperativo de que la Iglesia se 'redescubra su rostro femenino', indicando una crítica a las estructuras y prácticas que perpetúan la desigualdad de género.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "denuncia_desigualdad_genero = clasificar_var_denuncia_desigualdad_genero(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {denuncia_desigualdad_genero.codigo}\")\n",
    "print(f\"Razón: {denuncia_desigualdad_genero.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Presencia de mujeres racializadas en la noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujeresRacializadasConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No aparecen, 2=Sí aparecen mujeres racializadas\")\n",
    "    # Justificación\n",
    "    explicacion: str = Field(..., description=\"Detalle sobre quiénes son las mujeres detectadas y su contexto étnico\")\n",
    "\n",
    "def clasificar_var_mujeres_racializadas_noticias(titulo: str, texto_cuerpo: str) -> MujeresRacializadasConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta la presencia o mención de mujeres racializadas (no blancas/caucásicas) en la noticia.\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Buscamos términos que sugieran diversidad étnica, racial o contextos migratorios.\n",
    "    # Si no aparece NADA de esto, asumimos que se habla de mujeres blancas o el tema no es racial.\n",
    "    \n",
    "    terminos_clave = [\n",
    "        \"racializada\", \"negra\", \"afro\", \"etnia\", \"raza\", \"indígena\", \n",
    "        \"gitana\", \"romaní\", \"latina\", \"hispana\", \"asiática\", \"árabe\", \n",
    "        \"musulmana\", \"morocc\", \"marroquí\", \"subsahariana\", \"migrante\", \n",
    "        \"refugiada\", \"islam\", \"velo\", \"hijab\", \"mestiza\", \"mulata\",\n",
    "        \"origen\", \"nacionalidad\", \"extranjera\", \"diversidad\"\n",
    "    ]\n",
    "    \n",
    "    # Nota: Este filtro es laxo para no descartar falsos negativos, \n",
    "    # pero ayuda a limpiar noticias de política nacional estándar (ej: Ayuso, Montero).\n",
    "    if not any(t in texto_completo for t in terminos_clave):\n",
    "        return MujeresRacializadasConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene marcadores explícitos de diversidad étnica o racial.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la representación de las personas en esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si en la noticia aparecen, se mencionan o protagonizan **MUJERES RACIALIZADAS**.\n",
    "    \n",
    "    Definición de \"Mujer Racializada\" para este análisis:\n",
    "    Mujeres que son percibidas socialmente como no blancas en un contexto occidental. Incluye:\n",
    "    - Mujeres negras / afrodescendientes.\n",
    "    - Mujeres latinas / sudamericanas.\n",
    "    - Mujeres asiáticas.\n",
    "    - Mujeres árabes / magrebíes / musulmanas (contexto cultural-étnico).\n",
    "    - Mujeres indígenas.\n",
    "    - Mujeres gitanas / romaníes.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No:\n",
    "        - Solo aparecen mujeres blancas / caucásicas (ej: políticas europeas, actrices de Hollywood blancas).\n",
    "        - No se menciona el origen étnico y por el contexto se asume hegemonía blanca.\n",
    "        - Se habla de \"inmigrantes\" en general sin especificar mujeres.\n",
    "\n",
    "    2 = Sí:\n",
    "        - Aparece explícitamente una mujer descrita por su etnia u origen (ej: \"la activista afroamericana\", \"la cantante colombiana\").\n",
    "        - Se menciona a una figura pública conocida por ser racializada (ej: Kamala Harris, Rihanna, Salma Hayek, Zendaya) aunque no se diga su raza explícitamente en el texto.\n",
    "        - Noticias sobre colectivos específicos (ej: \"Las mujeres afganas\", \"Las temporeras marroquíes\").\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Indica qué mujer o colectivo racializado se ha detectado y por qué)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return MujeresRacializadasConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        return MujeresRacializadasConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return MujeresRacializadasConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: El texto no contiene marcadores explícitos de diversidad étnica o racial.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "mujeres_racializadas_noticias = clasificar_var_mujeres_racializadas_noticias(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {mujeres_racializadas_noticias.codigo}\")\n",
    "print(f\"Razón: {mujeres_racializadas_noticias.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Presencia de mujeres con discapacidad en la noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujeresConDiscapacidadConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No aparecen, 2=Sí aparecen mujeres con discapacidad\")\n",
    "    # Justificación\n",
    "    explicacion: str = Field(..., description=\"Detalle sobre quiénes son las mujeres detectadas y su contexto de discapacidad\")\n",
    "\n",
    "def clasificar_var_mujeres_con_discapacidad_noticias(titulo: str, texto_cuerpo: str) -> MujeresConDiscapacidadConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta la presencia o mención explícita de mujeres con discapacidad o diversidad funcional.\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Palabras clave que sugieren discapacidad, diversidad funcional o condiciones específicas.\n",
    "    # Si no aparece ninguna, descartamos la noticia.\n",
    "    \n",
    "    terminos_clave = [\n",
    "        \"discapacidad\", \"diversidad funcional\", \"silla de ruedas\", \"movilidad reducida\",\n",
    "        \"ciega\", \"sorda\", \"sordomuda\", \"invidente\", \"autis\", \" tea \", \"asperger\",\n",
    "        \"síndrome de down\", \"parálisis\", \"cerebral\", \"amputada\", \"prótesis\",\n",
    "        \"salud mental\", \"trastorno\", \"bipolar\", \"esquizofren\", \"depresio\", # En contextos de discapacidad psicosocial\n",
    "        \"dependencia\", \"capacitism\", \"paralímpic\", \"once\", \"cermi\"\n",
    "    ]\n",
    "    \n",
    "    if not any(t in texto_completo for t in terminos_clave):\n",
    "        return MujeresConDiscapacidadConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos relacionados con la discapacidad o diversidad funcional.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la representación de las personas en esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si en la noticia aparecen, se mencionan o protagonizan **MUJERES CON DISCAPACIDAD**.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No:\n",
    "        - Se menciona discapacidad, pero en HOMBRES (ej: \"El atleta paralímpico ganó el oro\").\n",
    "        - Se usan términos metafóricos (ej: \"La justicia es ciega\", \"parálisis política\").\n",
    "        - Son lesiones temporales (ej: \"La jugadora se rompió la pierna y estará baja un mes\").\n",
    "        - Se habla de discapacidad en general (leyes, barreras) sin mencionar a ninguna mujer o colectivo femenino específico.\n",
    "\n",
    "    2 = Sí:\n",
    "        - Aparece una mujer (o niña) con discapacidad física, sensorial, intelectual o psicosocial.\n",
    "        - Se habla de colectivos específicos (ej: \"Las mujeres con discapacidad sufren más violencia\").\n",
    "        - Se menciona a deportistas paralímpicas, activistas con diversidad funcional, etc.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Indica quién es la mujer y cuál es su discapacidad o contexto)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    # Gemma 4b suele ser bueno distinguiendo género en estos contextos\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return MujeresConDiscapacidadConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        return MujeresConDiscapacidadConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return MujeresConDiscapacidadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: El texto no contiene términos relacionados con la discapacidad o diversidad funcional.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "mujeres_con_discapacidad_noticias = clasificar_var_mujeres_con_discapacidad_noticias(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {mujeres_con_discapacidad_noticias.codigo}\")\n",
    "print(f\"Razón: {mujeres_con_discapacidad_noticias.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Presencia de diversidad generacional en las mujeres que aparecen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MujeresGeneracionalidadConExplicacion(BaseModel):\n",
    "    # 1 = No, 2 = Sí\n",
    "    codigo: int = Field(..., ge=1, le=2, description=\"1=No hay diversidad generacional, 2=Sí hay diversidad (niñas, ancianas o mezcla)\")\n",
    "    # Justificación\n",
    "    explicacion: str = Field(..., description=\"Detalle de las edades o generaciones identificadas en la noticia\")\n",
    "\n",
    "def clasificar_var_mujeres_generacionalidad_noticias(titulo: str, texto_cuerpo: str) -> MujeresGeneracionalidadConExplicacion:\n",
    "    \"\"\"\n",
    "    Detecta si en la noticia aparecen mujeres de **distintas generaciones** o de \n",
    "    **edades no hegemónicas** (niñas, adolescentes o ancianas).\n",
    "    Devuelve objeto con .codigo (1/2) y .explicacion (str).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unificamos texto\n",
    "    texto_completo = (titulo + \" \" + texto_cuerpo).lower()\n",
    "\n",
    "    # --- 1. FILTRO DE EFICIENCIA (Heurística) ---\n",
    "    # Buscamos marcadores de edad extremos o relaciones intergeneracionales.\n",
    "    # Si no aparecen, asumimos que son adultos estándar (lo más común en noticias).\n",
    "    \n",
    "    terminos_edad = [\n",
    "        # Infancia / Juventud\n",
    "        \"niña\", \"adolescente\", \"joven\", \"menor\", \"escolar\", \"alumna\", \"estudiante\", \n",
    "        \"chica\", \"hija\", \"infantil\", \"bebé\", \"generación z\",\n",
    "        # Vejez / Tercera Edad\n",
    "        \"anciana\", \"abuela\", \"jubilada\", \"mayor\", \"tercera edad\", \"senior\", \n",
    "        \"vejez\", \"pensionista\", \"octogenaria\", \"nonagenaria\", \"vieja\", \"residencia\",\n",
    "        # Relacional\n",
    "        \"madre\", \"nieta\", \"familia\", \"generaciones\", \"intergeneracional\"\n",
    "    ]\n",
    "    \n",
    "    if not any(t in texto_completo for t in terminos_edad):\n",
    "        return MujeresGeneracionalidadConExplicacion(\n",
    "            codigo=1,\n",
    "            explicacion=\"El texto no contiene términos que sugieran diversidad de edades (niñas, ancianas) o relaciones intergeneracionales.\"\n",
    "        )\n",
    "\n",
    "    # --- 2. PROMPT CON SOLICITUD DE JSON ---\n",
    "    texto_recortado = texto_cuerpo[:2000]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analiza la edad y las generaciones de las mujeres en esta noticia:\n",
    "    Título: \"{titulo}\"\n",
    "    Extracto: \"{texto_recortado}...\"\n",
    "\n",
    "    Tu tarea: Determinar si hay **DIVERSIDAD GENERACIONAL** en la representación femenina.\n",
    "\n",
    "    Criterios de clasificación:\n",
    "    \n",
    "    1 = No (Representación Estándar):\n",
    "        - Solo aparecen mujeres adultas en edad laboral típica (aprox 25-60 años). Ej: Políticas, profesionales, empresarias.\n",
    "        - Se menciona \"madre\" solo como dato biográfico sin relevancia en la historia (ej: \"es madre de dos hijos\").\n",
    "        - No se especifica la edad y se asume adultez.\n",
    "\n",
    "    2 = Sí (Diversidad / Edades no hegemónicas):\n",
    "        - Aparecen **Niñas o Adolescentes** con voz propia o como protagonistas.\n",
    "        - Aparecen **Mujeres Mayores / Ancianas / Jubiladas** (Visibilidad de la tercera edad).\n",
    "        - Hay un enfoque **Intergeneracional**: Se habla de madres e hijas, abuelas y nietas, o el impacto de un tema en distintas generaciones de mujeres.\n",
    "\n",
    "    FORMATO DE RESPUESTA (JSON):\n",
    "    Responde ÚNICAMENTE con un objeto JSON válido:\n",
    "    {{\n",
    "        \"codigo\": (1 o 2),\n",
    "        \"explicacion\": \"(Indica qué edades o relación generacional se ha detectado)\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 3. LLAMADA AL MODELO ---\n",
    "    # Usamos Gemma 4b (o tu modelo preferido)\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # --- 4. EXTRACCIÓN Y VALIDACIÓN ---\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1 or fin == 0:\n",
    "            return MujeresGeneracionalidadConExplicacion(\n",
    "                codigo=1, \n",
    "                explicacion=\"Error: El modelo no devolvió un formato JSON válido.\"\n",
    "            )\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "\n",
    "        return MujeresGeneracionalidadConExplicacion(**data)\n",
    "\n",
    "    except (json.JSONDecodeError, ValidationError) as e:\n",
    "        return MujeresGeneracionalidadConExplicacion(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico al procesar la respuesta: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código: 1\n",
      "Razón: La noticia se centra en el Papa Francisco y en su visión sobre el papel de la mujer en la Iglesia. Si bien se menciona el papel de María y de las madres, no hay ninguna mención explícita a niñas, adolescentes o mujeres mayores. La representación femenina se limita a la figura de la Virgen y a la referencia general a las madres sin detalles sobre sus edades o generaciones.\n"
     ]
    }
   ],
   "source": [
    "# -- Uso --\n",
    "mujeres_generacionalidad_noticias = clasificar_var_mujeres_generacionalidad_noticias(articulo.title, articulo.text)\n",
    "\n",
    "print(f\"Código: {mujeres_generacionalidad_noticias.codigo}\")\n",
    "print(f\"Razón: {mujeres_generacionalidad_noticias.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Tiene fotografías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "\n",
    "class FotografiasValidadas(BaseModel):\n",
    "    # Código: 1=No, 2=Sí\n",
    "    codigo: int = Field(..., description=\"1 = No tiene fotos, 2 = Sí tiene fotos.\")\n",
    "    \n",
    "    # Cantidad total\n",
    "    cantidad: int = Field(..., ge=0, description=\"Número total de fotografías editoriales detectadas.\")\n",
    "    \n",
    "    # Lista de links (URLs)\n",
    "    evidencias: List[str] = Field(default_factory=list, description=\"Lista de URLs de las imágenes encontradas.\")\n",
    "\n",
    "def clasificar_var_fotografias(articulo: Any) -> FotografiasValidadas:\n",
    "    \"\"\"\n",
    "    Analiza las imágenes del artículo (Top Image + Cuerpo).\n",
    "    Filtra iconos, basura y publicidad.\n",
    "    \n",
    "    Args:\n",
    "        articulo: Objeto 'Article' de la librería newspaper3k ya descargado y parseado.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Usamos un set para evitar duplicados (ej: si la top_image también sale en el texto)\n",
    "    imagenes_reales = set()\n",
    "    \n",
    "    # --- 1. IMAGEN DE PORTADA (TOP IMAGE) ---\n",
    "    if articulo.top_image and len(articulo.top_image) > 10:\n",
    "        # Filtro básico: que sea una URL válida y no vacía\n",
    "        imagenes_reales.add(articulo.top_image)\n",
    "\n",
    "    # --- 2. IMÁGENES DEL CUERPO ---\n",
    "    # Usamos clean_top_node (lxml object) que contiene solo el texto principal limpio\n",
    "    nodo_texto = articulo.clean_top_node \n",
    "    \n",
    "    if nodo_texto is not None:\n",
    "        # Buscamos todas las etiquetas <img>\n",
    "        imgs_en_texto = nodo_texto.xpath('.//img')\n",
    "        \n",
    "        for img in imgs_en_texto:\n",
    "            src = img.get('src')\n",
    "            if not src:\n",
    "                continue\n",
    "            \n",
    "            # Normalizamos a minúsculas para chequear\n",
    "            src_lower = src.lower()\n",
    "            \n",
    "            # --- FILTROS ANTI-BASURA (Heurística) ---\n",
    "            \n",
    "            # A. Descartar formatos que suelen ser de interfaz (iconos, spacers)\n",
    "            if src_lower.endswith(('.svg', '.gif', '.ico')):\n",
    "                continue\n",
    "                \n",
    "            # B. Palabras prohibidas (indican publicidad, tracking o diseño web)\n",
    "            palabras_prohibidas = [\n",
    "                'logo', 'icon', 'avatar', 'profile', 'pixel', 'spacer', \n",
    "                'doubleclick', 'adserver', 'banner', 'button', 'social',\n",
    "                'facebook', 'twitter', 'whatsapp', 'share', 'sprite',\n",
    "                'author', 'comment'\n",
    "            ]\n",
    "            \n",
    "            if any(palabra in src_lower for palabra in palabras_prohibidas):\n",
    "                continue\n",
    "\n",
    "            # C. Descartar por dimensiones diminutas (si el HTML las tiene)\n",
    "            # Muchos \"pixels\" de tracking son de 1x1\n",
    "            width = img.get('width')\n",
    "            height = img.get('height')\n",
    "            \n",
    "            # Si tiene width/height y es menor a 100px, seguramente no es una foto editorial\n",
    "            if width and width.isdigit() and int(width) < 100:\n",
    "                continue\n",
    "            if height and height.isdigit() and int(height) < 100:\n",
    "                continue\n",
    "\n",
    "            # Si pasa los filtros, añadimos la URL\n",
    "            imagenes_reales.add(src)\n",
    "\n",
    "    # --- 3. CONSTRUCCIÓN DE RESPUESTA ---\n",
    "    lista_urls = list(imagenes_reales)\n",
    "    cantidad_final = len(lista_urls)\n",
    "    \n",
    "    # Lógica de código: 2 si hay fotos, 1 si no\n",
    "    codigo_final = 2 if cantidad_final > 0 else 1\n",
    "\n",
    "    return FotografiasValidadas(\n",
    "        codigo=codigo_final,\n",
    "        cantidad=cantidad_final,\n",
    "        evidencias=lista_urls\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiene_fotografías: 2\n",
      "evidencias: ['https://imagenes.elpais.com/resizer/v2/GRTTGV7Y4ZKFDVK4U3GUUYUFIQ.jpg?auth=3d17bb971b271d189c1b6328e0e021caa8c8564205be253ff3fd874f05e20526&width=1200', 'https://imagenes.elpais.com/resizer/v2/BIL6F6XXBACFYNHAVX2ZOCOSEQ.jpg?auth=860ae2406676a882f13929e253d0da8a5a8737f37e136ebafe0ab14a6efdc776&width=414', 'https://imagenes.elpais.com/resizer/v2/4ARYAUF2ZAV3NZ3PP3N6XUV6PM.jpg?auth=dc0f4ec4476886d2edaf94a765bf5325c787d36cf24ffbab6d8fd277c1248640&width=414']\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "tiene_fotografías = clasificar_var_fotografias(articulo).codigo\n",
    "print(f\"tiene_fotografías: {tiene_fotografías}\")\n",
    "print(f\"evidencias: {clasificar_var_fotografias(articulo).evidencias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Número de fotografías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad: 3\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "numero_fotografias = clasificar_var_fotografias(articulo).cantidad\n",
    "print(f\"cantidad: {numero_fotografias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Tiene Fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuentesValidadas(BaseModel):\n",
    "    # Un solo número entero: 2 si hay fuentes, 1 si no hay\n",
    "    codigo: int = Field(..., description=\"1 = No tiene fuentes, 2 = Sí tiene fuentes.\")\n",
    "    \n",
    "    # La lista de evidencias (nombres de las fuentes)\n",
    "    evidencias: List[str] = Field(default_factory=list, description=\"Lista de nombres de las fuentes detectadas.\")\n",
    "    \n",
    "    # Cantidad total\n",
    "    cantidad: int = Field(..., description=\"Número total de fuentes.\")\n",
    "\n",
    "def clasificar_var_tiene_fuentes(texto_noticia: str) -> FuentesValidadas:\n",
    "    \"\"\"\n",
    "    Determina si la noticia tiene fuentes.\n",
    "    Retorna codigo=2 si encuentra al menos una, codigo=1 si no encuentra nada.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Validación inicial\n",
    "    if not texto_noticia or len(texto_noticia) < 50:\n",
    "        return FuentesValidadas(codigo=1, evidencias=[], cantidad=0)\n",
    "\n",
    "    # 2. Recorte (Analizamos el principio del texto donde se atribuyen las fuentes)\n",
    "    texto_analisis = texto_noticia[:3500]\n",
    "\n",
    "    # 3. Prompt: Solo pedimos la lista de nombres\n",
    "    prompt = f\"\"\"\n",
    "    Analiza el texto y extrae una lista de las FUENTES de información explícitas (personas, entidades, documentos) a las que se atribuyen los datos.\n",
    "\n",
    "    TEXTO: \"{texto_analisis}...\"\n",
    "\n",
    "    INSTRUCCIONES:\n",
    "    - Busca verbos de atribución: \"según X\", \"dijo Y\", \"informó Z\", \"fuentes de...\", \"el informe de...\".\n",
    "    - Si es un artículo de opinión sin datos externos, la lista debe estar vacía.\n",
    "\n",
    "    Responde SOLO con este JSON:\n",
    "    {{\n",
    "        \"fuentes\": [\"Nombre Fuente 1\", \"Nombre Fuente 2\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # 4. Llamada al LLM\n",
    "    respuesta_texto = consultar_ollama(prompt)\n",
    "\n",
    "    # 5. Lógica Python (Determinista)\n",
    "    try:\n",
    "        inicio = respuesta_texto.find('{')\n",
    "        fin = respuesta_texto.rfind('}') + 1\n",
    "        \n",
    "        if inicio == -1:\n",
    "            return FuentesValidadas(codigo=1, evidencias=[], cantidad=0)\n",
    "            \n",
    "        json_str = respuesta_texto[inicio:fin]\n",
    "        data = json.loads(json_str)\n",
    "        \n",
    "        # Extraemos la lista limpia\n",
    "        lista_fuentes = data.get(\"fuentes\", [])\n",
    "        cantidad = len(lista_fuentes)\n",
    "        \n",
    "        # --- AQUÍ ESTÁ EL CAMBIO ---\n",
    "        if cantidad > 0:\n",
    "            # Si hay elementos -> Código 2 (Sí)\n",
    "            return FuentesValidadas(\n",
    "                codigo=2,\n",
    "                evidencias=lista_fuentes,\n",
    "                cantidad=cantidad\n",
    "            )\n",
    "        else:\n",
    "            # Si la lista está vacía -> Código 1 (No)\n",
    "            return FuentesValidadas(\n",
    "                codigo=1,\n",
    "                evidencias=[],\n",
    "                cantidad=0\n",
    "            )\n",
    "\n",
    "    except Exception:\n",
    "        return FuentesValidadas(codigo=1, evidencias=[], cantidad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiene_fuentes: 2\n",
      "evidencias: ['Papa Francisco', 'Ministerio del Interior italiano', 'REUTERS', 'VATICAN MEDIA', 'Alessandra Smerilli']\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "tiene_fuentes = clasificar_var_tiene_fuentes(articulo.text).codigo\n",
    "print(f\"tiene_fuentes: {tiene_fuentes}\")\n",
    "print(f\"evidencias: {clasificar_var_tiene_fuentes(articulo.text).evidencias}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Número de Fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad: 5\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "print(f\"cantidad: {clasificar_var_tiene_fuentes(articulo.text).cantidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 02/2026 - Experimento Interspeech (Bloque II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 25.Tiene lenguaje sexista\n",
    "- 26.Uso del masculino genérico\n",
    "- 27.Uso de &quot;hombre&quot; para denominar a la humanidad\n",
    "- 28.Uso dual aparente (zorra/zorro)\n",
    "- 29.No usa cargos, profesiones y oficios para denominar mujeres\n",
    "- 30.Sexismo social en el discurso\n",
    "- 31.Androcentrismo\n",
    "- 32.Se mencionan mujeres sin el uso del nombre (la investigadora)\n",
    "- 33.Asimetría entre mujeres y hombre en el tratamiento (nombre de pila vs. apellido)\n",
    "- 34.Infantilización de las mujeres\n",
    "- 35.Denominación sexualizada (chicas, niñas, mujeres...)\n",
    "- 36.Denominación redundante (Una mujer ingeniera)\n",
    "- 37.Denominación dependiente (Relaciones familiares de las mujeres [&quot;hija de&quot;, &quot;esposa de&quot;])\n",
    "- 38.Existe criterios de excepción o noticiabilidad (la primera, la única...)\n",
    "- 39.Existe comparación de mujeres a hombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_variables_desde_json(ruta_archivo: str = \"variables.json\") -> list:\n",
    "    \"\"\"Carga el archivo JSON completo desde el disco.\"\"\"\n",
    "    try:\n",
    "        with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo '{ruta_archivo}'. Asegúrate de crearlo con los datos del prompt anterior.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"El archivo '{ruta_archivo}' no tiene un formato JSON válido.\")\n",
    "\n",
    "def obtener_config_variable(datos_json: list, codigo_buscado: str) -> dict:\n",
    "    \"\"\"Filtra la lista de variables para encontrar la configuración específica.\"\"\"\n",
    "    for variable in datos_json:\n",
    "        if variable[\"codigo\"] == codigo_buscado:\n",
    "            return variable\n",
    "    raise ValueError(f\"La variable con código '{codigo_buscado}' no existe en el archivo JSON.\")\n",
    "\n",
    "def cargar_texto_template(ruta: str) -> str:\n",
    "    return Path(ruta).read_text(encoding=\"utf-8\")\n",
    "\n",
    "def generar_prompt_dinamico(config: dict, texto: str, ruta_template: str) -> str:\n",
    "    template = cargar_texto_template(ruta_template)\n",
    "    \n",
    "    valores = config['valores_posibles']\n",
    "    \n",
    "    # ESTRATEGIA: Separar la opción \"No\" (índice 0) de las \"Sí\" (índices 1 en adelante)\n",
    "    # Asumimos siempre que la primera opción en tu JSON es la negativa (\"No\", \"No se aprecia\", etc.)\n",
    "    opciones_activas = []\n",
    "    \n",
    "    # Empezamos el bucle en 1 para saltarnos el índice 0\n",
    "    for i in range(1, len(valores)):\n",
    "        # Código real es i+1 (porque 0 es 1, 1 es 2...)\n",
    "        codigo_real = i + 1\n",
    "        descripcion = valores[i]\n",
    "        opciones_activas.append(f\"{codigo_real} = {descripcion}\")\n",
    "    \n",
    "    # Convertimos la lista en texto\n",
    "    lista_opciones_str = \"\\n\".join(opciones_activas)\n",
    "    \n",
    "    # Calculamos el rango para la instrucción JSON\n",
    "    rango_codigos = f\"1 al {len(valores)}\"\n",
    "\n",
    "    prompt_final = template.format(\n",
    "        nombre=config['nombre'],\n",
    "        definicion=config['definicion'],\n",
    "        metodologia=config['metodologia'],\n",
    "        ejemplos=config['ejemplos'],\n",
    "        texto_input=texto,\n",
    "        lista_opciones_activas=lista_opciones_str, # <--- CAMBIO: Solo opciones positivas\n",
    "        rango_codigos=rango_codigos\n",
    "    )\n",
    "    \n",
    "    return prompt_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. Tiene lenguaje sexista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json_repair\n",
    "\n",
    "class BloqueAnalisisLenguajeSexista(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo específico para 'lenguaje_sexista' que tiene 3 valores:\n",
    "    1 = No\n",
    "    2 = Sí\n",
    "    3 = Sí; además se observa un salto semántico\n",
    "    \"\"\"\n",
    "    codigo: int = Field(\n",
    "        ..., \n",
    "        ge=1, \n",
    "        le=3, \n",
    "        description=\"Selección numérica: 1='No', 2='Sí', 3='Sí; además se observa un salto semántico'\"\n",
    "    )\n",
    "    explicacion: str = Field(\n",
    "        ..., \n",
    "        description=\"Cadena de pensamiento (Chain of Thought). Explica paso a paso por qué se ha seleccionado ese código.\"\n",
    "    )\n",
    "    evidencias: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"Lista exacta de frases, palabras o fragmentos extraídos del texto que justifican la decisión.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def clasificar_var_lenguaje_sexista(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"25\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando lenguaje_sexista con template dinámico ---\n",
      "lenguaje_sexista codigo: 2\n",
      "lenguaje_sexista evidencias: ['‘mujeres’ como modelos de paz y unidad', '‘madres’ y ‘mujeres’ como ‘reunión de la familia humana’', '‘expareja’ como perpetrador de la violencia']\n",
      "lenguaje_sexista explicacion: El texto, a pesar de tratar un tema crucial como la violencia contra las mujeres, perpetúa un sesgo de género inherente a la forma en que se construye la narrativa. La constante referencia a ‘madres’ y ‘mujeres’ como modelos de paz, unidad y ‘reunión de la familia humana’ refuerza la idea de que las mujeres deben ser vistas principalmente por su rol maternal y su capacidad para ‘construir’ y ‘reunir’.  La repetición de estas categorías, sin una exploración de las diversas formas en que las mujeres pueden ejercer poder y liderazgo, reproduce un estereotipo. Además, la mención de ‘expareja’ en el contexto de la violencia, aunque relevante, se centra en la figura masculina como perpetrador, sin una exploración profunda de las causas estructurales de la violencia.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "lenguaje_sexista = clasificar_var_lenguaje_sexista(articulo.text)\n",
    "print(f\"lenguaje_sexista codigo: {lenguaje_sexista.codigo}\")\n",
    "print(f\"lenguaje_sexista evidencias: {lenguaje_sexista.evidencias}\")\n",
    "print(f\"lenguaje_sexista explicacion: {lenguaje_sexista.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. Uso del masculino genérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloqueAnalisisBinario(BaseModel):\n",
    "    \"\"\"\n",
    "    Modelo para variables con respuesta binaria:\n",
    "    1 = No\n",
    "    2 = Sí\n",
    "    \"\"\"\n",
    "    codigo: int = Field(\n",
    "        ..., \n",
    "        ge=1, \n",
    "        le=2, \n",
    "        description=\"Selección numérica: 1='No', 2='Sí'\"\n",
    "    )\n",
    "    explicacion: str = Field(\n",
    "        ..., \n",
    "        description=\"Cadena de pensamiento (Chain of Thought). Explica paso a paso por qué se ha seleccionado ese código, aplicando la metodología definida.\"\n",
    "    )\n",
    "    evidencias: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"Lista exacta de frases, palabras o fragmentos extraídos del texto que justifican la decisión.\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clasificar_var_masc_generico(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"26\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando masc_generico con template dinámico ---\n",
      "masc_generico codigo: 2\n",
      "masc_generico evidencias: ['‘el hombre’']\n",
      "masc_generico explicacion: El texto exhibe un uso sistemático del género gramatical masculino como referente universal ('el papa Francisco', 'el mundo necesita mirar a las madres', 'el hombre'). Esta naturalización del masculino como norma y la invisibilización de la mujer a través de la referencia constante al masculino, constituye un claro ejemplo de la variable 'masc_generico'. La construcción de la realidad se centra en la figura masculina, perpetuando un androcentrismo implícito.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "masc_generico = clasificar_var_masc_generico(articulo.text)\n",
    "print(f\"masc_generico codigo: {masc_generico.codigo}\")\n",
    "print(f\"masc_generico evidencias: {masc_generico.evidencias}\")\n",
    "print(f\"masc_generico explicacion: {masc_generico.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. Uso de &quot;hombre&quot; para denominar a la humanidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_hombre_denominar_humanidad(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"27\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando hombre_denominar_humanidad con template dinámico ---\n",
      "clasificar_var_hombre_denominar_humanidad codigo: 2\n",
      "clasificar_var_hombre_denominar_humanidad evidencias: ['‘el hombre de la inteligencia artificial’']\n",
      "clasificar_var_hombre_denominar_humanidad explicacion: El texto exhibe consistentemente la variable ‘hombre_denominar_humanidad’ a través de la constante referencia a ‘el hombre’ como referente universal, incluso cuando se habla de la humanidad en general. Frases como ‘quien lastima a una mujer profana a Dios, nacido de mujer’ y ‘necesita de una Madre que vuelva a reunir a la familia humana’ establecen al hombre como el modelo de humanidad, invisibilizando la mujer y asumiendo que la humanidad se define a través de la figura masculina. La repetición de ‘el hombre’ en contextos que deberían ser inclusivos, como ‘el hombre de la calle’ o ‘el hombre de la inteligencia artificial’, refuerza este sesgo.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "clasificar_var_hombre_denominar_humanidad = clasificar_var_hombre_denominar_humanidad(articulo.text)\n",
    "print(f\"clasificar_var_hombre_denominar_humanidad codigo: {clasificar_var_hombre_denominar_humanidad.codigo}\")\n",
    "print(f\"clasificar_var_hombre_denominar_humanidad evidencias: {clasificar_var_hombre_denominar_humanidad.evidencias}\")\n",
    "print(f\"clasificar_var_hombre_denominar_humanidad explicacion: {clasificar_var_hombre_denominar_humanidad.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. Uso dual aparente (zorro/zorra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_uso_dual_zorr(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"28\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando uso_dual_zorr con template dinámico ---\n",
      "uso_dual_zorr codigo: 2\n",
      "uso_dual_zorr evidencias: ['‘Miremos a María para ser constructores de unidad’', '‘La inteligencia artificial debe ser entendida como una galaxia de realidades distintas’', '‘La Iglesia necesita de María para redescubrir su propio rostro femenino’']\n",
      "uso_dual_zorr explicacion: El texto exhibe un uso sistemático de la variable ‘uso_dual_zorr’ a través de la constante referencia a ‘mujer’ y ‘hombre’ como categorías fundamentales para describir roles, responsabilidades y cualidades. La reiterada asociación de ‘mujer’ con atributos positivos como ‘cuidado’, ‘solicitud’, ‘generativa’, ‘madre’, ‘constructora de unidad’ y ‘emancipación’ en contraposición a la ‘cultura machista’ que genera ‘violencia’ y ‘odio’, revela una inversión de valores y una construcción de realidad que privilegia la figura femenina como modelo y solución, perpetuando así el androcentrismo. La constante referencia a la ‘mujer’ como ‘don’ y la necesidad de ‘redescubrir su rostro femenino’ refuerza esta dinámica.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "uso_dual_zorr = clasificar_var_uso_dual_zorr(articulo.text)\n",
    "print(f\"uso_dual_zorr codigo: {uso_dual_zorr.codigo}\")\n",
    "print(f\"uso_dual_zorr evidencias: {uso_dual_zorr.evidencias}\")\n",
    "print(f\"uso_dual_zorr explicacion: {uso_dual_zorr.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. No usa cargos, profesiones y oficios para denominar mujeres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_uso_cargo_mujer(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"29\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando uso_cargo_mujer con template dinámico ---\n",
      "uso_cargo_mujer codigo: 2\n",
      "uso_cargo_mujer evidencias: [\"'subsecretaria del dicasterio'\", \"'puestos de dirección'\", \"'la religiosa italiana Alessandra Smerilli fue nombrada'\"]\n",
      "uso_cargo_mujer explicacion: El texto exhibe de forma recurrente el 'uso_cargo_mujer' a través de la utilización constante del masculino gramatical para referirse a mujeres en roles de liderazgo y autoridad ('subsecretaria del dicasterio', 'puestos de dirección', 'la religiosa italiana').  Aunque el texto intenta transmitir una imagen de progreso y cambio, la naturalización del masculino como norma y la falta de especificidad en la denominación de las mujeres perpetúan la invisibilización y el androcentrismo. La frase 'la religiosa italiana Alessandra Smerilli fue nombrada' es particularmente reveladora, ya que no se nombra a la mujer directamente, sino que se la define a través de su cargo.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "uso_cargo_mujer = clasificar_var_uso_cargo_mujer(articulo.text)\n",
    "print(f\"uso_cargo_mujer codigo: {uso_cargo_mujer.codigo}\")\n",
    "print(f\"uso_cargo_mujer evidencias: {uso_cargo_mujer.evidencias}\")\n",
    "print(f\"uso_cargo_mujer explicacion: {uso_cargo_mujer.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30. Sexismo social en el discurso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_sexismo_discurso(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"30\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando sexismo_discurso con template dinámico ---\n",
      "sexismo_discurso codigo: 2\n",
      "sexismo_discurso evidencias: ['‘Mujer’ – se utiliza repetidamente para referirse a las víctimas de violencia y a la solución a los problemas.', \"'redescubrir su rostro femenino' – implica que la mujer necesita ser ‘redescubierta’ como modelo ideal.\", \"'Figura Perfecta' – María es presentada como un modelo inalcanzable y desvaloriza las características y experiencias de las mujeres en el presente.\"]\n",
      "sexismo_discurso explicacion: El texto, a pesar de denunciar la violencia contra las mujeres y reconocer avances en la participación femenina en la Iglesia, perpetúa un sexismo discursivo al idealizar la mujer como ‘Madre’, ‘Constructora de Unidad’ y ‘Figura Perfecta’ – roles tradicionales y asimétricos. La constante referencia a la ‘Madre’ y a la ‘Mujer’ como solución a problemas globales (paz, unidad) refuerza la idea de que la responsabilidad de la resolución de conflictos recae, inherentemente, en el género femenino, reproduciendo una visión patriarcal de la sociedad. Además, la descripción de María como ‘Figura Perfecta’ establece un modelo inalcanzable y, por tanto, desvaloriza las características y experiencias de las mujeres en el presente. La utilización de términos como ‘redescubrir su rostro femenino’ implica que este rostro, en su esencia, está ausente o necesita ser ‘redescubierto’, lo que implica una visión de género limitada y esencialista.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "sexismo_discurso = clasificar_var_sexismo_discurso(articulo.text)\n",
    "print(f\"sexismo_discurso codigo: {sexismo_discurso.codigo}\")\n",
    "print(f\"sexismo_discurso evidencias: {sexismo_discurso.evidencias}\")\n",
    "print(f\"sexismo_discurso explicacion: {sexismo_discurso.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31. Androcentrismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_androcentrismo(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"31\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando androcentrismo con template dinámico ---\n",
      "androcentrismo codigo: 2\n",
      "androcentrismo evidencias: ['‘La Iglesia necesita de María para redescubrir su propio rostro femenino’', '‘La Iglesia necesita de María para redescubrir su propio rostro femenino’', '‘La señora de Karembeu’ (aunque no explícitamente, la referencia a ‘la señora’ es un ejemplo de uso de un referente femenino como punto de referencia, implicando una jerarquía’']\n",
      "androcentrismo explicacion: El texto exhibe un androcentrismo evidente a través de la constante referencia a la ‘Madre’ (María) como modelo y solución a problemas sociales y existenciales. La construcción de la ‘Madre’ como figura central, y la invocación de su ‘dón’ (regalo) de ‘cuidado y solicitud’ y ‘paciencia y valentía materna’ refuerza la idea de que la mujer debe ser vista y valorada principalmente por sus cualidades maternales y su capacidad para ‘cuidar’.  Además, la reiterada mención de ‘la Iglesia necesita de María’ implica que la solución a los problemas de la Iglesia, y por extensión del mundo, reside en la figura femenina, perpetuando un modelo de autoridad y conocimiento basado en lo femenino. La referencia a ‘redescubrir su rostro femenino’ es una forma de esencialización, reduciendo la identidad femenina a un conjunto de atributos considerados ‘femeninos’ y, por tanto, subordinados.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "androcentrismo = clasificar_var_androcentrismo(articulo.text)\n",
    "print(f\"androcentrismo codigo: {androcentrismo.codigo}\")\n",
    "print(f\"androcentrismo evidencias: {androcentrismo.evidencias}\")\n",
    "print(f\"androcentrismo explicacion: {androcentrismo.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32. Se mencionan mujeres sin el uso del nombre (la investigadora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_mencion_nombre_investigadora(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"32\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando mencion_nombre_investigadora con template dinámico ---\n",
      "mencion_nombre_investigadora codigo: 1\n",
      "mencion_nombre_investigadora evidencias: []\n",
      "mencion_nombre_investigadora explicacion: El texto, en su conjunto, no presenta evidencia clara de la variable 'mencion_nombre_investradora'. Si bien se menciona a figuras como Francisco y Alessandra Smerilli, la mención se realiza de forma genérica, utilizando títulos y cargos en lugar de nombres y apellidos. La redacción es descriptiva y enfocada en el rol y la función, lo cual es común en el periodismo, pero no indica una invisibilización intencionada o un sesgo de género en la forma de identificar a las figuras femeninas. La repetición de 'el Papa Francisco' refuerza esta tendencia.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "mencion_nombre_investigadora = clasificar_var_mencion_nombre_investigadora(articulo.text)\n",
    "print(f\"mencion_nombre_investigadora codigo: {mencion_nombre_investigadora.codigo}\")\n",
    "print(f\"mencion_nombre_investigadora evidencias: {mencion_nombre_investigadora.evidencias}\")\n",
    "print(f\"mencion_nombre_investigadora explicacion: {mencion_nombre_investigadora.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33. Asimetría entre mujeres y hombre en el tratamiento (nombre de pila vs. apellido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_asimetria_mujer_hombre(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"33\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando asimetria_mujer_hombre con template dinámico ---\n",
      "asimetria_mujer_hombre codigo: 2\n",
      "asimetria_mujer_hombre evidencias: ['‘el papa Francisco’', '‘Alessandra Smerilli’', '‘María’', '‘la religiosa italiana Alessandra Smerilli’']\n",
      "asimetria_mujer_hombre explicacion: El texto exhibe una asimetría de tratamiento nominal significativa. Se refiere a Francisco como ‘el papa Francisco’ repetidamente, utilizando su título y nombre de pila, mientras que las mujeres, incluso figuras religiosas importantes como María y Alessandra Smerilli, se presentan con sus apellidos y nombres completos. Esta práctica, aunque aparentemente neutral, refuerza la construcción de una jerarquía de género, situando al hombre en la posición central y de referencia, y relegando a las mujeres a un segundo plano a través de la formalización del tratamiento. La repetición del tratamiento formal para Francisco, en contraposición al tratamiento más informal y personal para las mujeres, es una manifestación sutil pero constante del androcentrismo inherente al lenguaje periodístico.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "asimetria_mujer_hombre = clasificar_var_asimetria_mujer_hombre(articulo.text)\n",
    "print(f\"asimetria_mujer_hombre codigo: {asimetria_mujer_hombre.codigo}\")\n",
    "print(f\"asimetria_mujer_hombre evidencias: {asimetria_mujer_hombre.evidencias}\")\n",
    "print(f\"asimetria_mujer_hombre explicacion: {asimetria_mujer_hombre.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34. Infatilización de las mujeres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_disminutivos_infantilizacion(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"34\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando disminutivos_infantilizacion con template dinámico ---\n",
      "disminutivos_infantilizacion codigo: 2\n",
      "disminutivos_infantilizacion evidencias: ['‘cuidado y solicitud’']\n",
      "disminutivos_infantilizacion explicacion: El texto exhibe una fuerte infantilización de la mujer a través de la constante referencia a la ‘Madre’, ‘galaxia de realidades distintas’ (en referencia a la IA), y la reiterada invocación de ‘cuidado y solicitud’, ‘paciencia y valentía materna’. Estas expresiones, aunque aparentemente positivas en su intención, operan como un mecanismo de naturalización de roles tradicionales y una representación de la mujer como un ser inherentemente protector y dependiente, reforzando la imagen de ‘Madre’ como modelo a seguir y limitando su autonomía. La repetición de términos asociados a la infancia – ‘Madre’, ‘cuidado’ – es un indicativo claro de esta infantilización. La referencia a ‘C’è ancora domani’ como herramienta didáctica también puede interpretarse como una idealización de un pasado donde la mujer estaba subordinada a la autoridad masculina.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "disminutivos_infantilizacion = clasificar_var_disminutivos_infantilizacion(articulo.text)\n",
    "print(f\"disminutivos_infantilizacion codigo: {disminutivos_infantilizacion.codigo}\")\n",
    "print(f\"disminutivos_infantilizacion evidencias: {disminutivos_infantilizacion.evidencias}\")\n",
    "print(f\"disminutivos_infantilizacion explicacion: {disminutivos_infantilizacion.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35. Denominación sexualizada (chicas, niñas, mujeres...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_denominacion_sexualizada(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"35\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando denominacion_sexualizada con template dinámico ---\n",
      "denominacion_sexualizada codigo: 2\n",
      "denominacion_sexualizada evidencias: ['‘La Iglesia necesita de María’', '‘La Iglesia necesita de María para redescubrir su propio rostro femenino’', '‘La Iglesia necesita de María para ser generativa a través de una pastoral hecha de cuidado y solicitud, de paciencia y valentía materna’', '‘La Iglesia necesita de María para ser constructores de unidad’']\n",
      "denominacion_sexualizada explicacion: El texto, a pesar de tratar un tema urgente como la violencia contra las mujeres, perpetúa la variable ‘denominación sexualizada’ al referirse constantemente a las mujeres como ‘Madre’, ‘Mujeres’, ‘Familia’ y ‘la Iglesia necesita de María’.  Esta recurrencia, aunque intencionalmente para evocar un rol tradicional y protector, reduce a las mujeres a su función biológica y social, despojándolas de su individualidad y agencia. La insistencia en ‘María’ como modelo, aunque busca empoderamiento, sigue siendo una referencia que refuerza la idea de la mujer como receptora y transmisora de valores, en lugar de agente activo en la construcción de la realidad. La repetición de términos relacionados con la maternidad y el cuidado, aunque no explícitamente sexualizados, contribuye a una representación estereotipada y a una denominación basada únicamente en su sexo.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "denominacion_sexualizada = clasificar_var_denominacion_sexualizada(articulo.text)\n",
    "print(f\"denominacion_sexualizada codigo: {denominacion_sexualizada.codigo}\")\n",
    "print(f\"denominacion_sexualizada evidencias: {denominacion_sexualizada.evidencias}\")\n",
    "print(f\"denominacion_sexualizada explicacion: {denominacion_sexualizada.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36. Denominación redundante (Una mujer ingeniera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_denominacion_redundante(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"36\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando denominacion_redundante con template dinámico ---\n",
      "denominacion_redundante codigo: 2\n",
      "denominacion_redundante evidencias: ['‘el papa Francisco’', '‘el Pontífice’', '‘el Papa publica algunas semanas antes un mensaje especial’']\n",
      "denominacion_redundante explicacion: El texto, a pesar de tratar un tema urgente como la violencia contra las mujeres, perpetúa la variable ‘denominación_redundante’ al referirse constantemente a ‘el papa Francisco’ y ‘el Pontífice’.  La repetición de títulos honoríficos que ya implican la identidad del líder religioso, en lugar de utilizar simplemente ‘Francisco’, refuerza una visión patriarcal donde la figura masculina es siempre la principal y la que da nombre a las acciones y referencias.  La constante utilización de ‘el Pontífice’  es un ejemplo claro de cómo el lenguaje puede naturalizar la autoridad masculina y relegar a la mujer a un rol secundario, incluso cuando se aborda un problema de desigualdad.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "denominacion_redundante = clasificar_var_denominacion_redundante(articulo.text)\n",
    "print(f\"denominacion_redundante codigo: {denominacion_redundante.codigo}\")\n",
    "print(f\"denominacion_redundante evidencias: {denominacion_redundante.evidencias}\")\n",
    "print(f\"denominacion_redundante explicacion: {denominacion_redundante.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37. Denominación dependiente (Relaciones familiares de las mujeres [&quot;hija de&quot;, &quot;esposa de&quot;])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_denominacion_dependiente(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"37\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando denominacion_dependiente con template dinámico ---\n",
      "denominacion_dependiente codigo: 2\n",
      "denominacion_dependiente evidencias: ['‘la hija de Ali’', '‘la ex de Iker Casillas’', '‘la señora de Karembeu’', '‘María’ (mención constante como modelo y figura idealizada)']\n",
      "denominacion_dependiente explicacion: El texto, a pesar de su intento de abordar la violencia de género y el papel de las mujeres en la Iglesia, recurre consistentemente a la denominación dependiente. La referencia a ‘la hija de Ali’, ‘la ex de Iker Casillas’, ‘la señora de Karembeu’ y la reiterada mención a ‘María’ como modelo, establecen una relación de las mujeres a través de su vínculo con hombres. Esta construcción refuerza la idea de que la identidad femenina está definida en relación con figuras masculinas, perpetuando un androcentrismo implícito. La constante referencia a ‘María’ como ‘modelo’ es particularmente problemática, ya que la idealiza como una figura femenina sin agencia propia, reduciendo su valor a su rol maternal y religioso.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "denominacion_dependiente = clasificar_var_denominacion_dependiente(articulo.text)\n",
    "print(f\"denominacion_dependiente codigo: {denominacion_dependiente.codigo}\")\n",
    "print(f\"denominacion_dependiente evidencias: {denominacion_dependiente.evidencias}\")\n",
    "print(f\"denominacion_dependiente explicacion: {denominacion_dependiente.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38. Existe criterios de excepción o noticiabilidad (la primera, la única...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_criterios_excepcion(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"38\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando criterios_excepcion con template dinámico ---\n",
      "criterios_excepcion codigo: 2\n",
      "criterios_excepcion evidencias: ['‘figuras perfectas’']\n",
      "criterios_excepcion explicacion: El texto, a pesar de abordar la violencia contra las mujeres y los esfuerzos de la Iglesia para promover la igualdad, perpetúa el criterio de excepción al presentar a las mujeres como ‘recolección de dones’ y ‘figuras perfectas’ a través de la analogía con María. La referencia a ‘redescubrir su rostro femenino’ y ‘dar espacio a las mujeres’ implica que su rol es excepcional y necesita ser activamente buscado y restaurado, en lugar de ser considerado intrínseco a la Iglesia. Se establece una diferencia entre el rol ‘natural’ de la mujer y el rol que la Iglesia ‘debe’ darle, reforzando la idea de que la mujer es una anomalía que necesita ser reconocida y valorada. La mención de la subsecretaria como ‘el cargo más alto ocupado por una mujer’ también refuerza esta percepción de excepcionalidad.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "criterios_excepcion = clasificar_var_criterios_excepcion(articulo.text)\n",
    "print(f\"criterios_excepcion codigo: {criterios_excepcion.codigo}\")\n",
    "print(f\"criterios_excepcion evidencias: {criterios_excepcion.evidencias}\")\n",
    "print(f\"criterios_excepcion explicacion: {criterios_excepcion.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 39. Existe comparación de mujeres a hombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_var_comparacion_mujer_hombre(\n",
    "    texto_articulo: str, \n",
    "    ruta_json: str = \"variables.json\",\n",
    "    ruta_template: str = \"prompts/prompt_clara.md\"\n",
    ") -> BloqueAnalisisLenguajeSexista:\n",
    "    \n",
    "    # A. Carga Configuración\n",
    "    try:\n",
    "        vars_data = cargar_variables_desde_json(ruta_json)\n",
    "        config = obtener_config_variable(vars_data, \"39\") \n",
    "    except Exception as e:\n",
    "        return BloqueAnalisisLenguajeSexista(codigo=1, explicacion=f\"Error config: {e}\", evidencias=[])\n",
    "\n",
    "    # ✅ CAMBIO 2: Limpieza preventiva del texto ANTES del prompt\n",
    "    # Si el artículo tiene comillas dobles (\"), las convertimos a simples (')\n",
    "    # para que no confundan al modelo al generar el JSON.\n",
    "    texto_seguro = texto_articulo.replace('\"', \"'\")\n",
    "\n",
    "    # B. Generación del Prompt (pasamos el texto seguro)\n",
    "    prompt = generar_prompt_dinamico(config, texto_seguro, ruta_template)\n",
    "\n",
    "    # C. Llamada a Ollama\n",
    "    print(f\"--- Analizando {config['nombre']} con template dinámico ---\")\n",
    "    respuesta_raw = consultar_ollama(prompt, temperature=0.1) \n",
    "\n",
    "    # D. Parsing y Validación ROBUSTA\n",
    "    try:\n",
    "        # ✅ CAMBIO 3: Usar json_repair en lugar de json.loads\n",
    "        # json_repair hace tres cosas automáticamente:\n",
    "        # 1. Quita los bloques Markdown (```json)\n",
    "        # 2. Arregla comillas dobles rotas dentro de los textos\n",
    "        # 3. Cierra llaves faltantes\n",
    "        data = json_repair.loads(respuesta_raw)\n",
    "        \n",
    "        return BloqueAnalisisLenguajeSexista(**data)\n",
    "\n",
    "    except ValidationError as e:\n",
    "        print(f\"⚠️ Error de validación Pydantic: {e}\")\n",
    "        # Retorno de seguridad si faltan campos obligatorios\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"El modelo no devolvió los campos correctos. Raw: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fatal: {e}\")\n",
    "        return BloqueAnalisisLenguajeSexista(\n",
    "            codigo=1, \n",
    "            explicacion=f\"Error técnico irrecuperable: {str(e)}\", \n",
    "            evidencias=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando comparacion_mujer_hombre con template dinámico ---\n",
      "comparacion_mujer_hombre codigo: 2\n",
      "comparacion_mujer_hombre evidencias: ['‘Miremos a María para ser constructores de unidad’', '‘La mujer… representa su modelo y su figura perfecta’', '‘La inteligencia artificial debe ser entendida como una galaxia de realidades distintas’ (implica una valoración de la ‘realidad’ masculina como norma y la femenina como unida a ella)']\n",
      "comparacion_mujer_hombre explicacion: El texto, a pesar de su intento de abordar la violencia contra las mujeres y la necesidad de empoderamiento femenino en la Iglesia, perpetúa la variable ‘mujer-hombre’ a través de la constante referencia a la ‘mujer’ como modelo a imitar y como fuente de ‘paz’ y ‘unidad’. La frase ‘Miremos a María para ser constructores de unidad’ es particularmente reveladora, ya que establece a la mujer (María) como el referente ideal, un modelo a seguir, lo que refuerza la idea de una jerarquía de género donde la figura masculina es la norma y la femenina la que debe aspirar a emular. La referencia a ‘reunir a la familia humana’ también implica una visión tradicional de la familia centrada en la figura masculina. La repetición de la ‘mujer’ como solución a problemas sociales y la referencia a su ‘cuidado’ y ‘solicitud’ son indicadores claros de esta comparación constante.\n"
     ]
    }
   ],
   "source": [
    "# --- Uso ---\n",
    "comparacion_mujer_hombre = clasificar_var_comparacion_mujer_hombre(articulo.text)\n",
    "print(f\"comparacion_mujer_hombre codigo: {comparacion_mujer_hombre.codigo}\")\n",
    "print(f\"comparacion_mujer_hombre evidencias: {comparacion_mujer_hombre.evidencias}\")\n",
    "print(f\"comparacion_mujer_hombre explicacion: {comparacion_mujer_hombre.explicacion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
